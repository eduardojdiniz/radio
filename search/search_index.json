{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"RadIO: Pytorch Lightning Data Modules for Radiology. Project GitHub Repo: https://github.com/eduardojdiniz/radio","title":"Home"},{"location":"radio/","text":"Module radio package init Sub-modules radio.app radio.data radio.settings radio.structured_config radio.version","title":"Index"},{"location":"radio/#module-radio","text":"package init","title":"Module radio"},{"location":"radio/#sub-modules","text":"radio.app radio.data radio.settings radio.structured_config radio.version","title":"Sub-modules"},{"location":"radio/app/","text":"Module radio.app Package entry point Functions app(cfg: radio.structured_config.experiment.ExperimentConfig) \u2011> None : hydra entry point","title":"App"},{"location":"radio/app/#module-radioapp","text":"Package entry point","title":"Module radio.app"},{"location":"radio/app/#functions","text":"app(cfg: radio.structured_config.experiment.ExperimentConfig) \u2011> None : hydra entry point","title":"Functions"},{"location":"radio/version/","text":"Module radio.version package version","title":"Version"},{"location":"radio/version/#module-radioversion","text":"package version","title":"Module radio.version"},{"location":"radio/data/","text":"Module radio.data Data init Sub-modules radio.data.basedatamodule radio.data.constants radio.data.datadecorators radio.data.datamodules radio.data.dataset radio.data.datatypes radio.data.datautils radio.data.datavisualization radio.data.inference radio.data.validation radio.data.visiondatamodule","title":"Index"},{"location":"radio/data/#module-radiodata","text":"Data init","title":"Module radio.data"},{"location":"radio/data/#sub-modules","text":"radio.data.basedatamodule radio.data.constants radio.data.datadecorators radio.data.datamodules radio.data.dataset radio.data.datatypes radio.data.datautils radio.data.datavisualization radio.data.inference radio.data.validation radio.data.visiondatamodule","title":"Sub-modules"},{"location":"radio/data/basedatamodule/","text":"Module radio.data.basedatamodule Based on LightningDataModule for managing data. A datamodule is a shareable, reusable class that encapsulates all the steps needed to process data, i.e., decoupling datasets from models to allow building dataset-agnostic models. They also allow you to share a full dataset without explaining how to download, split, transform, and process the data. Classes BaseDataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/home/dinize@acct.upmchs.net/playground/radio/dataset'), train_transforms: Optional[torchio.transforms.transform.Transform] = None, val_transforms: Optional[torchio.transforms.transform.Transform] = None, test_transforms: Optional[torchio.transforms.transform.Transform] = None, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, seed: int = 41, **kwargs: Any) : Base class for making data modules. To create a subclass, you need to implement the following functions: A BaseDataModule needs to implement 6 key methods: <__init__>: (Optionally) Initialize the class, first call super.__init__(). <prepare_data>: Things to do on 1 GPU/TPU not on every GPU/TPU in distributed mode. <setup>: Things to do on every accelerator in distributed mode. <train_dataloader>: The training dataloader(s). <val_dataloader>: The validation dataloader(s). <test_dataloader>: The test dataloader(s). <teardown>: Things to do on every accelerator in distributed mode when finished. Typical Workflow ---------------- data = BaseDataModule() data.prepare_data() # download data.setup(stage) # process and split data.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root directory of dataset. If None, a temporary directory will be used. Default = ``DATA_ROOT / 'medical_decathlon'``. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split: int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Ancestors (in MRO) * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Descendants * radio.data.visiondatamodule.VisionDataModule ### Class variables `EXTRA_ARGS: dict` : Extra arguments for dataset_cls instantiation. `dataset_cls: type` : Dataset class to use. E.g., torchvision.datasets.MNIST `name: str` : Dataset name ### Instance variables `dims: Optional[Tuple[int, int, int]]` : A tuple describing the shape of the data ### Methods `prepare_data(self, *args: Any, **kwargs: Any) \u2011> None` : Data operations to be performed that need to be done only from a single process in distributed settings. For example, download and saving data. Warning ------- DO NOT set state here (use ``'setup'`` instead) since this is NOT called on every device. Example ------- def prepare_data(self, *args, **kwargs): # good download_data() tokenize() etc() # good torchvison.datasets.MNIST(self.root, train=True, download=True) torchvison.datasets.MNIST(self.root, train=False, download=True) # bad self.split = data_split self.some_state = some_other_state() `setup(self, stage: Optional[str] = None) \u2011> None` : Data operations to be performed on every GPU. This is a good hook when you need to build models dynamically or adjust something about them based on the data atrributes. For example, count number of classes, build vocabulary, perform train/val/test splits, apply transforms. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = None, set-up all stages. Default = None. Example ------- def setup(self, stage): if stage in (None, \"fit\"): # train + validation set-up self.data_train, self.data_val = load_fit(...) self.dims = self.data_train[0][0].shape self.l1 = nn.Linear(28, self.data_train.num_classes) if stage in (None, \"test\"): # test set-up self.data_test = load_test(...) self.dims = self.data_test[0][0].shape self.l1 = nn.Linear(28, self.data_test.num_classes) `teardown(self, stage: Optional[str] = None) \u2011> None` : Called at the end of fit (train + validate), validate, test, or predict. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = None, set-up all stages. Default = None. `test_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for testing. Returns ------- _ : Collection of DataLoader Collection of test dataloaders specifying testing samples. Examples ------- # single dataloader def test_dataloader(self): transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,)) ]) dataset = MNIST( root='/path/to/mnist/', train=False, transform=transform, download=True ) loader = torch.utils.data.DataLoader( dataset=dataset, batch_size=self.batch_size, shuffle=False ) return loader # multiple dataloaders, return as list def test_dataloader(self): mnist = MNIST(...) cifar = CIFAR(...) mnist_loader = torch.utils.data.DataLoader( dataset=mnist, batch_size=self.batch_size, shuffle=False ) cifar_loader = torch.utils.data.DataLoader( dataset=cifar, batch_size=self.batch_size, shuffle=False ) # each batch will be a list of tensors: [batch_mnist, batch_cifar] return [mnist_loader, cifar_loader] `train_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader], Sequence[Sequence[torch.utils.data.dataloader.DataLoader]], Sequence[Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, torch.utils.data.dataloader.DataLoader], Dict[str, Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, Sequence[torch.utils.data.dataloader.DataLoader]]]` : Generates one or multiple Pytorch DataLoaders for training. Returns ------- _ : Collection of DataLoader Collection of train dataloaders specifying training samples. Examples ------- # single dataloader def train_dataloader(self): transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,)) ]) dataset = MNIST( root='/path/to/mnist/', train=True, transform=transform, download=True ) loader = torch.utils.data.DataLoader( dataset=dataset, batch_size=self.batch_size, shuffle=True ) return loader # multiple dataloaders, return as list def train_dataloader(self): mnist = MNIST(...) cifar = CIFAR(...) mnist_loader = torch.utils.data.DataLoader( dataset=mnist, batch_size=self.batch_size, shuffle=True ) cifar_loader = torch.utils.data.DataLoader( dataset=cifar, batch_size=self.batch_size, shuffle=True ) # each batch will be a list of tensors: [batch_mnist, batch_cifar] return [mnist_loader, cifar_loader] # multiple dataloader, return as dict def train_dataloader(self): mnist = MNIST(...) cifar = CIFAR(...) mnist_loader = torch.utils.data.DataLoader( dataset=mnist, batch_size=self.batch_size, shuffle=True ) cifar_loader = torch.utils.data.DataLoader( dataset=cifar, batch_size=self.batch_size, shuffle=True ) # each batch will be a dict of tensors: {'mnist': batch_mnist, 'cifar': batch_cifar} return {'mnist': mnist_loader, 'cifar': cifar_loader} `val_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for validation. Returns ------- _ : Collection of DataLoader Collection of validation dataloaders specifying validation samples. Examples ------- # single dataloader def val_dataloader(self): transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,)) ]) dataset = MNIST( root='/path/to/mnist/', train=False, transform=transform, download=True ) loader = torch.utils.data.DataLoader( dataset=dataset, batch_size=self.batch_size, shuffle=False ) return loader # multiple dataloaders, return as list def val_dataloader(self): mnist = MNIST(...) cifar = CIFAR(...) mnist_loader = torch.utils.data.DataLoader( dataset=mnist, batch_size=self.batch_size, shuffle=False ) cifar_loader = torch.utils.data.DataLoader( dataset=cifar, batch_size=self.batch_size, shuffle=False ) # each batch will be a list of tensors: [batch_mnist, batch_cifar] return [mnist_loader, cifar_loader]","title":"Base Data Module"},{"location":"radio/data/basedatamodule/#module-radiodatabasedatamodule","text":"Based on LightningDataModule for managing data. A datamodule is a shareable, reusable class that encapsulates all the steps needed to process data, i.e., decoupling datasets from models to allow building dataset-agnostic models. They also allow you to share a full dataset without explaining how to download, split, transform, and process the data.","title":"Module radio.data.basedatamodule"},{"location":"radio/data/basedatamodule/#classes","text":"BaseDataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/home/dinize@acct.upmchs.net/playground/radio/dataset'), train_transforms: Optional[torchio.transforms.transform.Transform] = None, val_transforms: Optional[torchio.transforms.transform.Transform] = None, test_transforms: Optional[torchio.transforms.transform.Transform] = None, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, seed: int = 41, **kwargs: Any) : Base class for making data modules. To create a subclass, you need to implement the following functions: A BaseDataModule needs to implement 6 key methods: <__init__>: (Optionally) Initialize the class, first call super.__init__(). <prepare_data>: Things to do on 1 GPU/TPU not on every GPU/TPU in distributed mode. <setup>: Things to do on every accelerator in distributed mode. <train_dataloader>: The training dataloader(s). <val_dataloader>: The validation dataloader(s). <test_dataloader>: The test dataloader(s). <teardown>: Things to do on every accelerator in distributed mode when finished. Typical Workflow ---------------- data = BaseDataModule() data.prepare_data() # download data.setup(stage) # process and split data.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root directory of dataset. If None, a temporary directory will be used. Default = ``DATA_ROOT / 'medical_decathlon'``. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split: int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Ancestors (in MRO) * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Descendants * radio.data.visiondatamodule.VisionDataModule ### Class variables `EXTRA_ARGS: dict` : Extra arguments for dataset_cls instantiation. `dataset_cls: type` : Dataset class to use. E.g., torchvision.datasets.MNIST `name: str` : Dataset name ### Instance variables `dims: Optional[Tuple[int, int, int]]` : A tuple describing the shape of the data ### Methods `prepare_data(self, *args: Any, **kwargs: Any) \u2011> None` : Data operations to be performed that need to be done only from a single process in distributed settings. For example, download and saving data. Warning ------- DO NOT set state here (use ``'setup'`` instead) since this is NOT called on every device. Example ------- def prepare_data(self, *args, **kwargs): # good download_data() tokenize() etc() # good torchvison.datasets.MNIST(self.root, train=True, download=True) torchvison.datasets.MNIST(self.root, train=False, download=True) # bad self.split = data_split self.some_state = some_other_state() `setup(self, stage: Optional[str] = None) \u2011> None` : Data operations to be performed on every GPU. This is a good hook when you need to build models dynamically or adjust something about them based on the data atrributes. For example, count number of classes, build vocabulary, perform train/val/test splits, apply transforms. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = None, set-up all stages. Default = None. Example ------- def setup(self, stage): if stage in (None, \"fit\"): # train + validation set-up self.data_train, self.data_val = load_fit(...) self.dims = self.data_train[0][0].shape self.l1 = nn.Linear(28, self.data_train.num_classes) if stage in (None, \"test\"): # test set-up self.data_test = load_test(...) self.dims = self.data_test[0][0].shape self.l1 = nn.Linear(28, self.data_test.num_classes) `teardown(self, stage: Optional[str] = None) \u2011> None` : Called at the end of fit (train + validate), validate, test, or predict. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = None, set-up all stages. Default = None. `test_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for testing. Returns ------- _ : Collection of DataLoader Collection of test dataloaders specifying testing samples. Examples ------- # single dataloader def test_dataloader(self): transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,)) ]) dataset = MNIST( root='/path/to/mnist/', train=False, transform=transform, download=True ) loader = torch.utils.data.DataLoader( dataset=dataset, batch_size=self.batch_size, shuffle=False ) return loader # multiple dataloaders, return as list def test_dataloader(self): mnist = MNIST(...) cifar = CIFAR(...) mnist_loader = torch.utils.data.DataLoader( dataset=mnist, batch_size=self.batch_size, shuffle=False ) cifar_loader = torch.utils.data.DataLoader( dataset=cifar, batch_size=self.batch_size, shuffle=False ) # each batch will be a list of tensors: [batch_mnist, batch_cifar] return [mnist_loader, cifar_loader] `train_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader], Sequence[Sequence[torch.utils.data.dataloader.DataLoader]], Sequence[Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, torch.utils.data.dataloader.DataLoader], Dict[str, Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, Sequence[torch.utils.data.dataloader.DataLoader]]]` : Generates one or multiple Pytorch DataLoaders for training. Returns ------- _ : Collection of DataLoader Collection of train dataloaders specifying training samples. Examples ------- # single dataloader def train_dataloader(self): transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,)) ]) dataset = MNIST( root='/path/to/mnist/', train=True, transform=transform, download=True ) loader = torch.utils.data.DataLoader( dataset=dataset, batch_size=self.batch_size, shuffle=True ) return loader # multiple dataloaders, return as list def train_dataloader(self): mnist = MNIST(...) cifar = CIFAR(...) mnist_loader = torch.utils.data.DataLoader( dataset=mnist, batch_size=self.batch_size, shuffle=True ) cifar_loader = torch.utils.data.DataLoader( dataset=cifar, batch_size=self.batch_size, shuffle=True ) # each batch will be a list of tensors: [batch_mnist, batch_cifar] return [mnist_loader, cifar_loader] # multiple dataloader, return as dict def train_dataloader(self): mnist = MNIST(...) cifar = CIFAR(...) mnist_loader = torch.utils.data.DataLoader( dataset=mnist, batch_size=self.batch_size, shuffle=True ) cifar_loader = torch.utils.data.DataLoader( dataset=cifar, batch_size=self.batch_size, shuffle=True ) # each batch will be a dict of tensors: {'mnist': batch_mnist, 'cifar': batch_cifar} return {'mnist': mnist_loader, 'cifar': cifar_loader} `val_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for validation. Returns ------- _ : Collection of DataLoader Collection of validation dataloaders specifying validation samples. Examples ------- # single dataloader def val_dataloader(self): transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,)) ]) dataset = MNIST( root='/path/to/mnist/', train=False, transform=transform, download=True ) loader = torch.utils.data.DataLoader( dataset=dataset, batch_size=self.batch_size, shuffle=False ) return loader # multiple dataloaders, return as list def val_dataloader(self): mnist = MNIST(...) cifar = CIFAR(...) mnist_loader = torch.utils.data.DataLoader( dataset=mnist, batch_size=self.batch_size, shuffle=False ) cifar_loader = torch.utils.data.DataLoader( dataset=cifar, batch_size=self.batch_size, shuffle=False ) # each batch will be a list of tensors: [batch_mnist, batch_cifar] return [mnist_loader, cifar_loader]","title":"Classes"},{"location":"radio/data/constants/","text":"Module radio.data.constants Constants.","title":"Constants"},{"location":"radio/data/constants/#module-radiodataconstants","text":"Constants.","title":"Module radio.data.constants"},{"location":"radio/data/datadecorators/","text":"Module radio.data.datadecorators Decorators for Sample parameters validation. Functions assert_type(*dynamic_args, test_type=typing.Union[torch.Tensor, radio.data.datatypes.Tensor, typing.Sequence[typing.Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor, typing.Sequence[typing.Union[torch.Tensor, radio.data.datatypes.Tensor, typing.Sequence[typing.Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor]], radio.data.datatypes.SeqSeqTensor], **dynamic_kwargs) \u2011> Callable : Assert `*dynamic_args and **dynamic_kwargs are of test_type . Parameters ---------- _func : Callable, optional test_type: Tensors, optional Type to test ``dynamic_args`` and ``dynamic_kwargs`` aganst it. Default = ``Tensors``. Returns ------- _ : Callable Decorated function.","title":"Datadecorators"},{"location":"radio/data/datadecorators/#module-radiodatadatadecorators","text":"Decorators for Sample parameters validation.","title":"Module radio.data.datadecorators"},{"location":"radio/data/datadecorators/#functions","text":"assert_type(*dynamic_args, test_type=typing.Union[torch.Tensor, radio.data.datatypes.Tensor, typing.Sequence[typing.Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor, typing.Sequence[typing.Union[torch.Tensor, radio.data.datatypes.Tensor, typing.Sequence[typing.Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor]], radio.data.datatypes.SeqSeqTensor], **dynamic_kwargs) \u2011> Callable : Assert `*dynamic_args and **dynamic_kwargs are of test_type . Parameters ---------- _func : Callable, optional test_type: Tensors, optional Type to test ``dynamic_args`` and ``dynamic_kwargs`` aganst it. Default = ``Tensors``. Returns ------- _ : Callable Decorated function.","title":"Functions"},{"location":"radio/data/dataset/","text":"Module radio.data.dataset Datasets are based on the PyTorch torch.utils.data.Dataset data primitive. They store the samples and their corresponding labels. Pytorch domain libraries (e.g., vision, text, audio) provide pre-loaded datasets (e.g., MNIST) that subclass torch.utils.data.Dataset and implement functions specific to the particular data. They can be used to prototype and benchmark your model. You can find them at Image Datasets , Text Datasets , and Audio Datasets . This module implements an abstract base class BaseVisionDataset for vision datasets. It also replicates the official PyTorch image folder (https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py) so it can inherent from BaseVisionDataset and have extended functionality. Classes BaseVisionDataset(root: Union[str, pathlib.Path] = PosixPath('/home/dinize@acct.upmchs.net/playground/radio/dataset'), transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807) : Base Class For making datasets which are compatible with torchvision. It is necessary to override the __getitem__ and __len__ method. To create a subclass, you need to implement the following functions: <__init__>: (Optionally) Initialize the class, first call super.__init__(root, train, transform, target_transform, **kwargs). <__len__>: Return the number of samples in the dataset. <__getitem__>: Get a data point. Parameters ---------- root : Path or str Data root directory. Where to save/load the data. transform : Optional[Callable] A function/transform that takes in an PIL image and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. target_transform : Optional[Callable] A function/transform that takes in the target and transforms it. ### Ancestors (in MRO) * torchvision.datasets.vision.VisionDataset * torch.utils.data.dataset.Dataset * typing.Generic ### Descendants * radio.data.dataset.FolderDataset ### Class variables `functions: Dict[str, Callable]` : FolderDataset(root: Union[str, pathlib.Path], loader: Callable[[pathlib.Path], Any], transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[pathlib.Path], bool]] = None, return_paths: bool = False, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807) : A generic folder dataset. This default directory structure can be customized by overriding the :meth:`find_classes` and :meth:`make_dataset` methods. Attributes ---------- classes : list List of the class names sorted alphabetically. num_classes : int Number of classes in the dataset. class_to_idx : dict Dict with items (class_name, class_index). samples : list List of (sample, class_index) tuples. targets : list The class_index value for each image in the dataset. Parameters ---------- root : Path or str Data root directory. Where to save/load the data. loader : Callable A function to load a sample given its path. transform : Optional[Callable] A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop`` for images. target_transform : Callable[Optional] Optional function/transform that takes in a target and returns a transformed version. extensions : Tuple[str] A list of allowed extensions. is_valid_file : Optional[Callable[[Path], bool]] A function that takes path of a file and check if the file is a valid file (used to check of corrupt files). return_paths : bool If True, calling the dataset returns `(sample, target), target, sample path` instead of returning `(sample, target), target`. Notes ----- Both `extensions` and `is_valid_file` cannot be None or not None at the same time. ### Ancestors (in MRO) * radio.data.dataset.BaseVisionDataset * torchvision.datasets.vision.VisionDataset * torch.utils.data.dataset.Dataset * typing.Generic ### Descendants * radio.data.dataset.ImageFolder ### Class variables `functions: Dict[str, Callable]` : ### Static methods `find_classes(directory: pathlib.Path) \u2011> Tuple[List[str], Dict[str, int]]` : Find the class folders in a image dataset structured as follows: directory/ \u251c\u2500\u2500 class_x \u2502 \u251c\u2500\u2500 xxx.ext \u2502 \u251c\u2500\u2500 xxy.ext \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 xxz.ext \u2514\u2500\u2500 class_y \u251c\u2500\u2500 123.ext \u251c\u2500\u2500 nsdf3.ext \u2514\u2500\u2500 ... \u2514\u2500\u2500 asd932_.ext This method can be overridden to only consider a subset of classes, or to adapt to a different dataset directory structure. Arguments --------- directory : Path Root directory path, corresponding to ``self.root``. Raises ------ FileNotFoundError: If ``directory`` has no class folders. Returns ------- _: Tuple[List[str], Dict[str, int]] List of all classes and dictionary mapping each class to an index. `make_dataset(directory: pathlib.Path, class_to_idx: Dict[str, int], extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[pathlib.Path], bool]] = None, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807) \u2011> List[Tuple[pathlib.Path, int]]` : Generates a list of images of a form (path_to_sample, class). This can be overridden to e.g. read files from a compressed zip file instead of from the disk. Parameters ---------- directory : Path root dataset directory, corresponding to ``self.root``. class_to_idx : Dict[str, int] Dictionary mapping class name to class index. extensions : Tuple[str] A list of allowed extensions. is_valid_file : Optional[Callable[[Path], bool]] A function that takes path of a file and check if the file is a valid file (used to check of corrupt files). max_dataset_size : int Maximum number of samples allowed in the dataset. max_class_size : int Maximum number of samples allowed per class. Raises ------ ValueError: In case ``class_to_idx`` is empty. FileNotFoundError: In case no valid file was found for any class. Returns ------- _: Sample Samples of a form (path_to_sample, class). Notes ----- Both `extensions` and `is_valid_file` cannot be None or not None at the same time. ImageFolder(root: Union[str, pathlib.Path], loader: Callable[[pathlib.Path], Any] = <function default_image_loader>, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, is_valid_file: Optional[Callable[[pathlib.Path], bool]] = None, return_paths: bool = False, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807) : A generic image folder dataset where the images are arranged in this way by default: root/ \u251c\u2500\u2500 dog \u2502 \u251c\u2500\u2500 xxx.png \u2502 \u251c\u2500\u2500 xxy.png \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 xxz.png \u2514\u2500\u2500 cat \u251c\u2500\u2500 123.png \u251c\u2500\u2500 nsdf3.png \u2514\u2500\u2500 ... \u2514\u2500\u2500 asd932_.png This class inherits from :class:`FolderDataset` so the same methods can be overridden to customize the dataset. Attributes ---------- classes : list List of the class names sorted alphabetically. num_classes : int Number of classes in the dataset. class_to_idx : dict Dict with items (class_name, class_index). samples : list List of (images, class_index) tuples targets : list The class_index value for each image in the dataset Parameters ---------- root : Path or str Data root directory. Where to save/load the data. loader : Optional[Callable] A function to load a image given its path. transform : Optional[Callable] A function/transform that takes in an PIL image and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. target_transform : Callable[Optional] Optional function/transform that takes in a target and returns a transformed version. is_valid_file : Optional[Callable[[Path], bool]] A function that takes path of an image file and check if the file is a valid image file (used to check of corrupt files). return_paths : bool If True, calling the dataset returns `(img, label), label, image path` instead of returning `(img, label), label`. ### Ancestors (in MRO) * radio.data.dataset.FolderDataset * radio.data.dataset.BaseVisionDataset * torchvision.datasets.vision.VisionDataset * torch.utils.data.dataset.Dataset * typing.Generic ### Class variables `functions: Dict[str, Callable]` :","title":"Dataset"},{"location":"radio/data/dataset/#module-radiodatadataset","text":"Datasets are based on the PyTorch torch.utils.data.Dataset data primitive. They store the samples and their corresponding labels. Pytorch domain libraries (e.g., vision, text, audio) provide pre-loaded datasets (e.g., MNIST) that subclass torch.utils.data.Dataset and implement functions specific to the particular data. They can be used to prototype and benchmark your model. You can find them at Image Datasets , Text Datasets , and Audio Datasets . This module implements an abstract base class BaseVisionDataset for vision datasets. It also replicates the official PyTorch image folder (https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py) so it can inherent from BaseVisionDataset and have extended functionality.","title":"Module radio.data.dataset"},{"location":"radio/data/dataset/#classes","text":"BaseVisionDataset(root: Union[str, pathlib.Path] = PosixPath('/home/dinize@acct.upmchs.net/playground/radio/dataset'), transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807) : Base Class For making datasets which are compatible with torchvision. It is necessary to override the __getitem__ and __len__ method. To create a subclass, you need to implement the following functions: <__init__>: (Optionally) Initialize the class, first call super.__init__(root, train, transform, target_transform, **kwargs). <__len__>: Return the number of samples in the dataset. <__getitem__>: Get a data point. Parameters ---------- root : Path or str Data root directory. Where to save/load the data. transform : Optional[Callable] A function/transform that takes in an PIL image and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. target_transform : Optional[Callable] A function/transform that takes in the target and transforms it. ### Ancestors (in MRO) * torchvision.datasets.vision.VisionDataset * torch.utils.data.dataset.Dataset * typing.Generic ### Descendants * radio.data.dataset.FolderDataset ### Class variables `functions: Dict[str, Callable]` : FolderDataset(root: Union[str, pathlib.Path], loader: Callable[[pathlib.Path], Any], transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[pathlib.Path], bool]] = None, return_paths: bool = False, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807) : A generic folder dataset. This default directory structure can be customized by overriding the :meth:`find_classes` and :meth:`make_dataset` methods. Attributes ---------- classes : list List of the class names sorted alphabetically. num_classes : int Number of classes in the dataset. class_to_idx : dict Dict with items (class_name, class_index). samples : list List of (sample, class_index) tuples. targets : list The class_index value for each image in the dataset. Parameters ---------- root : Path or str Data root directory. Where to save/load the data. loader : Callable A function to load a sample given its path. transform : Optional[Callable] A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop`` for images. target_transform : Callable[Optional] Optional function/transform that takes in a target and returns a transformed version. extensions : Tuple[str] A list of allowed extensions. is_valid_file : Optional[Callable[[Path], bool]] A function that takes path of a file and check if the file is a valid file (used to check of corrupt files). return_paths : bool If True, calling the dataset returns `(sample, target), target, sample path` instead of returning `(sample, target), target`. Notes ----- Both `extensions` and `is_valid_file` cannot be None or not None at the same time. ### Ancestors (in MRO) * radio.data.dataset.BaseVisionDataset * torchvision.datasets.vision.VisionDataset * torch.utils.data.dataset.Dataset * typing.Generic ### Descendants * radio.data.dataset.ImageFolder ### Class variables `functions: Dict[str, Callable]` : ### Static methods `find_classes(directory: pathlib.Path) \u2011> Tuple[List[str], Dict[str, int]]` : Find the class folders in a image dataset structured as follows: directory/ \u251c\u2500\u2500 class_x \u2502 \u251c\u2500\u2500 xxx.ext \u2502 \u251c\u2500\u2500 xxy.ext \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 xxz.ext \u2514\u2500\u2500 class_y \u251c\u2500\u2500 123.ext \u251c\u2500\u2500 nsdf3.ext \u2514\u2500\u2500 ... \u2514\u2500\u2500 asd932_.ext This method can be overridden to only consider a subset of classes, or to adapt to a different dataset directory structure. Arguments --------- directory : Path Root directory path, corresponding to ``self.root``. Raises ------ FileNotFoundError: If ``directory`` has no class folders. Returns ------- _: Tuple[List[str], Dict[str, int]] List of all classes and dictionary mapping each class to an index. `make_dataset(directory: pathlib.Path, class_to_idx: Dict[str, int], extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[pathlib.Path], bool]] = None, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807) \u2011> List[Tuple[pathlib.Path, int]]` : Generates a list of images of a form (path_to_sample, class). This can be overridden to e.g. read files from a compressed zip file instead of from the disk. Parameters ---------- directory : Path root dataset directory, corresponding to ``self.root``. class_to_idx : Dict[str, int] Dictionary mapping class name to class index. extensions : Tuple[str] A list of allowed extensions. is_valid_file : Optional[Callable[[Path], bool]] A function that takes path of a file and check if the file is a valid file (used to check of corrupt files). max_dataset_size : int Maximum number of samples allowed in the dataset. max_class_size : int Maximum number of samples allowed per class. Raises ------ ValueError: In case ``class_to_idx`` is empty. FileNotFoundError: In case no valid file was found for any class. Returns ------- _: Sample Samples of a form (path_to_sample, class). Notes ----- Both `extensions` and `is_valid_file` cannot be None or not None at the same time. ImageFolder(root: Union[str, pathlib.Path], loader: Callable[[pathlib.Path], Any] = <function default_image_loader>, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, is_valid_file: Optional[Callable[[pathlib.Path], bool]] = None, return_paths: bool = False, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807) : A generic image folder dataset where the images are arranged in this way by default: root/ \u251c\u2500\u2500 dog \u2502 \u251c\u2500\u2500 xxx.png \u2502 \u251c\u2500\u2500 xxy.png \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 xxz.png \u2514\u2500\u2500 cat \u251c\u2500\u2500 123.png \u251c\u2500\u2500 nsdf3.png \u2514\u2500\u2500 ... \u2514\u2500\u2500 asd932_.png This class inherits from :class:`FolderDataset` so the same methods can be overridden to customize the dataset. Attributes ---------- classes : list List of the class names sorted alphabetically. num_classes : int Number of classes in the dataset. class_to_idx : dict Dict with items (class_name, class_index). samples : list List of (images, class_index) tuples targets : list The class_index value for each image in the dataset Parameters ---------- root : Path or str Data root directory. Where to save/load the data. loader : Optional[Callable] A function to load a image given its path. transform : Optional[Callable] A function/transform that takes in an PIL image and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. target_transform : Callable[Optional] Optional function/transform that takes in a target and returns a transformed version. is_valid_file : Optional[Callable[[Path], bool]] A function that takes path of an image file and check if the file is a valid image file (used to check of corrupt files). return_paths : bool If True, calling the dataset returns `(img, label), label, image path` instead of returning `(img, label), label`. ### Ancestors (in MRO) * radio.data.dataset.FolderDataset * radio.data.dataset.BaseVisionDataset * torchvision.datasets.vision.VisionDataset * torch.utils.data.dataset.Dataset * typing.Generic ### Class variables `functions: Dict[str, Callable]` :","title":"Classes"},{"location":"radio/data/datatypes/","text":"Module radio.data.datatypes Sample Variables and Types definition. Functions get_sample_type(sample_name: str) \u2011> type : Infer sample type from sample name. Parameters ---------- sample_name: str Sample name, e.g., ``'Tensor'`. Returns ------- sample_type: torch.Tensor or Image.Image Sample type, e.g., ``torch.Tensor``. Classes Img(data: SingletonVar, sample_type: InitVar[str] = 'PILImage') : Immutable Image Type. ### Ancestors (in MRO) * radio.data.datatypes.Sample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableImg(_data: SingletonVar, sample_type: InitVar[str] = 'PILImage') : Mutable Image Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableNamedImg(_name: KeyVar, _data: SingletonVar, sample_type: InitVar[str] = 'PILImage') : Mutable Named Image Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableNamedSample(_name: KeyVar, _data: SingletonVar, sample_type: InitVar[str] = 'MutableSample') : Mutable Named Sample Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableNamedImg * radio.data.datatypes.MutableNamedTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data: ~SingletonVar` : data attribute `name: ~KeyVar` : name attribute MutableNamedTensor(_name: KeyVar, _data: SingletonVar, sample_type: InitVar[str] = 'TorchTensor') : Mutable Named Tensor Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableSample(_data: SingletonVar, sample_type: InitVar[str] = 'MutableSample') : Mutable Sample Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableImg * radio.data.datatypes.MutableTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data: ~SingletonVar` : data attribute MutableSeqImg(data: MutableSeqVar, sample_type: InitVar[str] = 'MutableImg') : Mutable Sequence of Images Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableSeqNamedImg(name: KeyVar, data: MutableSeqNamedVar, sample_type: InitVar[str] = 'MutableNamedImg') : Mutable Sequence of Named Images Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableSeqNamedSample(name: KeyVar, data: MutableSeqNamedVar, sample_type: InitVar[str] = 'MutableNamedSample') : Mutable Sequence of Named Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableSeqNamedImg * radio.data.datatypes.MutableSeqNamedTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. `name` : Return an attribute of instance, which is of type owner. MutableSeqNamedTensor(name: KeyVar, data: MutableSeqNamedVar, sample_type: InitVar[str] = 'MutableNamedTensor') : Mutable Sequence of NamedTensors Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableSeqSample(data: MutableSeqVar, sample_type: InitVar[str] = 'MutableSample') : Mutable Sequence of Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableSeqImg * radio.data.datatypes.MutableSeqTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. MutableSeqSeqImg(data: MutableSeqSeqVar) : Mutable Nested Sequence of Images Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSeqSample * typing.Generic ### Class variables `sample_type: str` : MutableSeqSeqNamedImg(data: MutableSeqSeqNamedVar) : Mutable Nested Sequence of Named Images Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSeqNamedSample * typing.Generic ### Class variables `sample_type: str` : MutableSeqSeqNamedSample(data: MutableSeqSeqNamedVar) : Mutable Nested Sequence of Named Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableSeqSeqNamedImg * radio.data.datatypes.MutableSeqSeqNamedTensor ### Class variables `sample_type: str` : ### Instance variables `data: ~MutableSeqSeqNamedVar` : Return an attribute of instance, which is of type owner. MutableSeqSeqNamedTensor(data: MutableSeqSeqNamedVar) : Mutable Nested Sequence of Named Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSeqNamedSample * typing.Generic ### Class variables `sample_type: str` : MutableSeqSeqSample(data: MutableSeqSeqVar) : Mutable Nested Sequence of Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableSeqSeqImg * radio.data.datatypes.MutableSeqSeqTensor ### Class variables `sample_type: str` : ### Instance variables `data: ~MutableSeqSeqVar` : Return an attribute of instance, which is of type owner. MutableSeqSeqTensor(data: MutableSeqSeqVar) : Mutable Nested Sequence of Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSeqSample * typing.Generic ### Class variables `sample_type: str` : MutableSeqTensor(data: MutableSeqVar, sample_type: InitVar[str] = 'MutableTensor') : Mutable Sequence of Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableTensor(_data: SingletonVar, sample_type: InitVar[str] = 'TorchTensor') : Mutable Tensor Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : NamedImg(name: KeyVar, data: SingletonVar, sample_type: InitVar[str] = 'PILImage') : Immutable Named Image Type. ### Ancestors (in MRO) * radio.data.datatypes.NamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : NamedSample(name: KeyVar, data: SingletonVar, sample_type: InitVar[str] = 'Sample') : Immutable Named Sample Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.NamedImg * radio.data.datatypes.NamedTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. `name` : data given name NamedTensor(name: KeyVar, data: SingletonVar, sample_type: InitVar[str] = 'TorchTensor') : Immutable Named Tensor Type. ### Ancestors (in MRO) * radio.data.datatypes.NamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : Sample(data: SingletonVar, sample_type: InitVar[str] = 'Sample') : Immutable Sample Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.Img * radio.data.datatypes.Tensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. SeqImg(data: SeqVar, sample_type: InitVar[str] = 'Img') : Immutable Sequence of Images Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : SeqNamedImg(name: KeyVar, data: SeqNamedVar, sample_type: InitVar[str] = 'NamedImg') : Immutable Sequence of Named Images Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : SeqNamedSample(name: KeyVar, data: SeqNamedVar, sample_type: InitVar[str] = 'NamedSample') : Immutable Sequence of Named Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.SeqNamedImg * radio.data.datatypes.SeqNamedTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. `name` : Return an attribute of instance, which is of type owner. SeqNamedTensor(name: KeyVar, data: SeqNamedVar, sample_type: InitVar[str] = 'NamedTensor') : Immutable Sequence of Named Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : SeqSample(data: SeqVar, sample_type: InitVar[str] = 'Sample') : Immutable Sequence of Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.SeqImg * radio.data.datatypes.SeqTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. SeqSeqImg(data: SeqSeqVar) : Immutable Nested Sequence of Images Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSeqSample * typing.Generic ### Class variables `sample_type: str` : SeqSeqNamedImg(data: SeqSeqNamedVar) : Immutable Nested Sequence of Named Images Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSeqNamedSample * typing.Generic ### Class variables `sample_type: str` : SeqSeqNamedSample(data: SeqSeqNamedVar) : Immutable Nested Sequence of Named Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.SeqSeqNamedImg * radio.data.datatypes.SeqSeqNamedTensor ### Class variables `sample_type: str` : ### Instance variables `data: ~SeqSeqNamedVar` : Return an attribute of instance, which is of type owner. SeqSeqNamedTensor(data: SeqSeqNamedVar) : Immutable Nested Sequence of Named Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSeqNamedSample * typing.Generic ### Class variables `sample_type: str` : SeqSeqSample(data: SeqSeqVar) : Immutable Nested Sequence of Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.SeqSeqImg * radio.data.datatypes.SeqSeqTensor ### Class variables `sample_type: str` : ### Instance variables `data: ~SeqSeqVar` : Return an attribute of instance, which is of type owner. SeqSeqTensor(data: SeqSeqVar) : Immutable Nested Sequence of Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSeqSample * typing.Generic ### Class variables `sample_type: str` : SeqTensor(data: SeqVar, sample_type: InitVar[str] = 'Tensor') : Immutable Sequence of Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : Tensor(data: SingletonVar, sample_type: InitVar[str] = 'TorchTensor') : Immutable Tensor Type. ### Ancestors (in MRO) * radio.data.datatypes.Sample * typing.Generic ### Class variables `sample_type: InitVar[str]` :","title":"Datatypes"},{"location":"radio/data/datatypes/#module-radiodatadatatypes","text":"Sample Variables and Types definition.","title":"Module radio.data.datatypes"},{"location":"radio/data/datatypes/#functions","text":"get_sample_type(sample_name: str) \u2011> type : Infer sample type from sample name. Parameters ---------- sample_name: str Sample name, e.g., ``'Tensor'`. Returns ------- sample_type: torch.Tensor or Image.Image Sample type, e.g., ``torch.Tensor``.","title":"Functions"},{"location":"radio/data/datatypes/#classes","text":"Img(data: SingletonVar, sample_type: InitVar[str] = 'PILImage') : Immutable Image Type. ### Ancestors (in MRO) * radio.data.datatypes.Sample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableImg(_data: SingletonVar, sample_type: InitVar[str] = 'PILImage') : Mutable Image Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableNamedImg(_name: KeyVar, _data: SingletonVar, sample_type: InitVar[str] = 'PILImage') : Mutable Named Image Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableNamedSample(_name: KeyVar, _data: SingletonVar, sample_type: InitVar[str] = 'MutableSample') : Mutable Named Sample Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableNamedImg * radio.data.datatypes.MutableNamedTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data: ~SingletonVar` : data attribute `name: ~KeyVar` : name attribute MutableNamedTensor(_name: KeyVar, _data: SingletonVar, sample_type: InitVar[str] = 'TorchTensor') : Mutable Named Tensor Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableSample(_data: SingletonVar, sample_type: InitVar[str] = 'MutableSample') : Mutable Sample Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableImg * radio.data.datatypes.MutableTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data: ~SingletonVar` : data attribute MutableSeqImg(data: MutableSeqVar, sample_type: InitVar[str] = 'MutableImg') : Mutable Sequence of Images Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableSeqNamedImg(name: KeyVar, data: MutableSeqNamedVar, sample_type: InitVar[str] = 'MutableNamedImg') : Mutable Sequence of Named Images Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableSeqNamedSample(name: KeyVar, data: MutableSeqNamedVar, sample_type: InitVar[str] = 'MutableNamedSample') : Mutable Sequence of Named Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableSeqNamedImg * radio.data.datatypes.MutableSeqNamedTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. `name` : Return an attribute of instance, which is of type owner. MutableSeqNamedTensor(name: KeyVar, data: MutableSeqNamedVar, sample_type: InitVar[str] = 'MutableNamedTensor') : Mutable Sequence of NamedTensors Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableSeqSample(data: MutableSeqVar, sample_type: InitVar[str] = 'MutableSample') : Mutable Sequence of Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableSeqImg * radio.data.datatypes.MutableSeqTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. MutableSeqSeqImg(data: MutableSeqSeqVar) : Mutable Nested Sequence of Images Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSeqSample * typing.Generic ### Class variables `sample_type: str` : MutableSeqSeqNamedImg(data: MutableSeqSeqNamedVar) : Mutable Nested Sequence of Named Images Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSeqNamedSample * typing.Generic ### Class variables `sample_type: str` : MutableSeqSeqNamedSample(data: MutableSeqSeqNamedVar) : Mutable Nested Sequence of Named Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableSeqSeqNamedImg * radio.data.datatypes.MutableSeqSeqNamedTensor ### Class variables `sample_type: str` : ### Instance variables `data: ~MutableSeqSeqNamedVar` : Return an attribute of instance, which is of type owner. MutableSeqSeqNamedTensor(data: MutableSeqSeqNamedVar) : Mutable Nested Sequence of Named Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSeqNamedSample * typing.Generic ### Class variables `sample_type: str` : MutableSeqSeqSample(data: MutableSeqSeqVar) : Mutable Nested Sequence of Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.MutableSeqSeqImg * radio.data.datatypes.MutableSeqSeqTensor ### Class variables `sample_type: str` : ### Instance variables `data: ~MutableSeqSeqVar` : Return an attribute of instance, which is of type owner. MutableSeqSeqTensor(data: MutableSeqSeqVar) : Mutable Nested Sequence of Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSeqSample * typing.Generic ### Class variables `sample_type: str` : MutableSeqTensor(data: MutableSeqVar, sample_type: InitVar[str] = 'MutableTensor') : Mutable Sequence of Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSeqSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : MutableTensor(_data: SingletonVar, sample_type: InitVar[str] = 'TorchTensor') : Mutable Tensor Type. ### Ancestors (in MRO) * radio.data.datatypes.MutableSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : NamedImg(name: KeyVar, data: SingletonVar, sample_type: InitVar[str] = 'PILImage') : Immutable Named Image Type. ### Ancestors (in MRO) * radio.data.datatypes.NamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : NamedSample(name: KeyVar, data: SingletonVar, sample_type: InitVar[str] = 'Sample') : Immutable Named Sample Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.NamedImg * radio.data.datatypes.NamedTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. `name` : data given name NamedTensor(name: KeyVar, data: SingletonVar, sample_type: InitVar[str] = 'TorchTensor') : Immutable Named Tensor Type. ### Ancestors (in MRO) * radio.data.datatypes.NamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : Sample(data: SingletonVar, sample_type: InitVar[str] = 'Sample') : Immutable Sample Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.Img * radio.data.datatypes.Tensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. SeqImg(data: SeqVar, sample_type: InitVar[str] = 'Img') : Immutable Sequence of Images Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : SeqNamedImg(name: KeyVar, data: SeqNamedVar, sample_type: InitVar[str] = 'NamedImg') : Immutable Sequence of Named Images Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : SeqNamedSample(name: KeyVar, data: SeqNamedVar, sample_type: InitVar[str] = 'NamedSample') : Immutable Sequence of Named Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.SeqNamedImg * radio.data.datatypes.SeqNamedTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. `name` : Return an attribute of instance, which is of type owner. SeqNamedTensor(name: KeyVar, data: SeqNamedVar, sample_type: InitVar[str] = 'NamedTensor') : Immutable Sequence of Named Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqNamedSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : SeqSample(data: SeqVar, sample_type: InitVar[str] = 'Sample') : Immutable Sequence of Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.SeqImg * radio.data.datatypes.SeqTensor ### Class variables `sample_type: InitVar[str]` : ### Instance variables `data` : Return an attribute of instance, which is of type owner. SeqSeqImg(data: SeqSeqVar) : Immutable Nested Sequence of Images Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSeqSample * typing.Generic ### Class variables `sample_type: str` : SeqSeqNamedImg(data: SeqSeqNamedVar) : Immutable Nested Sequence of Named Images Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSeqNamedSample * typing.Generic ### Class variables `sample_type: str` : SeqSeqNamedSample(data: SeqSeqNamedVar) : Immutable Nested Sequence of Named Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.SeqSeqNamedImg * radio.data.datatypes.SeqSeqNamedTensor ### Class variables `sample_type: str` : ### Instance variables `data: ~SeqSeqNamedVar` : Return an attribute of instance, which is of type owner. SeqSeqNamedTensor(data: SeqSeqNamedVar) : Immutable Nested Sequence of Named Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSeqNamedSample * typing.Generic ### Class variables `sample_type: str` : SeqSeqSample(data: SeqSeqVar) : Immutable Nested Sequence of Samples Type. ### Ancestors (in MRO) * typing.Generic ### Descendants * radio.data.datatypes.SeqSeqImg * radio.data.datatypes.SeqSeqTensor ### Class variables `sample_type: str` : ### Instance variables `data: ~SeqSeqVar` : Return an attribute of instance, which is of type owner. SeqSeqTensor(data: SeqSeqVar) : Immutable Nested Sequence of Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSeqSample * typing.Generic ### Class variables `sample_type: str` : SeqTensor(data: SeqVar, sample_type: InitVar[str] = 'Tensor') : Immutable Sequence of Tensors Type. ### Ancestors (in MRO) * radio.data.datatypes.SeqSample * typing.Generic ### Class variables `sample_type: InitVar[str]` : Tensor(data: SingletonVar, sample_type: InitVar[str] = 'TorchTensor') : Immutable Tensor Type. ### Ancestors (in MRO) * radio.data.datatypes.Sample * typing.Generic ### Class variables `sample_type: InitVar[str]` :","title":"Classes"},{"location":"radio/data/datautils/","text":"Module radio.data.datautils Data related utilities. Functions check_integrity(path: pathlib.Path, md5: Optional[str] = None) \u2011> bool : default_image_loader(path: pathlib.Path) \u2011> PIL.Image.Image : Load image file as RGB PIL Image Parameters ---------- path : Path Image file path Returns ------- return : Image.Image RGB PIL Image denormalize(tensor: torch.Tensor, mean: Tuple[float, ...] = None, std: Tuple[float, ...] = None) : Undoes mean/standard deviation normalization, zero to one scaling, and channel rearrangement for a batch of images. Parameters ---------- tensor : torch.Tensor A (CHANNELS x HEIGHT x WIDTH) tensor mean: Tuple[float, ...] A tuple of mean values to be subtracted from each image channel. std: Tuple[float, ...] A tuple of standard deviation values to be devided from each image channel. Returns ---------- array : numpy.ndarray[float] A (HEIGHT x WIDTH x CHANNELS) numpy array of floats get_first_batch(loader: Iterable, default: Optional[~Var] = None) \u2011> Optional[~Var] : Returns the first item in the given iterable or default if empty, meaningful mostly with 'for' expressions. Parameters ---------- loader : Iterable Dataloader to get the batch from. default: Any, optional Returned if ``loader`` is empty. Default = ``None``. Returns ------- batch : Any First batch from the dataloader. Default = ``None``. load_standard_test_imgs(directory: pathlib.Path = PosixPath('/home/dinize@acct.upmchs.net/playground/radio/imgs')) : plot(imgs: Union[torch.Tensor, radio.data.datatypes.Tensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor]], radio.data.datatypes.SeqSeqTensor], baseline_imgs: Union[torch.Tensor, radio.data.datatypes.Tensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor]], radio.data.datatypes.SeqSeqTensor] = None, row_titles: List[str] = None, fig_title: str = None, **imshow_kwargs) \u2011> None : Plot images in a 2D grid. Arguments --------- imgs : Samples Collection of images to be plotted. Each element of ``imgs`` holds a row of the image grid to be plotted. baseline_imgs : Samples, Optional Collection of baseline images. If not ``None``, the first column of the grid will be filled with the baseline images. ``baseline_imgs`` is either a single image, or a collection of images of the same length of an element of ``imgs``. Default = ``None``. row_titles : List[str], Optional List of row titles. If not ``None``, ``len(row_title)`` must be equal to ``len(imgs)``. Default = ``None``. fig_title : str, Optional Figure title. Default = ``None``. plot_batch(batch: Dict, num_samples: int = 5, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, exclude_keys: Optional[List[str]] = None) \u2011> None : plot images and labels from a batch of images","title":"Data Utils"},{"location":"radio/data/datautils/#module-radiodatadatautils","text":"Data related utilities.","title":"Module radio.data.datautils"},{"location":"radio/data/datautils/#functions","text":"check_integrity(path: pathlib.Path, md5: Optional[str] = None) \u2011> bool : default_image_loader(path: pathlib.Path) \u2011> PIL.Image.Image : Load image file as RGB PIL Image Parameters ---------- path : Path Image file path Returns ------- return : Image.Image RGB PIL Image denormalize(tensor: torch.Tensor, mean: Tuple[float, ...] = None, std: Tuple[float, ...] = None) : Undoes mean/standard deviation normalization, zero to one scaling, and channel rearrangement for a batch of images. Parameters ---------- tensor : torch.Tensor A (CHANNELS x HEIGHT x WIDTH) tensor mean: Tuple[float, ...] A tuple of mean values to be subtracted from each image channel. std: Tuple[float, ...] A tuple of standard deviation values to be devided from each image channel. Returns ---------- array : numpy.ndarray[float] A (HEIGHT x WIDTH x CHANNELS) numpy array of floats get_first_batch(loader: Iterable, default: Optional[~Var] = None) \u2011> Optional[~Var] : Returns the first item in the given iterable or default if empty, meaningful mostly with 'for' expressions. Parameters ---------- loader : Iterable Dataloader to get the batch from. default: Any, optional Returned if ``loader`` is empty. Default = ``None``. Returns ------- batch : Any First batch from the dataloader. Default = ``None``. load_standard_test_imgs(directory: pathlib.Path = PosixPath('/home/dinize@acct.upmchs.net/playground/radio/imgs')) : plot(imgs: Union[torch.Tensor, radio.data.datatypes.Tensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor]], radio.data.datatypes.SeqSeqTensor], baseline_imgs: Union[torch.Tensor, radio.data.datatypes.Tensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor, Sequence[Union[torch.Tensor, radio.data.datatypes.Tensor]], radio.data.datatypes.SeqTensor]], radio.data.datatypes.SeqSeqTensor] = None, row_titles: List[str] = None, fig_title: str = None, **imshow_kwargs) \u2011> None : Plot images in a 2D grid. Arguments --------- imgs : Samples Collection of images to be plotted. Each element of ``imgs`` holds a row of the image grid to be plotted. baseline_imgs : Samples, Optional Collection of baseline images. If not ``None``, the first column of the grid will be filled with the baseline images. ``baseline_imgs`` is either a single image, or a collection of images of the same length of an element of ``imgs``. Default = ``None``. row_titles : List[str], Optional List of row titles. If not ``None``, ``len(row_title)`` must be equal to ``len(imgs)``. Default = ``None``. fig_title : str, Optional Figure title. Default = ``None``. plot_batch(batch: Dict, num_samples: int = 5, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, exclude_keys: Optional[List[str]] = None) \u2011> None : plot images and labels from a batch of images","title":"Functions"},{"location":"radio/data/datavisualization/","text":"Module radio.data.datavisualization Data related utilities. Functions plot_batch(batch: Dict[str, Any], num_samples: int = 5, random_samples: bool = True, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, exclude_keys: Optional[List[str]] = None) \u2011> None : plot images and labels from a batch of images plot_dataset(dataset: torchio.data.dataset.SubjectsDataset, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, exclude_keys: Optional[List[str]] = None) \u2011> None : plot images and labels from a dataset of subjects plot_subjects(subjects: List[torchio.data.subject.Subject], num_samples: int = 5, random_samples: bool = True, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, exclude_keys: Optional[List[str]] = None) \u2011> None : plot images and labels from a batch of images","title":"Datavisualization"},{"location":"radio/data/datavisualization/#module-radiodatadatavisualization","text":"Data related utilities.","title":"Module radio.data.datavisualization"},{"location":"radio/data/datavisualization/#functions","text":"plot_batch(batch: Dict[str, Any], num_samples: int = 5, random_samples: bool = True, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, exclude_keys: Optional[List[str]] = None) \u2011> None : plot images and labels from a batch of images plot_dataset(dataset: torchio.data.dataset.SubjectsDataset, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, exclude_keys: Optional[List[str]] = None) \u2011> None : plot images and labels from a dataset of subjects plot_subjects(subjects: List[torchio.data.subject.Subject], num_samples: int = 5, random_samples: bool = True, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, exclude_keys: Optional[List[str]] = None) \u2011> None : plot images and labels from a batch of images","title":"Functions"},{"location":"radio/data/validation/","text":"Module radio.data.validation Dataloaders are based on the PyTorch torch.utils.data.Dataloader data primitive. They are wrappers around torch.utils.data.Dataset that enable easy access to the dataset samples, i.e., they prepare your data for training/testing. Specifically, dataloaders are iterables that abstracts the complexity of retrieving \"minibatches\" from Datasets, reshuffling the data at every epoch to reduce model overfitting, use Python's multiprocessing to speed up data retrieval, and automatic memory pinning, in an easy API. Classes KFoldValidation(train_dataset: Union[torch.utils.data.dataset.Dataset, radio.data.dataset.BaseVisionDataset], val_dataset: Union[torch.utils.data.dataset.Dataset, radio.data.dataset.BaseVisionDataset] = None, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, collate_fn: Callable[[List[~Type]], Any] = None, pin_memory: bool = True, drop_last: bool = False, worker_init_fn: Callable[[int], None] = None, num_folds: int = 5, seed: int = 41) : Create train and validation dataloaders for K-Fold Cross-Validation. Parameters ---------- train_dataset : DatasetType Dataset from which to load the train data. val_dataset : DatasetType or None Dataset from which to load the validation data. If None, load the validation data from the train_dataset. ``val_dataset`` must be of the same size as ``train_dataset``. Default = None. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. collate_fn : Callable, optional Merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. worker_init_fn : Callable, optional If not ``None``, this will be called on each worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as input, after seeding and before data loading. Default = ``None``. num_folds : int, optional Number of folds. Must be at least ``2``. Default = ``5``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Methods `setup(self, val_split: Union[int, float] = 0.2) \u2011> None` : Creates train and validation collection of samplers. Parameters ---------- val_split: int or float, optional WARNING: val_split is not used in K-Fold validation. Left here just for compatibility with `OneFoldValidation`. Specify how the train_dataset should be split into train/validation datasets. Default = ``0.2``. `train_dataloader(self) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader], Sequence[Sequence[torch.utils.data.dataloader.DataLoader]], Sequence[Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, torch.utils.data.dataloader.DataLoader], Dict[str, Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, Sequence[torch.utils.data.dataloader.DataLoader]]]` : Generates one or multiple Pytorch DataLoaders for train. Parameters ---------- sampler : Sampler Sampler for validation samples. Returns ------- _ : Collection of DataLoader Collection of train dataloaders specifying training samples. `val_dataloader(self) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for validation. Parameters ---------- sampler : Sampler Sampler for validation samples. Returns ------- _ : Collection of DataLoader Collection of validation dataloaders specifying validation samples. OneFoldValidation(train_dataset: Union[torch.utils.data.dataset.Dataset, radio.data.dataset.BaseVisionDataset], val_dataset: Union[torch.utils.data.dataset.Dataset, radio.data.dataset.BaseVisionDataset] = None, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, collate_fn: Callable[[List[~Type]], Any] = None, pin_memory: bool = True, drop_last: bool = False, worker_init_fn: Callable[[int], None] = None, num_folds: int = 2, seed: int = 41) : Random split dataset into train and validation dataloaders. Parameters ---------- train_dataset : DatasetType Dataset from which to load the train data. val_dataset : DatasetType or None Dataset from which to load the validation data. If None, load the validation data from the train_dataset. ``val_dataset`` must be of the same size as ``train_dataset``. Default = None. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. collate_fn : Callable, optional Merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. worker_init_fn : Callable, optional If not ``None``, this will be called on each worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as input, after seeding and before data loading. Default = ``None``. num_folds : int, optional WARNING: ``num_folds`` shouldn't be set, it is hard-coded to ``2``. Parameter was only added for compatibility with KFoldValidation. Default = ``2``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Methods `setup(self, val_split: Union[int, float] = 0.2) \u2011> None` : Creates train and validation collection of samplers. Parameters ---------- val_split: int or float, optional Specify how the train_dataset should be split into train/validation datasets. Default = ``0.2``. `train_dataloader(self) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader], Sequence[Sequence[torch.utils.data.dataloader.DataLoader]], Sequence[Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, torch.utils.data.dataloader.DataLoader], Dict[str, Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, Sequence[torch.utils.data.dataloader.DataLoader]]]` : Generates one or multiple Pytorch DataLoaders for train. Returns ------- _ : Collection of DataLoader Collection of train dataloaders specifying training samples. `val_dataloader(self) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for validation. Returns ------- _ : Collection of DataLoaders Collection of validation dataloaders specifying validation samples.","title":"Validation"},{"location":"radio/data/validation/#module-radiodatavalidation","text":"Dataloaders are based on the PyTorch torch.utils.data.Dataloader data primitive. They are wrappers around torch.utils.data.Dataset that enable easy access to the dataset samples, i.e., they prepare your data for training/testing. Specifically, dataloaders are iterables that abstracts the complexity of retrieving \"minibatches\" from Datasets, reshuffling the data at every epoch to reduce model overfitting, use Python's multiprocessing to speed up data retrieval, and automatic memory pinning, in an easy API.","title":"Module radio.data.validation"},{"location":"radio/data/validation/#classes","text":"KFoldValidation(train_dataset: Union[torch.utils.data.dataset.Dataset, radio.data.dataset.BaseVisionDataset], val_dataset: Union[torch.utils.data.dataset.Dataset, radio.data.dataset.BaseVisionDataset] = None, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, collate_fn: Callable[[List[~Type]], Any] = None, pin_memory: bool = True, drop_last: bool = False, worker_init_fn: Callable[[int], None] = None, num_folds: int = 5, seed: int = 41) : Create train and validation dataloaders for K-Fold Cross-Validation. Parameters ---------- train_dataset : DatasetType Dataset from which to load the train data. val_dataset : DatasetType or None Dataset from which to load the validation data. If None, load the validation data from the train_dataset. ``val_dataset`` must be of the same size as ``train_dataset``. Default = None. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. collate_fn : Callable, optional Merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. worker_init_fn : Callable, optional If not ``None``, this will be called on each worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as input, after seeding and before data loading. Default = ``None``. num_folds : int, optional Number of folds. Must be at least ``2``. Default = ``5``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Methods `setup(self, val_split: Union[int, float] = 0.2) \u2011> None` : Creates train and validation collection of samplers. Parameters ---------- val_split: int or float, optional WARNING: val_split is not used in K-Fold validation. Left here just for compatibility with `OneFoldValidation`. Specify how the train_dataset should be split into train/validation datasets. Default = ``0.2``. `train_dataloader(self) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader], Sequence[Sequence[torch.utils.data.dataloader.DataLoader]], Sequence[Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, torch.utils.data.dataloader.DataLoader], Dict[str, Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, Sequence[torch.utils.data.dataloader.DataLoader]]]` : Generates one or multiple Pytorch DataLoaders for train. Parameters ---------- sampler : Sampler Sampler for validation samples. Returns ------- _ : Collection of DataLoader Collection of train dataloaders specifying training samples. `val_dataloader(self) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for validation. Parameters ---------- sampler : Sampler Sampler for validation samples. Returns ------- _ : Collection of DataLoader Collection of validation dataloaders specifying validation samples. OneFoldValidation(train_dataset: Union[torch.utils.data.dataset.Dataset, radio.data.dataset.BaseVisionDataset], val_dataset: Union[torch.utils.data.dataset.Dataset, radio.data.dataset.BaseVisionDataset] = None, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, collate_fn: Callable[[List[~Type]], Any] = None, pin_memory: bool = True, drop_last: bool = False, worker_init_fn: Callable[[int], None] = None, num_folds: int = 2, seed: int = 41) : Random split dataset into train and validation dataloaders. Parameters ---------- train_dataset : DatasetType Dataset from which to load the train data. val_dataset : DatasetType or None Dataset from which to load the validation data. If None, load the validation data from the train_dataset. ``val_dataset`` must be of the same size as ``train_dataset``. Default = None. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. collate_fn : Callable, optional Merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. worker_init_fn : Callable, optional If not ``None``, this will be called on each worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as input, after seeding and before data loading. Default = ``None``. num_folds : int, optional WARNING: ``num_folds`` shouldn't be set, it is hard-coded to ``2``. Parameter was only added for compatibility with KFoldValidation. Default = ``2``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Methods `setup(self, val_split: Union[int, float] = 0.2) \u2011> None` : Creates train and validation collection of samplers. Parameters ---------- val_split: int or float, optional Specify how the train_dataset should be split into train/validation datasets. Default = ``0.2``. `train_dataloader(self) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader], Sequence[Sequence[torch.utils.data.dataloader.DataLoader]], Sequence[Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, torch.utils.data.dataloader.DataLoader], Dict[str, Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, Sequence[torch.utils.data.dataloader.DataLoader]]]` : Generates one or multiple Pytorch DataLoaders for train. Returns ------- _ : Collection of DataLoader Collection of train dataloaders specifying training samples. `val_dataloader(self) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for validation. Returns ------- _ : Collection of DataLoaders Collection of validation dataloaders specifying validation samples.","title":"Classes"},{"location":"radio/data/visiondatamodule/","text":"Module radio.data.visiondatamodule Based on LightningDataModule for managing data. A datamodule is a shareable, reusable class that encapsulates all the steps needed to process data, i.e., decoupling datasets from models to allow building dataset-agnostic models. They also allow you to share a full dataset without explaining how to download, split, transform, and process the data. Classes VisionDataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/home/dinize@acct.upmchs.net/playground/radio/dataset'), train_transforms: Optional[torchio.transforms.transform.Transform] = None, val_transforms: Optional[torchio.transforms.transform.Transform] = None, test_transforms: Optional[torchio.transforms.transform.Transform] = None, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, seed: int = 41, **kwargs: Any) : Base class For making datasets which are compatible with torchvision. To create a subclass, you need to implement the following functions: A VisionDataModule needs to implement 2 key methods + an optional __init__: <__init__>: (Optionally) Initialize the class, first call super.__init__(). <default_transforms>: Default transforms to use in lieu of train_transforms, val_transforms, or test_transforms. <teardown>: Things to do on every accelerator in distributed mode when finished. Typical Workflow ---------------- data = VisionDataModule() data.prepare_data() # download data.setup(stage) # process and split data.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root directory of dataset. Default = ``DATA_ROOT``. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split: int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Ancestors (in MRO) * radio.data.basedatamodule.BaseDataModule * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Descendants * radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule * radio.data.datamodules.klu_apc2.KLUAPC2DataModule * radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule ### Static methods `get_max_shape(subjects: List[torchio.data.subject.Subject]) \u2011> Tuple[int, int, int]` : Get max height, width, and depth accross all subjects. Parameters ---------- subjects : List[tio.Subject] List of TorchIO Subject objects. Returns ------- shapes_tuple : Tuple[int, int, int] Max height, width and depth across all subjects. `size_eval_dataset(eval_dataset: Sized) \u2011> Union[int, Sequence[int]]` : Compute the size of the test or validation datasets. Parameters ---------- eval_dataset: EvalDatasetType Collection of test or validation datasets. Returns ------- _ : EvalSizeType Collection of test or validation datasets' sizes. `size_train_dataset(train_dataset: Sized) \u2011> Union[int, Sequence[int], Sequence[Sequence[int]], Sequence[Dict[str, int]], Dict[str, int], Dict[str, Dict[str, int]], Dict[str, Sequence[int]]]` : Compute the size of the train datasets. Parameters ---------- train_dataset: TrainDatasetType Collection of train datasets. Returns ------- _ : TrainSizeType Collection of train datasets' sizes. ### Methods `check_if_data_split(self, stem: str = '') \u2011> None` : Check if data is splitted in train, test and val folders `dataloader(self, dataset: Union[torch.utils.data.dataset.Dataset, radio.data.dataset.BaseVisionDataset], batch_size: Optional[int] = None, shuffle: Optional[bool] = None, num_workers: Optional[int] = None, pin_memory: Optional[bool] = None, drop_last: Optional[bool] = None) \u2011> torch.utils.data.dataloader.DataLoader` : Instantiate a DataLoader. Parameters ---------- batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. Returns ------- _ : DataLoader `default_transforms(self, stage: Optional[str] = None) \u2011> Callable` : Default transforms and augmentations for the dataset. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = None, set-up all stages. Default = None. Returns ------- _: Callable All preprocessing steps (and if ``'fit'``, augmentation steps too) that should be applied to the images. `predict_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Implement one or multiple PyTorch DataLoaders for prediction. It's recommended that all data downloads and preparation happen in :meth:`prepare_data`. - :meth:`~pytorch_lightning.trainer.Trainer.fit` - ... - :meth:`prepare_data` - :meth:`train_dataloader` - :meth:`val_dataloader` - :meth:`test_dataloader` Note: Lightning adds the correct sampler for distributed and arbitrary hardware There is no need to set it yourself. Return: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying prediction samples. Note: In the case where you return multiple prediction dataloaders, the :meth:`predict` will have an argument ``dataloader_idx`` which matches the order here. `prepare_data(self, *args: Any, **kwargs: Any) \u2011> None` : Saves files to data root dir. Verify data directory exists. Verify if test/train/val splitted. `setup(self, stage: Optional[str] = None) \u2011> None` : Creates train, validation and test collection of samplers. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = None, set-up all stages. Default = None. `teardown(self, stage: Optional[str] = None) \u2011> None` : Called at the end of fit (train + validate), validate, test, or predict. Remove root directory if a temporary was used. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = None, set-up all stages. Default = None. `test_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for test. Returns ------- _ : Collection of DataLoaders Collection of test dataloaders specifying test samples. `train_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader], Sequence[Sequence[torch.utils.data.dataloader.DataLoader]], Sequence[Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, torch.utils.data.dataloader.DataLoader], Dict[str, Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, Sequence[torch.utils.data.dataloader.DataLoader]]]` : Generates one or multiple Pytorch DataLoaders for train. Returns ------- _ : Collection of DataLoader Collection of train dataloaders specifying training samples. `val_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for validation. Returns ------- _ : Collection of DataLoader Collection of validation dataloaders specifying validation samples.","title":"Visiondatamodule"},{"location":"radio/data/visiondatamodule/#module-radiodatavisiondatamodule","text":"Based on LightningDataModule for managing data. A datamodule is a shareable, reusable class that encapsulates all the steps needed to process data, i.e., decoupling datasets from models to allow building dataset-agnostic models. They also allow you to share a full dataset without explaining how to download, split, transform, and process the data.","title":"Module radio.data.visiondatamodule"},{"location":"radio/data/visiondatamodule/#classes","text":"VisionDataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/home/dinize@acct.upmchs.net/playground/radio/dataset'), train_transforms: Optional[torchio.transforms.transform.Transform] = None, val_transforms: Optional[torchio.transforms.transform.Transform] = None, test_transforms: Optional[torchio.transforms.transform.Transform] = None, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, seed: int = 41, **kwargs: Any) : Base class For making datasets which are compatible with torchvision. To create a subclass, you need to implement the following functions: A VisionDataModule needs to implement 2 key methods + an optional __init__: <__init__>: (Optionally) Initialize the class, first call super.__init__(). <default_transforms>: Default transforms to use in lieu of train_transforms, val_transforms, or test_transforms. <teardown>: Things to do on every accelerator in distributed mode when finished. Typical Workflow ---------------- data = VisionDataModule() data.prepare_data() # download data.setup(stage) # process and split data.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root directory of dataset. Default = ``DATA_ROOT``. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split: int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Ancestors (in MRO) * radio.data.basedatamodule.BaseDataModule * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Descendants * radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule * radio.data.datamodules.klu_apc2.KLUAPC2DataModule * radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule ### Static methods `get_max_shape(subjects: List[torchio.data.subject.Subject]) \u2011> Tuple[int, int, int]` : Get max height, width, and depth accross all subjects. Parameters ---------- subjects : List[tio.Subject] List of TorchIO Subject objects. Returns ------- shapes_tuple : Tuple[int, int, int] Max height, width and depth across all subjects. `size_eval_dataset(eval_dataset: Sized) \u2011> Union[int, Sequence[int]]` : Compute the size of the test or validation datasets. Parameters ---------- eval_dataset: EvalDatasetType Collection of test or validation datasets. Returns ------- _ : EvalSizeType Collection of test or validation datasets' sizes. `size_train_dataset(train_dataset: Sized) \u2011> Union[int, Sequence[int], Sequence[Sequence[int]], Sequence[Dict[str, int]], Dict[str, int], Dict[str, Dict[str, int]], Dict[str, Sequence[int]]]` : Compute the size of the train datasets. Parameters ---------- train_dataset: TrainDatasetType Collection of train datasets. Returns ------- _ : TrainSizeType Collection of train datasets' sizes. ### Methods `check_if_data_split(self, stem: str = '') \u2011> None` : Check if data is splitted in train, test and val folders `dataloader(self, dataset: Union[torch.utils.data.dataset.Dataset, radio.data.dataset.BaseVisionDataset], batch_size: Optional[int] = None, shuffle: Optional[bool] = None, num_workers: Optional[int] = None, pin_memory: Optional[bool] = None, drop_last: Optional[bool] = None) \u2011> torch.utils.data.dataloader.DataLoader` : Instantiate a DataLoader. Parameters ---------- batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. Returns ------- _ : DataLoader `default_transforms(self, stage: Optional[str] = None) \u2011> Callable` : Default transforms and augmentations for the dataset. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = None, set-up all stages. Default = None. Returns ------- _: Callable All preprocessing steps (and if ``'fit'``, augmentation steps too) that should be applied to the images. `predict_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Implement one or multiple PyTorch DataLoaders for prediction. It's recommended that all data downloads and preparation happen in :meth:`prepare_data`. - :meth:`~pytorch_lightning.trainer.Trainer.fit` - ... - :meth:`prepare_data` - :meth:`train_dataloader` - :meth:`val_dataloader` - :meth:`test_dataloader` Note: Lightning adds the correct sampler for distributed and arbitrary hardware There is no need to set it yourself. Return: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying prediction samples. Note: In the case where you return multiple prediction dataloaders, the :meth:`predict` will have an argument ``dataloader_idx`` which matches the order here. `prepare_data(self, *args: Any, **kwargs: Any) \u2011> None` : Saves files to data root dir. Verify data directory exists. Verify if test/train/val splitted. `setup(self, stage: Optional[str] = None) \u2011> None` : Creates train, validation and test collection of samplers. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = None, set-up all stages. Default = None. `teardown(self, stage: Optional[str] = None) \u2011> None` : Called at the end of fit (train + validate), validate, test, or predict. Remove root directory if a temporary was used. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = None, set-up all stages. Default = None. `test_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for test. Returns ------- _ : Collection of DataLoaders Collection of test dataloaders specifying test samples. `train_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader], Sequence[Sequence[torch.utils.data.dataloader.DataLoader]], Sequence[Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, torch.utils.data.dataloader.DataLoader], Dict[str, Dict[str, torch.utils.data.dataloader.DataLoader]], Dict[str, Sequence[torch.utils.data.dataloader.DataLoader]]]` : Generates one or multiple Pytorch DataLoaders for train. Returns ------- _ : Collection of DataLoader Collection of train dataloaders specifying training samples. `val_dataloader(self, *args: Any, **kwargs: Any) \u2011> Union[torch.utils.data.dataloader.DataLoader, Sequence[torch.utils.data.dataloader.DataLoader]]` : Generates one or multiple Pytorch DataLoaders for validation. Returns ------- _ : Collection of DataLoader Collection of validation dataloaders specifying validation samples.","title":"Classes"},{"location":"radio/data/datamodules/","text":"Module radio.data.datamodules Data Modules init Sub-modules radio.data.datamodules.brain_aging_prediction radio.data.datamodules.brain_aging_prediction_patch radio.data.datamodules.klu_apc2 radio.data.datamodules.medical_decathlon","title":"Index"},{"location":"radio/data/datamodules/#module-radiodatadatamodules","text":"Data Modules init","title":"Module radio.data.datamodules"},{"location":"radio/data/datamodules/#sub-modules","text":"radio.data.datamodules.brain_aging_prediction radio.data.datamodules.brain_aging_prediction_patch radio.data.datamodules.klu_apc2 radio.data.datamodules.medical_decathlon","title":"Sub-modules"},{"location":"radio/data/datamodules/brain_aging_prediction/","text":"Module radio.data.datamodules.brain_aging_prediction Brain Aging Prediction Data Module Classes BrainAgingPredictionDataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/media/cerebro/Studies'), study: str = 'Brain_Aging_Prediction', data_dir: str = 'Public/data', step: str = 'step01_structural_processing', train_transforms: Optional[torchio.transforms.transform.Transform] = None, val_transforms: Optional[torchio.transforms.transform.Transform] = None, test_transforms: Optional[torchio.transforms.transform.Transform] = None, use_augmentation: bool = True, use_preprocessing: bool = True, resample: bool = False, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, dims: Tuple[int, int, int] = (160, 192, 160), seed: int = 41, verbose: bool = False, **kwargs: Any) : Brain Aging Prediction Data Module. Typical Workflow ---------------- data = BrainAgingPredictionDataModule() data.prepare_data() # download data.setup(stage) # process and split data.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root to GPN's CEREBRO Studies folder. Default = ``'/media/cerebro/Studies'``. study : str, optional Study name. Default = ``'Brain_Aging_Prediction'``. data_dir : str, optional Subdirectory where the data is located. Default = ``'Public/data'``. step : str, optional Which processing step to use. Default = ``'step01_structural_processing'``. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. use_augmentation : bool, optional If ``True``, augment samples during the ``fit`` stage. Default = ``True``. use_preprocessing : bool, optional If ``True``, preprocess samples. Default = ``True``. resample : bool, optional If ``True``, resample all images to ``'T1'``. Default = ``False``. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split : int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. intensities : List[str], optional Which intensities to load. Default = ``['T1']``. labels : List[str], optional Which labels to load. Default = ``[]``. dims : Tuple[int, int, int], optional Max spatial dimensions across subjects' images. If ``None``, compute dimensions from dataset. Default = ``(160, 192, 160)``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. verbose : bool, optional If ``True``, print debugging messages. Default = ``False``. ### Ancestors (in MRO) * radio.data.visiondatamodule.VisionDataModule * radio.data.basedatamodule.BaseDataModule * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Descendants * radio.data.datamodules.brain_aging_prediction_patch.BrainAgingPredictionPatchDataModule ### Class variables `intensity2template` : `label2template: Dict[str, string.Template]` : ### Static methods `get_augmentation_transforms() \u2011> torchio.transforms.transform.Transform` : \" Get augmentation transorms to apply to subjects during training. Returns ------- augment : tio.Transform All augmentation steps that should be applied to subjects during training. `get_paths(data_root: Union[str, pathlib.Path], stem: str = 'step01_structural_processing', has_train_test_split: bool = False, has_train_val_split: bool = False, test_split: Union[int, float] = 0.2, shuffle: bool = True, seed: int = 41) \u2011> Tuple[collections.OrderedDict[Tuple[str, str], pathlib.Path], collections.OrderedDict[Tuple[str, str], pathlib.Path], collections.OrderedDict[Tuple[str, str], pathlib.Path]]` : Get subject and scan IDs and the respective paths from the study data directory. Returns ------- _ : {(str, str): Path}, {(str, str): Path}, {(str, str): Path} Paths for respectively, train, test and images and labels. ### Methods `default_transforms(self, stage: Optional[str] = None) \u2011> torchio.transforms.transform.Transform` : Default transforms and augmentations for the dataset. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, ``'test'``, or ``'predict'``. If stage = None, set-up all stages. Default = None. Returns ------- _: tio.Transform All preprocessing steps (and if ``'fit'``, augmentation steps too) that should be applied to the subjects. `get_preprocessing_transforms(self, shape: Optional[Tuple[int, int, int]] = None, resample: bool = False) \u2011> torchio.transforms.transform.Transform` : Get preprocessing transorms to apply to all subjects. Returns ------- preprocess : tio.Transform All preprocessing steps that should be applied to all subjects. `get_subjects(self, fold: str = 'train') \u2011> List[torchio.data.subject.Subject]` : Get train, test, or val list of TorchIO Subjects. Parameters ---------- fold : str, optional Identify which type of dataset, ``'train'``, ``'test'``, or ``'val'``. Default = ``'train'``. Returns ------- _ : List[tio.Subject] Train, test or val list of TorchIO Subjects. `get_subjects_dicts(self, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None) \u2011> Tuple[collections.OrderedDict[Tuple[str, str], collections.OrderedDict[str, Any]], collections.OrderedDict[Tuple[str, str], collections.OrderedDict[str, Any]], collections.OrderedDict[Tuple[str, str], collections.OrderedDict[str, Any]]]` : Get paths to nii files for train/test/val images and labels. Returns ------- _ : {(str, str): Dict}, {(str, str): Dict}, {(str, str): Dict} Paths to, respectively, train, test, and val images and labels. `prepare_data(self, *args: Any, **kwargs: Any) \u2011> None` : Verify data directory exists and if test/train/val splitted. `save(self, dataloader: torch.utils.data.dataloader.DataLoader, root: Union[str, pathlib.Path] = PosixPath('/media/cerebro/Workspaces/Students/Eduardo_Diniz/Studies'), data_dir: str = 'processed_data', step: str = 'step01_structural_processing', fold: str = 'train') \u2011> None` : Arguments --------- root : Path or str, optional Root where to save data. Default = ``'~/LocalCerebro'``. `setup(self, stage: Optional[str] = None) \u2011> None` : Creates train, validation and test collection of samplers. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = ``None``, set-up all stages. Default = ``None``.","title":"Brain aging prediction"},{"location":"radio/data/datamodules/brain_aging_prediction/#module-radiodatadatamodulesbrain_aging_prediction","text":"Brain Aging Prediction Data Module","title":"Module radio.data.datamodules.brain_aging_prediction"},{"location":"radio/data/datamodules/brain_aging_prediction/#classes","text":"BrainAgingPredictionDataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/media/cerebro/Studies'), study: str = 'Brain_Aging_Prediction', data_dir: str = 'Public/data', step: str = 'step01_structural_processing', train_transforms: Optional[torchio.transforms.transform.Transform] = None, val_transforms: Optional[torchio.transforms.transform.Transform] = None, test_transforms: Optional[torchio.transforms.transform.Transform] = None, use_augmentation: bool = True, use_preprocessing: bool = True, resample: bool = False, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, dims: Tuple[int, int, int] = (160, 192, 160), seed: int = 41, verbose: bool = False, **kwargs: Any) : Brain Aging Prediction Data Module. Typical Workflow ---------------- data = BrainAgingPredictionDataModule() data.prepare_data() # download data.setup(stage) # process and split data.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root to GPN's CEREBRO Studies folder. Default = ``'/media/cerebro/Studies'``. study : str, optional Study name. Default = ``'Brain_Aging_Prediction'``. data_dir : str, optional Subdirectory where the data is located. Default = ``'Public/data'``. step : str, optional Which processing step to use. Default = ``'step01_structural_processing'``. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. use_augmentation : bool, optional If ``True``, augment samples during the ``fit`` stage. Default = ``True``. use_preprocessing : bool, optional If ``True``, preprocess samples. Default = ``True``. resample : bool, optional If ``True``, resample all images to ``'T1'``. Default = ``False``. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split : int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. intensities : List[str], optional Which intensities to load. Default = ``['T1']``. labels : List[str], optional Which labels to load. Default = ``[]``. dims : Tuple[int, int, int], optional Max spatial dimensions across subjects' images. If ``None``, compute dimensions from dataset. Default = ``(160, 192, 160)``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. verbose : bool, optional If ``True``, print debugging messages. Default = ``False``. ### Ancestors (in MRO) * radio.data.visiondatamodule.VisionDataModule * radio.data.basedatamodule.BaseDataModule * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Descendants * radio.data.datamodules.brain_aging_prediction_patch.BrainAgingPredictionPatchDataModule ### Class variables `intensity2template` : `label2template: Dict[str, string.Template]` : ### Static methods `get_augmentation_transforms() \u2011> torchio.transforms.transform.Transform` : \" Get augmentation transorms to apply to subjects during training. Returns ------- augment : tio.Transform All augmentation steps that should be applied to subjects during training. `get_paths(data_root: Union[str, pathlib.Path], stem: str = 'step01_structural_processing', has_train_test_split: bool = False, has_train_val_split: bool = False, test_split: Union[int, float] = 0.2, shuffle: bool = True, seed: int = 41) \u2011> Tuple[collections.OrderedDict[Tuple[str, str], pathlib.Path], collections.OrderedDict[Tuple[str, str], pathlib.Path], collections.OrderedDict[Tuple[str, str], pathlib.Path]]` : Get subject and scan IDs and the respective paths from the study data directory. Returns ------- _ : {(str, str): Path}, {(str, str): Path}, {(str, str): Path} Paths for respectively, train, test and images and labels. ### Methods `default_transforms(self, stage: Optional[str] = None) \u2011> torchio.transforms.transform.Transform` : Default transforms and augmentations for the dataset. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, ``'test'``, or ``'predict'``. If stage = None, set-up all stages. Default = None. Returns ------- _: tio.Transform All preprocessing steps (and if ``'fit'``, augmentation steps too) that should be applied to the subjects. `get_preprocessing_transforms(self, shape: Optional[Tuple[int, int, int]] = None, resample: bool = False) \u2011> torchio.transforms.transform.Transform` : Get preprocessing transorms to apply to all subjects. Returns ------- preprocess : tio.Transform All preprocessing steps that should be applied to all subjects. `get_subjects(self, fold: str = 'train') \u2011> List[torchio.data.subject.Subject]` : Get train, test, or val list of TorchIO Subjects. Parameters ---------- fold : str, optional Identify which type of dataset, ``'train'``, ``'test'``, or ``'val'``. Default = ``'train'``. Returns ------- _ : List[tio.Subject] Train, test or val list of TorchIO Subjects. `get_subjects_dicts(self, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None) \u2011> Tuple[collections.OrderedDict[Tuple[str, str], collections.OrderedDict[str, Any]], collections.OrderedDict[Tuple[str, str], collections.OrderedDict[str, Any]], collections.OrderedDict[Tuple[str, str], collections.OrderedDict[str, Any]]]` : Get paths to nii files for train/test/val images and labels. Returns ------- _ : {(str, str): Dict}, {(str, str): Dict}, {(str, str): Dict} Paths to, respectively, train, test, and val images and labels. `prepare_data(self, *args: Any, **kwargs: Any) \u2011> None` : Verify data directory exists and if test/train/val splitted. `save(self, dataloader: torch.utils.data.dataloader.DataLoader, root: Union[str, pathlib.Path] = PosixPath('/media/cerebro/Workspaces/Students/Eduardo_Diniz/Studies'), data_dir: str = 'processed_data', step: str = 'step01_structural_processing', fold: str = 'train') \u2011> None` : Arguments --------- root : Path or str, optional Root where to save data. Default = ``'~/LocalCerebro'``. `setup(self, stage: Optional[str] = None) \u2011> None` : Creates train, validation and test collection of samplers. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, or ``'test'``. If stage = ``None``, set-up all stages. Default = ``None``.","title":"Classes"},{"location":"radio/data/datamodules/brain_aging_prediction_patch/","text":"Module radio.data.datamodules.brain_aging_prediction_patch Based on BaseDataModule for managing data. A vision datamodule that is shareable, reusable class that encapsulates all the steps needed to process data, i.e., decoupling datasets from models to allow building dataset-agnostic models. They also allow you to share a full dataset without explaining how to download, split, transform, and process the data. Classes BrainAgingPredictionPatchDataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/media/cerebro'), study: str = 'Brain_Aging_Prediction', data_dir: str = 'Public/data', step: str = 'step01_structural_processing', train_transforms: Optional[torchio.transforms.transform.Transform] = None, val_transforms: Optional[torchio.transforms.transform.Transform] = None, test_transforms: Optional[torchio.transforms.transform.Transform] = None, use_augmentation: bool = True, use_preprocessing: bool = True, resample: bool = False, patch_size: Union[int, Tuple[int, int, int]] = 96, probability_map: Optional[str] = None, label_name: Optional[str] = None, label_probabilities: Optional[Dict[int, float]] = None, queue_max_length: int = 256, samples_per_volume: int = 16, batch_size: int = 32, shuffle_subjects: bool = True, shuffle_patches: bool = True, num_workers: int = 0, pin_memory: bool = True, start_background: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, dims: Tuple[int, int, int] = (160, 192, 160), seed: int = 41, verbose: bool = False, **kwargs: Any) : Base class For making patch-based datasets which are compatible with torchvision. To create a subclass, you need to implement the following functions: A VisionPatchDataModule needs to implement 2 key methods + an optional __init__: <__init__>: (Optionally) Initialize the class, first call super.__init__(). <default_transforms>: Default transforms to use in lieu of train_transforms, val_transforms, or test_transforms. <teardown>: Things to do on every accelerator in distributed mode when finished. Typical Workflow ---------------- data = VisionPatchDataModule() data.prepare_data() # download data.setup(stage) # process and split data.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root to GPN's CEREBRO Studies folder. Default = ``'/media/cerebro/Studies'``. study : str, optional Study name. Default = ``'Brain_Aging_Prediction'``. data_dir : str, optional Subdirectory where the data is located. Default = ``'Public/data'``. step : str, optional Which processing step to use. Default = ``'step01_structural_processing'``. patch_size : int or (int, int, int) Tuple of integers ``(w, h, d)`` to generate patches of size ``w x h x d``. If a single number ``n`` is provided, ``w = h = d = n``. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. use_augmentation : bool, optional If ``True``, augment samples during the ``fit`` stage. Default = ``True``. use_preprocessing : bool, optional If ``True``, preprocess samples. Default = ``True``. resample : bool, optional If ``True``, resample all images to ``'T1'``. Default = ``False``. probability_map : str, optional Name of the image in the input subject that will be used as a sampling probability map. The probability of sampling a patch centered on a specific voxel is the value of that voxel in the probability map. The probabilities need not be normalized. For example, voxels can have values 0, 1 and 5. Voxels with value 0 will never be at the center of a patch. Voxels with value 5 will have 5 times more chance of being at the center of a patch that voxels with a value of 1. If ``None``, uniform sampling is used. Default = ``None``. label_name : str, optional Name of the label image in the subject that will be used to generate the sampling probability map. If ``None`` and ``probability_map`` is ``None``, the first image of type ``torchio.LABEL`` found in the subject subject will be used. If ``probability_map`` is not ``None``, then ``label_name`` and ``label_probability`` are ignored. Default = ``None``. label_probabilities : Dict[int, float], optional Dictionary containing the probability that each class will be sampled. Probabilities do not need to be normalized. For example, a value of {0: 0, 1: 2, 2: 1, 3: 1} will create a sampler whose patches centers will have 50% probability of being labeled as 1, 25% of being 2 and 25% of being 3. If None, the label map is binarized and the value is set to {0: 0, 1: 1}. If the input has multiple channels, a value of {0: 0, 1: 2, 2: 1, 3: 1} will create a sampler whose patches centers will have 50% probability of being taken from a non zero value of channel 1, 25% from channel 2 and 25% from channel 3. If ``probability_map`` is not ``None``, then ``label_name`` and ``label_probability`` are ignored. Default = ``None``. queue_max_length : int, optional Maximum number of patches that can be stored in the queue. Using a large number means that the queue needs to be filled less often, but more CPU memory is needed to store the patches. Default = ``256``. samples_per_volume : int, optional Number of patches to extract from each volume. A small number of patches ensures a large variability in the queue, but training will be slower. Default = ``16``. batch_size : int, optional How many patches per batch to load. Default = ``32``. shuffle_subjects : bool, optional Whether to shuffle the subjects dataset at the beginning of every epoch (an epoch ends when all the patches from all the subjects have been processed). Default = ``True``. shuffle_patches : bool, optional Whether to shuffle the patches queue at the beginning of every epoch. Default = ``True``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. start_background : bool, optional If ``True``, the loader will start working in the background as soon as the queues are instantiated. Default = ``True``. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split: int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. intensities : List[str], optional Which intensities to load. Default = ``['T1']``. labels : List[str], optional Which labels to load. Default = ``[]``. dims : Tuple[int, int, int], optional Max spatial dimensions across subjects' images. If ``None``, compute dimensions from dataset. Default = ``(160, 192, 160)``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. verbose : bool, optional If ``True``, print debugging messages. Default = ``False``. ### Ancestors (in MRO) * radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule * radio.data.visiondatamodule.VisionDataModule * radio.data.basedatamodule.BaseDataModule * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Class variables `intensity2template` : `label2template: Dict[str, string.Template]` :","title":"Brain aging prediction patch"},{"location":"radio/data/datamodules/brain_aging_prediction_patch/#module-radiodatadatamodulesbrain_aging_prediction_patch","text":"Based on BaseDataModule for managing data. A vision datamodule that is shareable, reusable class that encapsulates all the steps needed to process data, i.e., decoupling datasets from models to allow building dataset-agnostic models. They also allow you to share a full dataset without explaining how to download, split, transform, and process the data.","title":"Module radio.data.datamodules.brain_aging_prediction_patch"},{"location":"radio/data/datamodules/brain_aging_prediction_patch/#classes","text":"BrainAgingPredictionPatchDataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/media/cerebro'), study: str = 'Brain_Aging_Prediction', data_dir: str = 'Public/data', step: str = 'step01_structural_processing', train_transforms: Optional[torchio.transforms.transform.Transform] = None, val_transforms: Optional[torchio.transforms.transform.Transform] = None, test_transforms: Optional[torchio.transforms.transform.Transform] = None, use_augmentation: bool = True, use_preprocessing: bool = True, resample: bool = False, patch_size: Union[int, Tuple[int, int, int]] = 96, probability_map: Optional[str] = None, label_name: Optional[str] = None, label_probabilities: Optional[Dict[int, float]] = None, queue_max_length: int = 256, samples_per_volume: int = 16, batch_size: int = 32, shuffle_subjects: bool = True, shuffle_patches: bool = True, num_workers: int = 0, pin_memory: bool = True, start_background: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, dims: Tuple[int, int, int] = (160, 192, 160), seed: int = 41, verbose: bool = False, **kwargs: Any) : Base class For making patch-based datasets which are compatible with torchvision. To create a subclass, you need to implement the following functions: A VisionPatchDataModule needs to implement 2 key methods + an optional __init__: <__init__>: (Optionally) Initialize the class, first call super.__init__(). <default_transforms>: Default transforms to use in lieu of train_transforms, val_transforms, or test_transforms. <teardown>: Things to do on every accelerator in distributed mode when finished. Typical Workflow ---------------- data = VisionPatchDataModule() data.prepare_data() # download data.setup(stage) # process and split data.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root to GPN's CEREBRO Studies folder. Default = ``'/media/cerebro/Studies'``. study : str, optional Study name. Default = ``'Brain_Aging_Prediction'``. data_dir : str, optional Subdirectory where the data is located. Default = ``'Public/data'``. step : str, optional Which processing step to use. Default = ``'step01_structural_processing'``. patch_size : int or (int, int, int) Tuple of integers ``(w, h, d)`` to generate patches of size ``w x h x d``. If a single number ``n`` is provided, ``w = h = d = n``. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. use_augmentation : bool, optional If ``True``, augment samples during the ``fit`` stage. Default = ``True``. use_preprocessing : bool, optional If ``True``, preprocess samples. Default = ``True``. resample : bool, optional If ``True``, resample all images to ``'T1'``. Default = ``False``. probability_map : str, optional Name of the image in the input subject that will be used as a sampling probability map. The probability of sampling a patch centered on a specific voxel is the value of that voxel in the probability map. The probabilities need not be normalized. For example, voxels can have values 0, 1 and 5. Voxels with value 0 will never be at the center of a patch. Voxels with value 5 will have 5 times more chance of being at the center of a patch that voxels with a value of 1. If ``None``, uniform sampling is used. Default = ``None``. label_name : str, optional Name of the label image in the subject that will be used to generate the sampling probability map. If ``None`` and ``probability_map`` is ``None``, the first image of type ``torchio.LABEL`` found in the subject subject will be used. If ``probability_map`` is not ``None``, then ``label_name`` and ``label_probability`` are ignored. Default = ``None``. label_probabilities : Dict[int, float], optional Dictionary containing the probability that each class will be sampled. Probabilities do not need to be normalized. For example, a value of {0: 0, 1: 2, 2: 1, 3: 1} will create a sampler whose patches centers will have 50% probability of being labeled as 1, 25% of being 2 and 25% of being 3. If None, the label map is binarized and the value is set to {0: 0, 1: 1}. If the input has multiple channels, a value of {0: 0, 1: 2, 2: 1, 3: 1} will create a sampler whose patches centers will have 50% probability of being taken from a non zero value of channel 1, 25% from channel 2 and 25% from channel 3. If ``probability_map`` is not ``None``, then ``label_name`` and ``label_probability`` are ignored. Default = ``None``. queue_max_length : int, optional Maximum number of patches that can be stored in the queue. Using a large number means that the queue needs to be filled less often, but more CPU memory is needed to store the patches. Default = ``256``. samples_per_volume : int, optional Number of patches to extract from each volume. A small number of patches ensures a large variability in the queue, but training will be slower. Default = ``16``. batch_size : int, optional How many patches per batch to load. Default = ``32``. shuffle_subjects : bool, optional Whether to shuffle the subjects dataset at the beginning of every epoch (an epoch ends when all the patches from all the subjects have been processed). Default = ``True``. shuffle_patches : bool, optional Whether to shuffle the patches queue at the beginning of every epoch. Default = ``True``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. start_background : bool, optional If ``True``, the loader will start working in the background as soon as the queues are instantiated. Default = ``True``. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split: int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. intensities : List[str], optional Which intensities to load. Default = ``['T1']``. labels : List[str], optional Which labels to load. Default = ``[]``. dims : Tuple[int, int, int], optional Max spatial dimensions across subjects' images. If ``None``, compute dimensions from dataset. Default = ``(160, 192, 160)``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. verbose : bool, optional If ``True``, print debugging messages. Default = ``False``. ### Ancestors (in MRO) * radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule * radio.data.visiondatamodule.VisionDataModule * radio.data.basedatamodule.BaseDataModule * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Class variables `intensity2template` : `label2template: Dict[str, string.Template]` :","title":"Classes"},{"location":"radio/data/datamodules/klu_apc2/","text":"Module radio.data.datamodules.klu_apc2 KLU_APC2 Data Module Functions plot_klu(batch: dict, num_imgs: int = 5, slice_num: int = 150, train: bool = True) \u2011> None : plot images and labels from a batch of train images Classes KLUAPC2DataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/media/cerebro/Studies/KLU_APC2/Public/Analysis/data'), step: str = 'step02_structural_processing', train_transforms: Optional[Callable] = None, val_transforms: Optional[Callable] = None, test_transforms: Optional[Callable] = None, use_augmentation: bool = True, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, modalities: List[str] = ['T1w', 'FLAIR', 'T2w'], labels: List[str] = ['WMH'], dims: List[int] = [256, 256, 256], seed: int = 41, **kwargs: Any) : KLU APC2 Data Module. Typical Workflow ---------------- klu = KLUAPC2DataModule() klu.prepare_data() # download klu.setup(stage) # process and split klu.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root directory of dataset. Default = ``''/media/cerebro/Studies/KLU_APC2/Public/Analysis/data''``. step : str, optional Which processing step to use. Default = ``''step02_structural_processing''``. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. use_augmentation : bool, optional If ``True``, augment samples during the ``fit`` stage. Default = ``True``. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split : int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. dims : List[int], optional Max spatial dimensions across subjects' images. Default = ``[320, 256, 256]``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Ancestors (in MRO) * radio.data.visiondatamodule.VisionDataModule * radio.data.basedatamodule.BaseDataModule * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Static methods `get_augmentation_transforms() \u2011> Callable` : \" Get augmentation transorms to apply to subjects during training. Returns ------- augment : tio.Compose All augmentation steps that should be applied to subjects during training. `split_dict(dictionary: collections.OrderedDict, test_split: Union[int, float] = 0.2, shuffle: bool = True) \u2011> Tuple[collections.OrderedDict, collections.OrderedDict]` : Split dict into two. ### Methods `default_transforms(self, stage: Optional[str] = None) \u2011> Callable` : Default transforms and augmentations for the dataset. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, ``'test'``, or ``'predict'``. If stage = None, set-up all stages. Default = None. Returns ------- _: Callable All preprocessing steps (and if ``'fit'``, augmentation steps too) that should be applied to the subjects. `get_max_shape(self, subjects: List[torchio.data.subject.Subject]) \u2011> List[int]` : Get max shape. Parameters ---------- subjects : List[tio.Subject] List of TorchIO Subject objects. Returns ------- _ : np.ndarray((1, 3), np.int_) Max height, width and depth across all subjects. `get_paths(self) \u2011> collections.OrderedDict` : Get subject and scan IDs and the respective paths from the study data directory. Returns ------- _ : Tuple[List[Path], List[Path]] Paths to train images and labels. `get_preprocessing_transforms(self, size: Optional[List[int]] = [256, 256, 256], t2w_present: bool = False, flair_present: bool = False) \u2011> Callable` : Get preprocessing transorms to apply to all subjects. Returns ------- preprocess : tio.Compose All preprocessing steps that should be applied to all subjects. `get_subject_dicts(self, step: str = 'step06_WMHz_new', modalities: List[str] = ['T1w', 'FLAIR'], labels: List[str] = ['WMH']) \u2011> Tuple[collections.OrderedDict[Tuple[str, str], dict], collections.OrderedDict[Tuple[str, str], dict]]` : Get paths to nii files for train images and labels. Returns ------- _ : Tuple[List[Path], List[Path]] Paths to train images and labels. `get_subjects(self, train: bool = True) \u2011> List[torchio.data.subject.Subject]` : Get TorchIO Subject train and test subjects. Parameters ---------- train : bool, optional If True, return a loader for the train dataset, else for the validation dataset. Default = ``True``. Returns ------- _ : List[tio.Subject] TorchIO Subject train or test subjects. `prepare_data(self, *args: Any, **kwargs: Any) \u2011> None` : Verify data directory exists. `setup(self, stage: Optional[str] = None) \u2011> None` : Creates train, validation and test collection of samplers. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, ``'test'``, or ``'predict'``. If stage = None, set-up all stages. Default = None.","title":"Klu apc2"},{"location":"radio/data/datamodules/klu_apc2/#module-radiodatadatamodulesklu_apc2","text":"KLU_APC2 Data Module","title":"Module radio.data.datamodules.klu_apc2"},{"location":"radio/data/datamodules/klu_apc2/#functions","text":"plot_klu(batch: dict, num_imgs: int = 5, slice_num: int = 150, train: bool = True) \u2011> None : plot images and labels from a batch of train images","title":"Functions"},{"location":"radio/data/datamodules/klu_apc2/#classes","text":"KLUAPC2DataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/media/cerebro/Studies/KLU_APC2/Public/Analysis/data'), step: str = 'step02_structural_processing', train_transforms: Optional[Callable] = None, val_transforms: Optional[Callable] = None, test_transforms: Optional[Callable] = None, use_augmentation: bool = True, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, modalities: List[str] = ['T1w', 'FLAIR', 'T2w'], labels: List[str] = ['WMH'], dims: List[int] = [256, 256, 256], seed: int = 41, **kwargs: Any) : KLU APC2 Data Module. Typical Workflow ---------------- klu = KLUAPC2DataModule() klu.prepare_data() # download klu.setup(stage) # process and split klu.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root directory of dataset. Default = ``''/media/cerebro/Studies/KLU_APC2/Public/Analysis/data''``. step : str, optional Which processing step to use. Default = ``''step02_structural_processing''``. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. use_augmentation : bool, optional If ``True``, augment samples during the ``fit`` stage. Default = ``True``. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split : int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. dims : List[int], optional Max spatial dimensions across subjects' images. Default = ``[320, 256, 256]``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Ancestors (in MRO) * radio.data.visiondatamodule.VisionDataModule * radio.data.basedatamodule.BaseDataModule * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Static methods `get_augmentation_transforms() \u2011> Callable` : \" Get augmentation transorms to apply to subjects during training. Returns ------- augment : tio.Compose All augmentation steps that should be applied to subjects during training. `split_dict(dictionary: collections.OrderedDict, test_split: Union[int, float] = 0.2, shuffle: bool = True) \u2011> Tuple[collections.OrderedDict, collections.OrderedDict]` : Split dict into two. ### Methods `default_transforms(self, stage: Optional[str] = None) \u2011> Callable` : Default transforms and augmentations for the dataset. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, ``'test'``, or ``'predict'``. If stage = None, set-up all stages. Default = None. Returns ------- _: Callable All preprocessing steps (and if ``'fit'``, augmentation steps too) that should be applied to the subjects. `get_max_shape(self, subjects: List[torchio.data.subject.Subject]) \u2011> List[int]` : Get max shape. Parameters ---------- subjects : List[tio.Subject] List of TorchIO Subject objects. Returns ------- _ : np.ndarray((1, 3), np.int_) Max height, width and depth across all subjects. `get_paths(self) \u2011> collections.OrderedDict` : Get subject and scan IDs and the respective paths from the study data directory. Returns ------- _ : Tuple[List[Path], List[Path]] Paths to train images and labels. `get_preprocessing_transforms(self, size: Optional[List[int]] = [256, 256, 256], t2w_present: bool = False, flair_present: bool = False) \u2011> Callable` : Get preprocessing transorms to apply to all subjects. Returns ------- preprocess : tio.Compose All preprocessing steps that should be applied to all subjects. `get_subject_dicts(self, step: str = 'step06_WMHz_new', modalities: List[str] = ['T1w', 'FLAIR'], labels: List[str] = ['WMH']) \u2011> Tuple[collections.OrderedDict[Tuple[str, str], dict], collections.OrderedDict[Tuple[str, str], dict]]` : Get paths to nii files for train images and labels. Returns ------- _ : Tuple[List[Path], List[Path]] Paths to train images and labels. `get_subjects(self, train: bool = True) \u2011> List[torchio.data.subject.Subject]` : Get TorchIO Subject train and test subjects. Parameters ---------- train : bool, optional If True, return a loader for the train dataset, else for the validation dataset. Default = ``True``. Returns ------- _ : List[tio.Subject] TorchIO Subject train or test subjects. `prepare_data(self, *args: Any, **kwargs: Any) \u2011> None` : Verify data directory exists. `setup(self, stage: Optional[str] = None) \u2011> None` : Creates train, validation and test collection of samplers. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, ``'test'``, or ``'predict'``. If stage = None, set-up all stages. Default = None.","title":"Classes"},{"location":"radio/data/datamodules/medical_decathlon/","text":"Module radio.data.datamodules.medical_decathlon Medical Decathlon Data Module Functions plot_test_batch(batch: dict, num_imgs: int = 5, slice_num: int = 24) \u2011> None : plot images from a batch of test images plot_train_batch(batch: dict, num_imgs: int = 5, slice_num: int = 24) \u2011> None : plot images and labels from a batch of train images Classes MedicalDecathlonDataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/home/dinize@acct.upmchs.net/playground/radio/dataset/medical_decathlon'), task: str = 'Task04_Hippocampus', train_transforms: Optional[Callable] = None, val_transforms: Optional[Callable] = None, test_transforms: Optional[Callable] = None, use_augmentation: bool = True, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, seed: int = 41, **kwargs: Any) : Medical Decathlon Data Module. Typical Workflow ---------------- medicaldecathlon = MedicalDecathlonDataModule() medicaldecathlon.prepare_data() # download medicaldecathlon.setup(stage) # process and split medicaldecathlon.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root directory of dataset. If None, a temporary directory will be used. Default = ``DATA_ROOT / 'medical_decathlon'``. task : str, optional Which task to download and execute. One of ``'Task01_BrainTumour'``, ``'Task02_Heart'``, ``'Task03_Liver'``, ``'Task04_Hippocampus'``, ``'Task05_Prostate'``, ``'Task06_Lung'``, ``'Task07_Pancreas'``, ``'Task08_HepaticVessel'``, ``'Task09_Spleen'``, and ``'Task10_Colon'``. Default = ``'Task04_Hippocampus'``. See = http://medicaldecathlon.com/#tasks. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. use_augmentation : bool, optional If ``True``, augment samples during the ``fit`` stage. Default = ``True``. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split: int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Ancestors (in MRO) * radio.data.visiondatamodule.VisionDataModule * radio.data.basedatamodule.BaseDataModule * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Static methods `get_augmentation_transforms() \u2011> Callable` : \" Get augmentation transorms to apply to subjects during training. Returns ------- augment : tio.Compose All augmentation steps that should be applied to subjects during training. `get_niis(directory: pathlib.Path) \u2011> List[pathlib.Path]` : Get paths to nii files in the given directory. ### Methods `default_transforms(self, stage: Optional[str] = None) \u2011> Callable` : Default transforms and augmentations for the dataset. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, ``'test'``, or ``'predict'``. If stage = None, set-up all stages. Default = None. Returns ------- _: Callable All preprocessing steps (and if ``'fit'``, augmentation steps too) that should be applied to the subjects. `get_max_shape(self, subjects: List[torchio.data.subject.Subject]) \u2011> numpy.ndarray` : Get max shape. Parameters ---------- subjects : List[tio.Subject] List of TorchIO Subject objects. Returns ------- _ : np.ndarray((1, 3), np.int_) Max height, width and depth across all subjects. `get_preprocessing_transforms(self) \u2011> Callable` : Get preprocessing transorms to apply to all subjects. Returns ------- preprocess : tio.Compose All preprocessing steps that should be applied to all subjects. `get_subjects(self, train: bool = True) \u2011> List[torchio.data.subject.Subject]` : Get TorchIO Subject train and test subjects. Parameters ---------- train : bool, optional If True, return a loader for the train dataset, else for the validation dataset. Default = ``True``. Returns ------- _ : List[tio.Subject] TorchIO Subject train or test subjects. `get_test_paths(self) \u2011> List[pathlib.Path]` : Get paths to nii files for test images. Returns ------- _ : List[Path] Paths to test images. `get_train_paths(self) \u2011> Tuple[List[pathlib.Path], List[pathlib.Path]]` : Get paths to nii files for train images and labels. Returns ------- _ : Tuple[List[Path], List[Path]] Paths to train images and labels. `prepare_data(self, *args: Any, **kwargs: Any) \u2011> None` : Saves files to task data directory. `setup(self, stage: Optional[str] = None) \u2011> None` : Creates train, validation and test collection of samplers. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, ``'test'``, or ``'predict'``. If stage = None, set-up all stages. Default = None.","title":"Medical decathlon"},{"location":"radio/data/datamodules/medical_decathlon/#module-radiodatadatamodulesmedical_decathlon","text":"Medical Decathlon Data Module","title":"Module radio.data.datamodules.medical_decathlon"},{"location":"radio/data/datamodules/medical_decathlon/#functions","text":"plot_test_batch(batch: dict, num_imgs: int = 5, slice_num: int = 24) \u2011> None : plot images from a batch of test images plot_train_batch(batch: dict, num_imgs: int = 5, slice_num: int = 24) \u2011> None : plot images and labels from a batch of train images","title":"Functions"},{"location":"radio/data/datamodules/medical_decathlon/#classes","text":"MedicalDecathlonDataModule(*args: Any, root: Union[str, pathlib.Path] = PosixPath('/home/dinize@acct.upmchs.net/playground/radio/dataset/medical_decathlon'), task: str = 'Task04_Hippocampus', train_transforms: Optional[Callable] = None, val_transforms: Optional[Callable] = None, test_transforms: Optional[Callable] = None, use_augmentation: bool = True, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, seed: int = 41, **kwargs: Any) : Medical Decathlon Data Module. Typical Workflow ---------------- medicaldecathlon = MedicalDecathlonDataModule() medicaldecathlon.prepare_data() # download medicaldecathlon.setup(stage) # process and split medicaldecathlon.teardown(stage) # clean-up Parameters ---------- root : Path or str, optional Root directory of dataset. If None, a temporary directory will be used. Default = ``DATA_ROOT / 'medical_decathlon'``. task : str, optional Which task to download and execute. One of ``'Task01_BrainTumour'``, ``'Task02_Heart'``, ``'Task03_Liver'``, ``'Task04_Hippocampus'``, ``'Task05_Prostate'``, ``'Task06_Lung'``, ``'Task07_Pancreas'``, ``'Task08_HepaticVessel'``, ``'Task09_Spleen'``, and ``'Task10_Colon'``. Default = ``'Task04_Hippocampus'``. See = http://medicaldecathlon.com/#tasks. train_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. val_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. test_transforms : Callable, optional A function/transform that takes in a sample and returns a transformed version, e.g, ``torchvision.transforms.RandomCrop``. use_augmentation : bool, optional If ``True``, augment samples during the ``fit`` stage. Default = ``True``. batch_size : int, optional How many samples per batch to load. Default = ``32``. shuffle : bool, optional Whether to shuffle the data at every epoch. Default = ``False``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. drop_last : bool, optional Set to ``True`` to drop the last incomplete batch, if the dataset size is not divisible by the batch size. If ``False`` and the size of dataset is not divisible by the batch size, then the last batch will be smaller. Default = ``False``. num_folds : int, optional Number of folds. Must be at least ``2``. ``2`` corresponds to a single train/validation split. Default = ``2``. val_split: int or float, optional If ``num_folds = 2``, then ``val_split`` specify how the train_dataset should be split into train/validation datasets. If ``num_folds > 2``, then it is not used. Default = ``0.2``. seed : int, optional When `shuffle` is True, `seed` affects the ordering of the indices, which controls the randomness of each fold. It is also use to seed the RNG used by RandomSampler to generate random indexes and multiprocessing to generate `base_seed` for workers. Pass an int for reproducible output across multiple function calls. Default = ``41``. ### Ancestors (in MRO) * radio.data.visiondatamodule.VisionDataModule * radio.data.basedatamodule.BaseDataModule * pytorch_lightning.core.datamodule.LightningDataModule * pytorch_lightning.core.hooks.CheckpointHooks * pytorch_lightning.core.hooks.DataHooks * pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin ### Static methods `get_augmentation_transforms() \u2011> Callable` : \" Get augmentation transorms to apply to subjects during training. Returns ------- augment : tio.Compose All augmentation steps that should be applied to subjects during training. `get_niis(directory: pathlib.Path) \u2011> List[pathlib.Path]` : Get paths to nii files in the given directory. ### Methods `default_transforms(self, stage: Optional[str] = None) \u2011> Callable` : Default transforms and augmentations for the dataset. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, ``'test'``, or ``'predict'``. If stage = None, set-up all stages. Default = None. Returns ------- _: Callable All preprocessing steps (and if ``'fit'``, augmentation steps too) that should be applied to the subjects. `get_max_shape(self, subjects: List[torchio.data.subject.Subject]) \u2011> numpy.ndarray` : Get max shape. Parameters ---------- subjects : List[tio.Subject] List of TorchIO Subject objects. Returns ------- _ : np.ndarray((1, 3), np.int_) Max height, width and depth across all subjects. `get_preprocessing_transforms(self) \u2011> Callable` : Get preprocessing transorms to apply to all subjects. Returns ------- preprocess : tio.Compose All preprocessing steps that should be applied to all subjects. `get_subjects(self, train: bool = True) \u2011> List[torchio.data.subject.Subject]` : Get TorchIO Subject train and test subjects. Parameters ---------- train : bool, optional If True, return a loader for the train dataset, else for the validation dataset. Default = ``True``. Returns ------- _ : List[tio.Subject] TorchIO Subject train or test subjects. `get_test_paths(self) \u2011> List[pathlib.Path]` : Get paths to nii files for test images. Returns ------- _ : List[Path] Paths to test images. `get_train_paths(self) \u2011> Tuple[List[pathlib.Path], List[pathlib.Path]]` : Get paths to nii files for train images and labels. Returns ------- _ : Tuple[List[Path], List[Path]] Paths to train images and labels. `prepare_data(self, *args: Any, **kwargs: Any) \u2011> None` : Saves files to task data directory. `setup(self, stage: Optional[str] = None) \u2011> None` : Creates train, validation and test collection of samplers. Parameters ---------- stage: Optional[str] Either ``'fit``, ``'validate'``, ``'test'``, or ``'predict'``. If stage = None, set-up all stages. Default = None.","title":"Classes"},{"location":"radio/data/inference/","text":"Module radio.data.inference Inference init Sub-modules radio.data.inference.aggregator","title":"Index"},{"location":"radio/data/inference/#module-radiodatainference","text":"Inference init","title":"Module radio.data.inference"},{"location":"radio/data/inference/#sub-modules","text":"radio.data.inference.aggregator","title":"Sub-modules"},{"location":"radio/data/inference/aggregator/","text":"Module radio.data.inference.aggregator Based on BaseDataModule for managing data. A vision datamodule that is shareable, reusable class that encapsulates all the steps needed to process data, i.e., decoupling datasets from models to allow building dataset-agnostic models. They also allow you to share a full dataset without explaining how to download, split, transform, and process the data. Classes PatchBasedInference(patch_size: Union[int, Tuple[int, int, int]] = 96, patch_overlap: Union[int, Tuple[int, int, int]] = (0, 0, 0), patch_batch_size: int = 32, padding_mode: Union[str, float, ForwardRef(None)] = None, overlap_mode: str = 'crop', num_workers: int = 0, pin_memory: bool = True, verbose: bool = False) : Dense Patch-based inference. Typical Workflow ---------------- in_dataset: tio.SubjectsDataset model: torch.nn.Module intensities: List[str] out_dataset: tio.SubjectsDataset inferencemodule = PatchBasedInference( patch_size, patch_overlap, padding_mode, overlap_mode, ) out_dataset = inferencemodule(in_dataset, model, intensities) Parameters ---------- patch_size : int or (int, int, int) Tuple of integers ``(w, h, d)`` to generate patches of size ``w x h x d``. If a single number ``n`` is provided, ``w = h = d = n``. patch_overlap : int or (int, int, int), optional Tuple of even integers ``(w_o, h_o, d_o)`` specifying the overlap between patches for dense inference. If a single number ``n`` is provided, ``w_o = h_o = d_o = n``. Default = ``(0, 0, 0)``. patch_batch_size : int, optional How many patches per batch to load. Default = ``32``. padding_mode : str or float or None, optional If ``None``, the volume will not be padded before sampling and patches at the border will not be cropped by the aggregator. Otherwise, the volume will be padded with ``w_o/2, h_o/2, d_o/2`` on each side before sampling and it will cropped by the aggregator to its original size. Possible padding modes: ``('empty', 'edge', 'wrap', 'constant', 'linear_ramp', 'maximum', 'mean', 'median', 'minimum', 'reflect', 'symmetric')``. If it is a number, the mode will be set to ``'constant'``. Default = ``None``. overlap_mode : str, optional If ``'crop'``, the overlapping predictions will be cropped. If ``'average'``, the predictions in the overlapping areas will be averaged with equal weights. Default = ``'crop'``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. Default = ``True``. verbose : bool, optional If ``True``, print debugging messages. Default = ``False``.","title":"Aggregator"},{"location":"radio/data/inference/aggregator/#module-radiodatainferenceaggregator","text":"Based on BaseDataModule for managing data. A vision datamodule that is shareable, reusable class that encapsulates all the steps needed to process data, i.e., decoupling datasets from models to allow building dataset-agnostic models. They also allow you to share a full dataset without explaining how to download, split, transform, and process the data.","title":"Module radio.data.inference.aggregator"},{"location":"radio/data/inference/aggregator/#classes","text":"PatchBasedInference(patch_size: Union[int, Tuple[int, int, int]] = 96, patch_overlap: Union[int, Tuple[int, int, int]] = (0, 0, 0), patch_batch_size: int = 32, padding_mode: Union[str, float, ForwardRef(None)] = None, overlap_mode: str = 'crop', num_workers: int = 0, pin_memory: bool = True, verbose: bool = False) : Dense Patch-based inference. Typical Workflow ---------------- in_dataset: tio.SubjectsDataset model: torch.nn.Module intensities: List[str] out_dataset: tio.SubjectsDataset inferencemodule = PatchBasedInference( patch_size, patch_overlap, padding_mode, overlap_mode, ) out_dataset = inferencemodule(in_dataset, model, intensities) Parameters ---------- patch_size : int or (int, int, int) Tuple of integers ``(w, h, d)`` to generate patches of size ``w x h x d``. If a single number ``n`` is provided, ``w = h = d = n``. patch_overlap : int or (int, int, int), optional Tuple of even integers ``(w_o, h_o, d_o)`` specifying the overlap between patches for dense inference. If a single number ``n`` is provided, ``w_o = h_o = d_o = n``. Default = ``(0, 0, 0)``. patch_batch_size : int, optional How many patches per batch to load. Default = ``32``. padding_mode : str or float or None, optional If ``None``, the volume will not be padded before sampling and patches at the border will not be cropped by the aggregator. Otherwise, the volume will be padded with ``w_o/2, h_o/2, d_o/2`` on each side before sampling and it will cropped by the aggregator to its original size. Possible padding modes: ``('empty', 'edge', 'wrap', 'constant', 'linear_ramp', 'maximum', 'mean', 'median', 'minimum', 'reflect', 'symmetric')``. If it is a number, the mode will be set to ``'constant'``. Default = ``None``. overlap_mode : str, optional If ``'crop'``, the overlapping predictions will be cropped. If ``'average'``, the predictions in the overlapping areas will be averaged with equal weights. Default = ``'crop'``. num_workers : int, optional How many subprocesses to use for data loading. ``0`` means that the data will be loaded in the main process. Default: ``0``. pin_memory : bool, optional If ``True``, the data loader will copy Tensors into CUDA pinned memory before returning them. Default = ``True``. verbose : bool, optional If ``True``, print debugging messages. Default = ``False``.","title":"Classes"},{"location":"radio/settings/","text":"Module radio.settings This package includes a miscellaneous collection of useful helper functions Sub-modules radio.settings.pathutils","title":"Index"},{"location":"radio/settings/#module-radiosettings","text":"This package includes a miscellaneous collection of useful helper functions","title":"Module radio.settings"},{"location":"radio/settings/#sub-modules","text":"radio.settings.pathutils","title":"Sub-modules"},{"location":"radio/settings/pathutils/","text":"Module radio.settings.pathutils Manages Paths for Saving Models and Logs. Functions ensure_exists(path: Union[str, pathlib.Path]) \u2011> pathlib.Path : Enforce the directory existence. is_dir_or_symlink(path: Union[str, pathlib.Path]) \u2011> bool : Check if the path is a directory or a symlink to a directory. is_valid_extension(filename: Union[str, pathlib.Path], extensions: Tuple[str, ...]) \u2011> bool : Verifies if given file name has a valid extension. Parameters ---------- filename : str or Path Path to a file. extensions : Tuple[str, ...] Extensions to consider (lowercase). Returns ------- return : bool True if the filename ends with one of given extensions. is_valid_image(filename: Union[str, pathlib.Path]) \u2011> bool : Verifies if given file name has a valid image extension. Parameters ---------- filename : str or Path Path to a file. Returns ------- return : bool True if the filename ends with one of the valid image extensions.","title":"Pathutils"},{"location":"radio/settings/pathutils/#module-radiosettingspathutils","text":"Manages Paths for Saving Models and Logs.","title":"Module radio.settings.pathutils"},{"location":"radio/settings/pathutils/#functions","text":"ensure_exists(path: Union[str, pathlib.Path]) \u2011> pathlib.Path : Enforce the directory existence. is_dir_or_symlink(path: Union[str, pathlib.Path]) \u2011> bool : Check if the path is a directory or a symlink to a directory. is_valid_extension(filename: Union[str, pathlib.Path], extensions: Tuple[str, ...]) \u2011> bool : Verifies if given file name has a valid extension. Parameters ---------- filename : str or Path Path to a file. extensions : Tuple[str, ...] Extensions to consider (lowercase). Returns ------- return : bool True if the filename ends with one of given extensions. is_valid_image(filename: Union[str, pathlib.Path]) \u2011> bool : Verifies if given file name has a valid image extension. Parameters ---------- filename : str or Path Path to a file. Returns ------- return : bool True if the filename ends with one of the valid image extensions.","title":"Functions"},{"location":"radio/structured_config/","text":"Module radio.structured_config Sub-modules radio.structured_config.dataset radio.structured_config.experiment radio.structured_config.optimizer Functions register_configs() \u2011> None : dataset register its configs in structured_config/dataset . optimizer register its configs in structured_config/optimizer . experiment register its configs in structured_config/experiment .","title":"Index"},{"location":"radio/structured_config/#module-radiostructured_config","text":"","title":"Module radio.structured_config"},{"location":"radio/structured_config/#sub-modules","text":"radio.structured_config.dataset radio.structured_config.experiment radio.structured_config.optimizer","title":"Sub-modules"},{"location":"radio/structured_config/#functions","text":"register_configs() \u2011> None : dataset register its configs in structured_config/dataset . optimizer register its configs in structured_config/optimizer . experiment register its configs in structured_config/experiment .","title":"Functions"},{"location":"radio/structured_config/dataset/","text":"Module radio.structured_config.dataset Functions register_configs() \u2011> None : Classes Cifar10Config(name: dataclasses.InitVar[str] = 'cifar10', train: bool = True, download: bool = True) : Cifar10Config( target : str = 'torchvision.datasets.CIFAR10', name: dataclasses.InitVar[str] = 'cifar10', train: bool = True, download: bool = True) ### Ancestors (in MRO) * radio.structured_config.dataset.DatasetConfig ### Class variables `name: dataclasses.InitVar[str]` : DatasetConfig(name: dataclasses.InitVar[str] = '???', train: bool = True, download: bool = True) : DatasetConfig( target : str = '???', name: dataclasses.InitVar[str] = '???', train: bool = True, download: bool = True) ### Descendants * radio.structured_config.dataset.Cifar10Config * radio.structured_config.dataset.MNISTConfig ### Class variables `download: bool` : `name: dataclasses.InitVar[str]` : `root: str` : `train: bool` : MNISTConfig(name: dataclasses.InitVar[str] = 'mnist', train: bool = True, download: bool = True) : MNISTConfig( target : str = 'torchvision.datasets.MNIST', name: dataclasses.InitVar[str] = 'mnist', train: bool = True, download: bool = True) ### Ancestors (in MRO) * radio.structured_config.dataset.DatasetConfig ### Class variables `name: dataclasses.InitVar[str]` :","title":"Dataset"},{"location":"radio/structured_config/dataset/#module-radiostructured_configdataset","text":"","title":"Module radio.structured_config.dataset"},{"location":"radio/structured_config/dataset/#functions","text":"register_configs() \u2011> None :","title":"Functions"},{"location":"radio/structured_config/dataset/#classes","text":"Cifar10Config(name: dataclasses.InitVar[str] = 'cifar10', train: bool = True, download: bool = True) : Cifar10Config( target : str = 'torchvision.datasets.CIFAR10', name: dataclasses.InitVar[str] = 'cifar10', train: bool = True, download: bool = True) ### Ancestors (in MRO) * radio.structured_config.dataset.DatasetConfig ### Class variables `name: dataclasses.InitVar[str]` : DatasetConfig(name: dataclasses.InitVar[str] = '???', train: bool = True, download: bool = True) : DatasetConfig( target : str = '???', name: dataclasses.InitVar[str] = '???', train: bool = True, download: bool = True) ### Descendants * radio.structured_config.dataset.Cifar10Config * radio.structured_config.dataset.MNISTConfig ### Class variables `download: bool` : `name: dataclasses.InitVar[str]` : `root: str` : `train: bool` : MNISTConfig(name: dataclasses.InitVar[str] = 'mnist', train: bool = True, download: bool = True) : MNISTConfig( target : str = 'torchvision.datasets.MNIST', name: dataclasses.InitVar[str] = 'mnist', train: bool = True, download: bool = True) ### Ancestors (in MRO) * radio.structured_config.dataset.DatasetConfig ### Class variables `name: dataclasses.InitVar[str]` :","title":"Classes"},{"location":"radio/structured_config/experiment/","text":"Module radio.structured_config.experiment Functions register_configs() \u2011> None : Classes ExperimentConfig(phase: str = '???', debug: bool = '???', dataset: radio.structured_config.dataset.DatasetConfig = '???', optimizer: radio.structured_config.optimizer.OptimizerConfig = '???') : ExperimentConfig(phase: str = '???', debug: bool = '???', dataset: radio.structured_config.dataset.DatasetConfig = '???', optimizer: radio.structured_config.optimizer.OptimizerConfig = '???') ### Descendants * radio.structured_config.experiment.PilotConfig ### Class variables `dataset: radio.structured_config.dataset.DatasetConfig` : `debug: bool` : `optimizer: radio.structured_config.optimizer.OptimizerConfig` : `phase: str` : PilotConfig(phase: str = 'train', debug: bool = False, dataset: radio.structured_config.dataset.DatasetConfig = MNISTConfig(_target_='torchvision.datasets.MNIST', root='/data/mnist', train=True, download=True), optimizer: radio.structured_config.optimizer.OptimizerConfig = AdamConfig(name='adam', lr=0.001, beta=0.01)) : PilotConfig(phase: str = 'train', debug: bool = False, dataset: radio.structured_config.dataset.DatasetConfig = MNISTConfig( target ='torchvision.datasets.MNIST', root='/data/mnist', train=True, download=True), optimizer: radio.structured_config.optimizer.OptimizerConfig = AdamConfig(name='adam', lr=0.001, beta=0.01)) ### Ancestors (in MRO) * radio.structured_config.experiment.ExperimentConfig ### Class variables `dataset: radio.structured_config.dataset.DatasetConfig` : `debug: bool` : `optimizer: radio.structured_config.optimizer.OptimizerConfig` : `phase: str` :","title":"Experiment"},{"location":"radio/structured_config/experiment/#module-radiostructured_configexperiment","text":"","title":"Module radio.structured_config.experiment"},{"location":"radio/structured_config/experiment/#functions","text":"register_configs() \u2011> None :","title":"Functions"},{"location":"radio/structured_config/experiment/#classes","text":"ExperimentConfig(phase: str = '???', debug: bool = '???', dataset: radio.structured_config.dataset.DatasetConfig = '???', optimizer: radio.structured_config.optimizer.OptimizerConfig = '???') : ExperimentConfig(phase: str = '???', debug: bool = '???', dataset: radio.structured_config.dataset.DatasetConfig = '???', optimizer: radio.structured_config.optimizer.OptimizerConfig = '???') ### Descendants * radio.structured_config.experiment.PilotConfig ### Class variables `dataset: radio.structured_config.dataset.DatasetConfig` : `debug: bool` : `optimizer: radio.structured_config.optimizer.OptimizerConfig` : `phase: str` : PilotConfig(phase: str = 'train', debug: bool = False, dataset: radio.structured_config.dataset.DatasetConfig = MNISTConfig(_target_='torchvision.datasets.MNIST', root='/data/mnist', train=True, download=True), optimizer: radio.structured_config.optimizer.OptimizerConfig = AdamConfig(name='adam', lr=0.001, beta=0.01)) : PilotConfig(phase: str = 'train', debug: bool = False, dataset: radio.structured_config.dataset.DatasetConfig = MNISTConfig( target ='torchvision.datasets.MNIST', root='/data/mnist', train=True, download=True), optimizer: radio.structured_config.optimizer.OptimizerConfig = AdamConfig(name='adam', lr=0.001, beta=0.01)) ### Ancestors (in MRO) * radio.structured_config.experiment.ExperimentConfig ### Class variables `dataset: radio.structured_config.dataset.DatasetConfig` : `debug: bool` : `optimizer: radio.structured_config.optimizer.OptimizerConfig` : `phase: str` :","title":"Classes"},{"location":"radio/structured_config/optimizer/","text":"Module radio.structured_config.optimizer Functions register_configs() \u2011> None : Classes AdamConfig(name: str = 'adam', lr: float = 0.001, beta: float = 0.01) : AdamConfig(name: str = 'adam', lr: float = 0.001, beta: float = 0.01) ### Ancestors (in MRO) * radio.structured_config.optimizer.OptimizerConfig ### Class variables `beta: float` : `lr: float` : `name: str` : NesterovConfig(name: str = 'nesterov', lr: float = 0.01) : NesterovConfig(name: str = 'nesterov', lr: float = 0.01) ### Ancestors (in MRO) * radio.structured_config.optimizer.OptimizerConfig ### Class variables `name: str` : OptimizerConfig(name: str = '???', lr: float = 0.01) : OptimizerConfig(name: str = '???', lr: float = 0.01) ### Descendants * radio.structured_config.optimizer.AdamConfig * radio.structured_config.optimizer.NesterovConfig ### Class variables `lr: float` : `name: str` :","title":"Optimizer"},{"location":"radio/structured_config/optimizer/#module-radiostructured_configoptimizer","text":"","title":"Module radio.structured_config.optimizer"},{"location":"radio/structured_config/optimizer/#functions","text":"register_configs() \u2011> None :","title":"Functions"},{"location":"radio/structured_config/optimizer/#classes","text":"AdamConfig(name: str = 'adam', lr: float = 0.001, beta: float = 0.01) : AdamConfig(name: str = 'adam', lr: float = 0.001, beta: float = 0.01) ### Ancestors (in MRO) * radio.structured_config.optimizer.OptimizerConfig ### Class variables `beta: float` : `lr: float` : `name: str` : NesterovConfig(name: str = 'nesterov', lr: float = 0.01) : NesterovConfig(name: str = 'nesterov', lr: float = 0.01) ### Ancestors (in MRO) * radio.structured_config.optimizer.OptimizerConfig ### Class variables `name: str` : OptimizerConfig(name: str = '???', lr: float = 0.01) : OptimizerConfig(name: str = '???', lr: float = 0.01) ### Descendants * radio.structured_config.optimizer.AdamConfig * radio.structured_config.optimizer.NesterovConfig ### Class variables `lr: float` : `name: str` :","title":"Classes"}]}