<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>radio.data.datamodules.brain_aging_prediction API documentation</title>
<meta name="description" content="Brain Aging Prediction Data Module" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>radio.data.datamodules.brain_aging_prediction</code></h1>
</header>
<section id="section-intro">
<p>Brain Aging Prediction Data Module</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python
# coding=utf-8
&#34;&#34;&#34;
Brain Aging Prediction Data Module
&#34;&#34;&#34;

from typing import Any, Dict, List, Optional, Tuple, Union, cast
from pathlib import Path
import re
from string import Template
from collections import OrderedDict
import numpy as np
import torchio as tio  # type: ignore
from torch.utils.data import DataLoader
from radio.settings.pathutils import is_dir_or_symlink, PathType, ensure_exists
from ..visiondatamodule import VisionDataModule
from ..datautils import get_subjects_from_batch
from ..datatypes import SubjPathType, SubjDictType

__all__ = [&#34;BrainAgingPredictionDataModule&#34;]


class BrainAgingPredictionDataModule(VisionDataModule):
    &#34;&#34;&#34;
    Brain Aging Prediction Data Module.

    Typical Workflow
    ----------------
    data = BrainAgingPredictionDataModule()
    data.prepare_data() # download
    data.setup(stage) # process and split
    data.teardown(stage) # clean-up

    Parameters
    ----------
    root : Path or str, optional
        Root to GPN&#39;s CEREBRO Studies folder.
        Default = ``&#39;/media/cerebro/Studies&#39;``.
    study : str, optional
        Study name. Default = ``&#39;Brain_Aging_Prediction&#39;``.
    data_dir : str, optional
        Subdirectory where the data is located.
        Default = ``&#39;Public/data&#39;``.
    step : str, optional
        Which processing step to use.
        Default = ``&#39;step01_structural_processing&#39;``.
    train_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    val_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    test_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    use_augmentation : bool, optional
        If ``True``, augment samples during the ``fit`` stage.
        Default = ``True``.
    use_preprocessing : bool, optional
        If ``True``, preprocess samples. Default = ``True``.
    resample : bool, optional
        If ``True``, resample all images to ``&#39;T1&#39;``. Default = ``False``.
    batch_size : int, optional
        How many samples per batch to load. Default = ``32``.
    shuffle : bool, optional
        Whether to shuffle the data at every epoch. Default = ``False``.
    num_workers : int, optional
        How many subprocesses to use for data loading. ``0`` means that the
        data will be loaded in the main process. Default: ``0``.
    pin_memory : bool, optional
        If ``True``, the data loader will copy Tensors into CUDA pinned memory
        before returning them.
    drop_last : bool, optional
        Set to ``True`` to drop the last incomplete batch, if the dataset size
        is not divisible by the batch size. If ``False`` and the size of
        dataset is not divisible by the batch size, then the last batch will be
        smaller. Default = ``False``.
    num_folds : int, optional
        Number of folds. Must be at least ``2``. ``2`` corresponds to a single
        train/validation split. Default = ``2``.
    val_split : int or float, optional
        If ``num_folds = 2``, then ``val_split`` specify how the
        train_dataset should be split into train/validation datasets. If
        ``num_folds &gt; 2``, then it is not used. Default = ``0.2``.
    intensities : List[str], optional
        Which intensities to load. Default = ``[&#39;T1&#39;]``.
    labels : List[str], optional
        Which labels to load. Default = ``[]``.
    dims : Tuple[int, int, int], optional
        Max spatial dimensions across subjects&#39; images. If ``None``, compute
        dimensions from dataset. Default = ``(160, 192, 160)``.
    seed : int, optional
        When `shuffle` is True, `seed` affects the ordering of the indices,
        which controls the randomness of each fold. It is also use to seed the
        RNG used by RandomSampler to generate random indexes and
        multiprocessing to generate `base_seed` for workers. Pass an int for
        reproducible output across multiple function calls. Default = ``41``.
    verbose : bool, optional
        If ``True``, print debugging messages. Default = ``False``.
    &#34;&#34;&#34;
    name: str = &#34;brain_aging_prediction&#34;
    dataset_cls = tio.SubjectsDataset
    intensity2template = {
        &#34;T1&#34;: Template(&#39;wstrip_m${subj_id}_${scan_id}_T1.nii&#39;),
        &#34;FLAIR&#34;: Template(&#39;wstrip_mr${subj_id}_${scan_id}_FLAIR.nii&#39;),
    }
    label2template: Dict[str, Template] = {}

    def __init__(
        self,
        *args: Any,
        root: PathType = Path(&#39;/media/cerebro/Studies&#39;),
        study: str = &#39;Brain_Aging_Prediction&#39;,
        data_dir: str = &#39;Public/data&#39;,
        step: str = &#39;step01_structural_processing&#39;,
        train_transforms: Optional[tio.Transform] = None,
        val_transforms: Optional[tio.Transform] = None,
        test_transforms: Optional[tio.Transform] = None,
        use_augmentation: bool = True,
        use_preprocessing: bool = True,
        resample: bool = False,
        batch_size: int = 32,
        shuffle: bool = True,
        num_workers: int = 0,
        pin_memory: bool = True,
        drop_last: bool = False,
        num_folds: int = 2,
        val_split: Union[int, float] = 0.2,
        intensities: Optional[List[str]] = None,
        labels: Optional[List[str]] = None,
        dims: Tuple[int, int, int] = (160, 192, 160),
        seed: int = 41,
        verbose: bool = False,
        **kwargs: Any,
    ) -&gt; None:
        root = Path(root) / study / data_dir
        super().__init__(
            *args,
            root=root,
            train_transforms=train_transforms,
            val_transforms=val_transforms,
            test_transforms=test_transforms,
            batch_size=batch_size,
            shuffle=shuffle,
            num_workers=num_workers,
            pin_memory=pin_memory,
            drop_last=drop_last,
            num_folds=num_folds,
            val_split=val_split,
            seed=seed,
            **kwargs,
        )
        self.study = study
        self.data_dir = data_dir
        self.step = step
        self.intensities = intensities if intensities else [&#39;T1&#39;, &#39;FLAIR&#39;]
        self.labels = labels if labels else []
        self.dims = dims
        self.use_augmentation = use_augmentation
        self.use_preprocessing = use_preprocessing
        self.resample = resample
        self.verbose = verbose

    def prepare_data(self, *args: Any, **kwargs: Any) -&gt; None:
        &#34;&#34;&#34;Verify data directory exists and if test/train/val splitted.&#34;&#34;&#34;
        if not is_dir_or_symlink(self.root):
            raise OSError(&#39;Study data directory not found!&#39;)
        self.check_if_data_split(self.step)

    def setup(self, stage: Optional[str] = None) -&gt; None:
        &#34;&#34;&#34;
        Creates train, validation and test collection of samplers.

        Parameters
        ----------
        stage: Optional[str]
            Either ``&#39;fit``, ``&#39;validate&#39;``, or ``&#39;test&#39;``.
            If stage = ``None``, set-up all stages. Default = ``None``.
        &#34;&#34;&#34;
        if stage == &#34;fit&#34; or stage is None:
            train_transforms = self.default_transforms(
                stage=&#34;fit&#34;
            ) if self.train_transforms is None else self.train_transforms

            val_transforms = self.default_transforms(
                stage=&#34;fit&#34;
            ) if self.val_transforms is None else self.val_transforms

            if not self.has_train_val_split:
                train_subjects = self.get_subjects(fold=&#34;train&#34;)
                train_dataset = self.dataset_cls(
                    train_subjects,
                    transform=train_transforms,
                )
                val_dataset = self.dataset_cls(
                    train_subjects,
                    transform=val_transforms,
                )
                self.validation = self.val_cls(
                    train_dataset=train_dataset,
                    val_dataset=val_dataset,
                    batch_size=self.batch_size,
                    shuffle=self.shuffle,
                    num_workers=self.num_workers,
                    pin_memory=self.pin_memory,
                    drop_last=self.drop_last,
                    num_folds=self.num_folds,
                    seed=self.seed,
                )
                self.validation.setup(self.val_split)
                self.has_validation = True
                self.train_dataset = train_dataset
                self.size_train = self.size_train_dataset(
                    self.validation.train_samplers)
                self.val_dataset = val_dataset
                self.size_val = self.size_eval_dataset(
                    self.validation.val_samplers)
            else:
                train_subjects = self.get_subjects(fold=&#34;train&#34;)
                self.train_dataset = self.dataset_cls(
                    train_subjects, transform=train_transforms)
                self.size_train = self.size_train_dataset(self.train_dataset)

                val_subjects = self.get_subjects(fold=&#34;val&#34;)
                self.val_dataset = self.dataset_cls(val_subjects,
                                                    transform=val_transforms)
                self.size_val = self.size_eval_dataset(self.val_dataset)

        if stage == &#34;test&#34; or stage is None:
            test_transforms = self.default_transforms(
                stage=&#34;test&#34;
            ) if self.test_transforms is None else self.test_transforms
            test_subjects = self.get_subjects(fold=&#34;test&#34;)
            self.test_dataset = self.dataset_cls(test_subjects,
                                                 transform=test_transforms)
            self.size_test = self.size_eval_dataset(self.test_dataset)

    def get_subjects(self, fold: str = &#34;train&#34;) -&gt; List[tio.Subject]:
        &#34;&#34;&#34;
        Get train, test, or val list of TorchIO Subjects.

        Parameters
        ----------
        fold : str, optional
            Identify which type of dataset, ``&#39;train&#39;``, ``&#39;test&#39;``, or
            ``&#39;val&#39;``. Default = ``&#39;train&#39;``.

        Returns
        -------
        _ : List[tio.Subject]
            Train, test or val list of TorchIO Subjects.
        &#34;&#34;&#34;
        train_subjs, test_subjs, val_subjs = self.get_subjects_dicts(
            intensities=self.intensities, labels=self.labels)
        if fold == &#34;train&#34;:
            subjs_dict = train_subjs
        elif fold == &#34;test&#34;:
            subjs_dict = test_subjs
        else:
            subjs_dict = val_subjs

        subjects = []
        for _, subject_dict in subjs_dict.items():
            subject = tio.Subject(subject_dict)
            subjects.append(subject)
        return subjects

    def get_subjects_dicts(
        self,
        intensities: Optional[List[str]] = None,
        labels: Optional[List[str]] = None,
    ) -&gt; Tuple[SubjDictType, SubjDictType, SubjDictType]:
        &#34;&#34;&#34;
        Get paths to nii files for train/test/val images and labels.

        Returns
        -------
        _ : {(str, str): Dict}, {(str, str): Dict}, {(str, str): Dict}
            Paths to, respectively, train, test, and val images and labels.
        &#34;&#34;&#34;

        def _get_dict(
            paths_dict: OrderedDict[Tuple[str, str], Path],
            intensities: List[str],
            labels: List[str],
            train: bool = True,
        ) -&gt; SubjDictType:
            subjects_dict: SubjDictType = OrderedDict()
            for (subj_id, scan_id), path in paths_dict.items():
                subjects_dict[(subj_id, scan_id)] = OrderedDict({
                    &#34;subj_id&#34;:
                    subj_id,
                    &#34;scan_id&#34;:
                    scan_id
                })
                for intensity in intensities:
                    intensity_path = path / self.intensity2template[
                        intensity].substitute(subj_id=subj_id, scan_id=scan_id)
                    if intensity_path.is_file():
                        subjects_dict[(subj_id, scan_id)].update(
                            {intensity: tio.ScalarImage(intensity_path)})
                    else:
                        subjects_dict.pop((subj_id, scan_id), None)

                if train:
                    for label in labels:
                        label_path = path / self.label2template[
                            label].substitute(subj_id=subj_id, scan_id=scan_id)
                        if label_path.is_file():
                            subjects_dict[(subj_id, scan_id)].update(
                                {label: tio.LabelMap(label_path)})
                        else:
                            subjects_dict.pop((subj_id, scan_id), None)
            return subjects_dict

        intensities = intensities if intensities else [&#39;T1&#39;, &#39;FLAIR&#39;]
        labels = labels if labels else []

        for intensity in intensities:
            assert intensity in self.intensity2template

        for label in labels:
            assert label in self.label2template

        subj_train_paths, subj_test_paths, subj_val_paths = self.get_paths(
            self.root,
            stem=self.step,
            has_train_test_split=self.has_train_test_split,
            has_train_val_split=self.has_train_val_split,
            shuffle=self.shuffle,
            seed=self.seed,
        )

        subj_train_dict = _get_dict(subj_train_paths,
                                    intensities,
                                    labels,
                                    train=True)
        subj_val_dict = _get_dict(subj_val_paths,
                                  intensities,
                                  labels,
                                  train=True)
        subj_test_dict = _get_dict(subj_test_paths,
                                   intensities,
                                   labels,
                                   train=False)

        return subj_train_dict, subj_test_dict, subj_val_dict

    @staticmethod
    def get_paths(
        data_root: PathType,
        stem: str = &#39;step01_structural_processing&#39;,
        has_train_test_split: bool = False,
        has_train_val_split: bool = False,
        test_split: Union[int, float] = 0.2,
        shuffle: bool = True,
        seed: int = 41,
    ) -&gt; Tuple[SubjPathType, SubjPathType, SubjPathType]:
        &#34;&#34;&#34;
        Get subject and scan IDs and the respective paths from the study data
        directory.

        Returns
        -------
        _ : {(str, str): Path}, {(str, str): Path}, {(str, str): Path}
            Paths for respectively, train, test and images and labels.
        &#34;&#34;&#34;

        def _split_subj_train_paths(
                paths: OrderedDict) -&gt; Tuple[OrderedDict, OrderedDict]:
            &#34;&#34;&#34;Split dictionary into two proportially to `test_split`.&#34;&#34;&#34;
            len_paths = len(paths)
            if isinstance(test_split, int):
                train_len = len_paths - test_split
                splits = [train_len, test_split]
            elif isinstance(test_split, float):
                test_len = int(np.floor(test_split * len_paths))
                train_len = len_paths - test_len
                splits = [train_len, test_len]
            else:
                raise ValueError(f&#34;Unsupported type {type(test_split)}&#34;)
            indexes = list(range(len_paths))
            if shuffle:
                np.random.seed(seed)
                np.random.shuffle(indexes)
            train_idx, test_idx = indexes[:splits[0]], indexes[:splits[1]]

            paths_list = list(paths.items())

            subj_train_paths = OrderedDict([
                value for idx, value in enumerate(paths_list)
                if idx in train_idx
            ])
            subj_test_paths = OrderedDict([
                value for idx, value in enumerate(paths_list)
                if idx in test_idx
            ])
            return subj_train_paths, subj_test_paths

        data_root = Path(data_root)
        subj_pattern = r&#34;[a-zA-z]{3}_[a-zA-Z]{2}_\d{4}&#34;
        scan_pattern = r&#34;[a-zA-z]{4}\d{3}&#34;
        no_split_regex = re.compile(&#34;(&#34; + subj_pattern + &#34;)&#34; + &#34;/&#34; +
                                    subj_pattern + &#34;_&#34; + &#34;(&#34; + scan_pattern +
                                    &#34;)&#34;)
        has_split_regex = re.compile(&#34;(&#34; + subj_pattern + &#34;)&#34; + &#34;_&#34; + &#34;(&#34; +
                                     scan_pattern + &#34;)&#34;)

        def _get_subj_paths(data_root, regex):
            subj_paths = OrderedDict()
            for item in data_root.glob(&#34;*&#34;):
                if not item.is_dir() and not item.name.startswith(&#39;.&#39;):
                    match = regex.search(str(item))
                    if match is not None:
                        subj_id, scan_id = match.groups()
                        subj_paths[(subj_id, scan_id)] = data_root
            return subj_paths

        if not has_train_test_split:
            paths = OrderedDict()
            for item in data_root.glob(&#34;*/*&#34;):
                if item.is_dir() and not item.name.startswith(&#39;.&#39;):
                    match = no_split_regex.search(str(item))
                    if match is not None:
                        subj_id, scan_id = match.groups()
                        paths[(subj_id, scan_id)] = data_root / subj_id / (
                            subj_id + &#34;_&#34; + scan_id) / stem
            subj_train_paths, subj_test_paths = _split_subj_train_paths(paths)
        else:
            train_root = data_root / stem / &#34;train&#34;
            subj_train_paths = _get_subj_paths(train_root, has_split_regex)
            test_root = data_root / stem / &#34;test&#34;
            subj_test_paths = _get_subj_paths(test_root, has_split_regex)

        val_root = data_root / stem / &#34;val&#34;
        subj_val_paths = _get_subj_paths(
            val_root,
            has_split_regex) if has_train_val_split else OrderedDict()

        return subj_train_paths, subj_test_paths, subj_val_paths

    def get_preprocessing_transforms(
        self,
        shape: Optional[Tuple[int, int, int]] = None,
        resample: bool = False,
    ) -&gt; tio.Transform:
        &#34;&#34;&#34;
        Get preprocessing transorms to apply to all subjects.

        Returns
        -------
        preprocess : tio.Transform
            All preprocessing steps that should be applied to all subjects.
        &#34;&#34;&#34;
        preprocess_list: List[tio.transforms.Transform] = []

        # Use standard orientation for all images, RAS+
        preprocess_list.append(tio.ToCanonical())

        # If true, resample to T1
        if resample:
            preprocess_list.append(tio.Resample(&#39;T1&#39;))

        if shape is None:
            train_subjects = self.get_subjects(fold=&#34;train&#34;)
            test_subjects = self.get_subjects(fold=&#34;test&#34;)
            shape = self.get_max_shape(train_subjects + test_subjects)
        else:
            shape = self.dims

        preprocess_list.extend([
            tio.RescaleIntensity((-1, 1)),
            tio.CropOrPad(shape),  # (160, 192, 160)
            tio.EnsureShapeMultiple(8),  # better suited for U-Net type Nets
            tio.OneHot()  # for labels
        ])

        return tio.Compose(preprocess_list)

    @staticmethod
    def get_augmentation_transforms() -&gt; tio.Transform:
        &#34;&#34;&#34;&#34;
        Get augmentation transorms to apply to subjects during training.

        Returns
        -------
        augment : tio.Transform
            All augmentation steps that should be applied to subjects during
            training.
        &#34;&#34;&#34;
        augment = tio.Compose([
            tio.RandomAffine(),
            tio.RandomGamma(p=0.5),
            tio.RandomNoise(p=0.5),
            tio.RandomMotion(p=0.1),
            tio.RandomBiasField(p=0.25),
        ])
        return augment

    def default_transforms(
        self,
        stage: Optional[str] = None,
    ) -&gt; tio.Transform:
        &#34;&#34;&#34;
        Default transforms and augmentations for the dataset.

        Parameters
        ----------
        stage: Optional[str]
            Either ``&#39;fit``, ``&#39;validate&#39;``, ``&#39;test&#39;``, or ``&#39;predict&#39;``.
            If stage = None, set-up all stages. Default = None.

        Returns
        -------
        _: tio.Transform
            All preprocessing steps (and if ``&#39;fit&#39;``, augmentation steps too)
            that should be applied to the subjects.
        &#34;&#34;&#34;
        transforms: List[tio.transforms.Transform] = []
        if self.use_preprocessing:
            preprocess = self.get_preprocessing_transforms(
                shape=self.dims,
                resample=self.resample,
            )
            transforms.append(preprocess)
        if (stage == &#34;fit&#34; or stage is None) and self.use_augmentation:
            augment = self.get_augmentation_transforms()
            transforms.append(augment)

        return tio.Compose(transforms)

    def save(self,
             dataloader: DataLoader,
             root: PathType = Path(
                 &#34;/media/cerebro/Workspaces/Students/Eduardo_Diniz/Studies&#34;),
             data_dir: str = &#39;processed_data&#39;,
             step: str = &#39;step01_structural_processing&#39;,
             fold: str = &#34;train&#34;) -&gt; None:
        &#34;&#34;&#34;
        Arguments
        ---------
        root : Path or str, optional
            Root where to save data. Default = ``&#39;~/LocalCerebro&#39;``.
        &#34;&#34;&#34;
        save_root = ensure_exists(
            Path(root).expanduser() / self.study / data_dir / step / fold)

        for batch in dataloader:
            subjects = get_subjects_from_batch(cast(Dict[str, Any], batch))
            for subject in subjects:
                subj_id = subject[&#34;subj_id&#34;]
                scan_id = subject[&#34;scan_id&#34;]
                for image_name in subject.get_images_names():
                    filename = self.intensity2template[image_name].substitute(
                        subj_id=subj_id, scan_id=scan_id)
                    subject[image_name].save(save_root / filename)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule"><code class="flex name class">
<span>class <span class="ident">BrainAgingPredictionDataModule</span></span>
<span>(</span><span>*args: Any, root: Union[str, pathlib.Path] = PosixPath('/media/cerebro/Studies'), study: str = 'Brain_Aging_Prediction', data_dir: str = 'Public/data', step: str = 'step01_structural_processing', train_transforms: Optional[torchio.transforms.transform.Transform] = None, val_transforms: Optional[torchio.transforms.transform.Transform] = None, test_transforms: Optional[torchio.transforms.transform.Transform] = None, use_augmentation: bool = True, use_preprocessing: bool = True, resample: bool = False, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, dims: Tuple[int, int, int] = (160, 192, 160), seed: int = 41, verbose: bool = False, **kwargs: Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Brain Aging Prediction Data Module.</p>
<h2 id="typical-workflow">Typical Workflow</h2>
<p>data = BrainAgingPredictionDataModule()
data.prepare_data() # download
data.setup(stage) # process and split
data.teardown(stage) # clean-up</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>root</code></strong> :&ensp;<code>Path</code> or <code>str</code>, optional</dt>
<dd>Root to GPN's CEREBRO Studies folder.
Default = <code>'/media/cerebro/Studies'</code>.</dd>
<dt><strong><code>study</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Study name. Default = <code>'Brain_Aging_Prediction'</code>.</dd>
<dt><strong><code>data_dir</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Subdirectory where the data is located.
Default = <code>'Public/data'</code>.</dd>
<dt><strong><code>step</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Which processing step to use.
Default = <code>'step01_structural_processing'</code>.</dd>
<dt><strong><code>train_transforms</code></strong> :&ensp;<code>Callable</code>, optional</dt>
<dd>A function/transform that takes in a sample and returns a
transformed version, e.g, <code>torchvision.transforms.RandomCrop</code>.</dd>
<dt><strong><code>val_transforms</code></strong> :&ensp;<code>Callable</code>, optional</dt>
<dd>A function/transform that takes in a sample and returns a
transformed version, e.g, <code>torchvision.transforms.RandomCrop</code>.</dd>
<dt><strong><code>test_transforms</code></strong> :&ensp;<code>Callable</code>, optional</dt>
<dd>A function/transform that takes in a sample and returns a
transformed version, e.g, <code>torchvision.transforms.RandomCrop</code>.</dd>
<dt><strong><code>use_augmentation</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, augment samples during the <code>fit</code> stage.
Default = <code>True</code>.</dd>
<dt><strong><code>use_preprocessing</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, preprocess samples. Default = <code>True</code>.</dd>
<dt><strong><code>resample</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, resample all images to <code>'T1'</code>. Default = <code>False</code>.</dd>
<dt><strong><code>batch_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>How many samples per batch to load. Default = <code>32</code>.</dd>
<dt><strong><code>shuffle</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to shuffle the data at every epoch. Default = <code>False</code>.</dd>
<dt><strong><code>num_workers</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>How many subprocesses to use for data loading. <code>0</code> means that the
data will be loaded in the main process. Default: <code>0</code>.</dd>
<dt><strong><code>pin_memory</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, the data loader will copy Tensors into CUDA pinned memory
before returning them.</dd>
<dt><strong><code>drop_last</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Set to <code>True</code> to drop the last incomplete batch, if the dataset size
is not divisible by the batch size. If <code>False</code> and the size of
dataset is not divisible by the batch size, then the last batch will be
smaller. Default = <code>False</code>.</dd>
<dt><strong><code>num_folds</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of folds. Must be at least <code>2</code>. <code>2</code> corresponds to a single
train/validation split. Default = <code>2</code>.</dd>
<dt><strong><code>val_split</code></strong> :&ensp;<code>int</code> or <code>float</code>, optional</dt>
<dd>If <code>num_folds = 2</code>, then <code>val_split</code> specify how the
train_dataset should be split into train/validation datasets. If
<code>num_folds &gt; 2</code>, then it is not used. Default = <code>0.2</code>.</dd>
<dt><strong><code>intensities</code></strong> :&ensp;<code>List[str]</code>, optional</dt>
<dd>Which intensities to load. Default = <code>['T1']</code>.</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>List[str]</code>, optional</dt>
<dd>Which labels to load. Default = <code>[]</code>.</dd>
<dt><strong><code>dims</code></strong> :&ensp;<code>Tuple[int, int, int]</code>, optional</dt>
<dd>Max spatial dimensions across subjects' images. If <code>None</code>, compute
dimensions from dataset. Default = <code>(160, 192, 160)</code>.</dd>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>When <code>shuffle</code> is True, <code>seed</code> affects the ordering of the indices,
which controls the randomness of each fold. It is also use to seed the
RNG used by RandomSampler to generate random indexes and
multiprocessing to generate <code>base_seed</code> for workers. Pass an int for
reproducible output across multiple function calls. Default = <code>41</code>.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, print debugging messages. Default = <code>False</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BrainAgingPredictionDataModule(VisionDataModule):
    &#34;&#34;&#34;
    Brain Aging Prediction Data Module.

    Typical Workflow
    ----------------
    data = BrainAgingPredictionDataModule()
    data.prepare_data() # download
    data.setup(stage) # process and split
    data.teardown(stage) # clean-up

    Parameters
    ----------
    root : Path or str, optional
        Root to GPN&#39;s CEREBRO Studies folder.
        Default = ``&#39;/media/cerebro/Studies&#39;``.
    study : str, optional
        Study name. Default = ``&#39;Brain_Aging_Prediction&#39;``.
    data_dir : str, optional
        Subdirectory where the data is located.
        Default = ``&#39;Public/data&#39;``.
    step : str, optional
        Which processing step to use.
        Default = ``&#39;step01_structural_processing&#39;``.
    train_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    val_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    test_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    use_augmentation : bool, optional
        If ``True``, augment samples during the ``fit`` stage.
        Default = ``True``.
    use_preprocessing : bool, optional
        If ``True``, preprocess samples. Default = ``True``.
    resample : bool, optional
        If ``True``, resample all images to ``&#39;T1&#39;``. Default = ``False``.
    batch_size : int, optional
        How many samples per batch to load. Default = ``32``.
    shuffle : bool, optional
        Whether to shuffle the data at every epoch. Default = ``False``.
    num_workers : int, optional
        How many subprocesses to use for data loading. ``0`` means that the
        data will be loaded in the main process. Default: ``0``.
    pin_memory : bool, optional
        If ``True``, the data loader will copy Tensors into CUDA pinned memory
        before returning them.
    drop_last : bool, optional
        Set to ``True`` to drop the last incomplete batch, if the dataset size
        is not divisible by the batch size. If ``False`` and the size of
        dataset is not divisible by the batch size, then the last batch will be
        smaller. Default = ``False``.
    num_folds : int, optional
        Number of folds. Must be at least ``2``. ``2`` corresponds to a single
        train/validation split. Default = ``2``.
    val_split : int or float, optional
        If ``num_folds = 2``, then ``val_split`` specify how the
        train_dataset should be split into train/validation datasets. If
        ``num_folds &gt; 2``, then it is not used. Default = ``0.2``.
    intensities : List[str], optional
        Which intensities to load. Default = ``[&#39;T1&#39;]``.
    labels : List[str], optional
        Which labels to load. Default = ``[]``.
    dims : Tuple[int, int, int], optional
        Max spatial dimensions across subjects&#39; images. If ``None``, compute
        dimensions from dataset. Default = ``(160, 192, 160)``.
    seed : int, optional
        When `shuffle` is True, `seed` affects the ordering of the indices,
        which controls the randomness of each fold. It is also use to seed the
        RNG used by RandomSampler to generate random indexes and
        multiprocessing to generate `base_seed` for workers. Pass an int for
        reproducible output across multiple function calls. Default = ``41``.
    verbose : bool, optional
        If ``True``, print debugging messages. Default = ``False``.
    &#34;&#34;&#34;
    name: str = &#34;brain_aging_prediction&#34;
    dataset_cls = tio.SubjectsDataset
    intensity2template = {
        &#34;T1&#34;: Template(&#39;wstrip_m${subj_id}_${scan_id}_T1.nii&#39;),
        &#34;FLAIR&#34;: Template(&#39;wstrip_mr${subj_id}_${scan_id}_FLAIR.nii&#39;),
    }
    label2template: Dict[str, Template] = {}

    def __init__(
        self,
        *args: Any,
        root: PathType = Path(&#39;/media/cerebro/Studies&#39;),
        study: str = &#39;Brain_Aging_Prediction&#39;,
        data_dir: str = &#39;Public/data&#39;,
        step: str = &#39;step01_structural_processing&#39;,
        train_transforms: Optional[tio.Transform] = None,
        val_transforms: Optional[tio.Transform] = None,
        test_transforms: Optional[tio.Transform] = None,
        use_augmentation: bool = True,
        use_preprocessing: bool = True,
        resample: bool = False,
        batch_size: int = 32,
        shuffle: bool = True,
        num_workers: int = 0,
        pin_memory: bool = True,
        drop_last: bool = False,
        num_folds: int = 2,
        val_split: Union[int, float] = 0.2,
        intensities: Optional[List[str]] = None,
        labels: Optional[List[str]] = None,
        dims: Tuple[int, int, int] = (160, 192, 160),
        seed: int = 41,
        verbose: bool = False,
        **kwargs: Any,
    ) -&gt; None:
        root = Path(root) / study / data_dir
        super().__init__(
            *args,
            root=root,
            train_transforms=train_transforms,
            val_transforms=val_transforms,
            test_transforms=test_transforms,
            batch_size=batch_size,
            shuffle=shuffle,
            num_workers=num_workers,
            pin_memory=pin_memory,
            drop_last=drop_last,
            num_folds=num_folds,
            val_split=val_split,
            seed=seed,
            **kwargs,
        )
        self.study = study
        self.data_dir = data_dir
        self.step = step
        self.intensities = intensities if intensities else [&#39;T1&#39;, &#39;FLAIR&#39;]
        self.labels = labels if labels else []
        self.dims = dims
        self.use_augmentation = use_augmentation
        self.use_preprocessing = use_preprocessing
        self.resample = resample
        self.verbose = verbose

    def prepare_data(self, *args: Any, **kwargs: Any) -&gt; None:
        &#34;&#34;&#34;Verify data directory exists and if test/train/val splitted.&#34;&#34;&#34;
        if not is_dir_or_symlink(self.root):
            raise OSError(&#39;Study data directory not found!&#39;)
        self.check_if_data_split(self.step)

    def setup(self, stage: Optional[str] = None) -&gt; None:
        &#34;&#34;&#34;
        Creates train, validation and test collection of samplers.

        Parameters
        ----------
        stage: Optional[str]
            Either ``&#39;fit``, ``&#39;validate&#39;``, or ``&#39;test&#39;``.
            If stage = ``None``, set-up all stages. Default = ``None``.
        &#34;&#34;&#34;
        if stage == &#34;fit&#34; or stage is None:
            train_transforms = self.default_transforms(
                stage=&#34;fit&#34;
            ) if self.train_transforms is None else self.train_transforms

            val_transforms = self.default_transforms(
                stage=&#34;fit&#34;
            ) if self.val_transforms is None else self.val_transforms

            if not self.has_train_val_split:
                train_subjects = self.get_subjects(fold=&#34;train&#34;)
                train_dataset = self.dataset_cls(
                    train_subjects,
                    transform=train_transforms,
                )
                val_dataset = self.dataset_cls(
                    train_subjects,
                    transform=val_transforms,
                )
                self.validation = self.val_cls(
                    train_dataset=train_dataset,
                    val_dataset=val_dataset,
                    batch_size=self.batch_size,
                    shuffle=self.shuffle,
                    num_workers=self.num_workers,
                    pin_memory=self.pin_memory,
                    drop_last=self.drop_last,
                    num_folds=self.num_folds,
                    seed=self.seed,
                )
                self.validation.setup(self.val_split)
                self.has_validation = True
                self.train_dataset = train_dataset
                self.size_train = self.size_train_dataset(
                    self.validation.train_samplers)
                self.val_dataset = val_dataset
                self.size_val = self.size_eval_dataset(
                    self.validation.val_samplers)
            else:
                train_subjects = self.get_subjects(fold=&#34;train&#34;)
                self.train_dataset = self.dataset_cls(
                    train_subjects, transform=train_transforms)
                self.size_train = self.size_train_dataset(self.train_dataset)

                val_subjects = self.get_subjects(fold=&#34;val&#34;)
                self.val_dataset = self.dataset_cls(val_subjects,
                                                    transform=val_transforms)
                self.size_val = self.size_eval_dataset(self.val_dataset)

        if stage == &#34;test&#34; or stage is None:
            test_transforms = self.default_transforms(
                stage=&#34;test&#34;
            ) if self.test_transforms is None else self.test_transforms
            test_subjects = self.get_subjects(fold=&#34;test&#34;)
            self.test_dataset = self.dataset_cls(test_subjects,
                                                 transform=test_transforms)
            self.size_test = self.size_eval_dataset(self.test_dataset)

    def get_subjects(self, fold: str = &#34;train&#34;) -&gt; List[tio.Subject]:
        &#34;&#34;&#34;
        Get train, test, or val list of TorchIO Subjects.

        Parameters
        ----------
        fold : str, optional
            Identify which type of dataset, ``&#39;train&#39;``, ``&#39;test&#39;``, or
            ``&#39;val&#39;``. Default = ``&#39;train&#39;``.

        Returns
        -------
        _ : List[tio.Subject]
            Train, test or val list of TorchIO Subjects.
        &#34;&#34;&#34;
        train_subjs, test_subjs, val_subjs = self.get_subjects_dicts(
            intensities=self.intensities, labels=self.labels)
        if fold == &#34;train&#34;:
            subjs_dict = train_subjs
        elif fold == &#34;test&#34;:
            subjs_dict = test_subjs
        else:
            subjs_dict = val_subjs

        subjects = []
        for _, subject_dict in subjs_dict.items():
            subject = tio.Subject(subject_dict)
            subjects.append(subject)
        return subjects

    def get_subjects_dicts(
        self,
        intensities: Optional[List[str]] = None,
        labels: Optional[List[str]] = None,
    ) -&gt; Tuple[SubjDictType, SubjDictType, SubjDictType]:
        &#34;&#34;&#34;
        Get paths to nii files for train/test/val images and labels.

        Returns
        -------
        _ : {(str, str): Dict}, {(str, str): Dict}, {(str, str): Dict}
            Paths to, respectively, train, test, and val images and labels.
        &#34;&#34;&#34;

        def _get_dict(
            paths_dict: OrderedDict[Tuple[str, str], Path],
            intensities: List[str],
            labels: List[str],
            train: bool = True,
        ) -&gt; SubjDictType:
            subjects_dict: SubjDictType = OrderedDict()
            for (subj_id, scan_id), path in paths_dict.items():
                subjects_dict[(subj_id, scan_id)] = OrderedDict({
                    &#34;subj_id&#34;:
                    subj_id,
                    &#34;scan_id&#34;:
                    scan_id
                })
                for intensity in intensities:
                    intensity_path = path / self.intensity2template[
                        intensity].substitute(subj_id=subj_id, scan_id=scan_id)
                    if intensity_path.is_file():
                        subjects_dict[(subj_id, scan_id)].update(
                            {intensity: tio.ScalarImage(intensity_path)})
                    else:
                        subjects_dict.pop((subj_id, scan_id), None)

                if train:
                    for label in labels:
                        label_path = path / self.label2template[
                            label].substitute(subj_id=subj_id, scan_id=scan_id)
                        if label_path.is_file():
                            subjects_dict[(subj_id, scan_id)].update(
                                {label: tio.LabelMap(label_path)})
                        else:
                            subjects_dict.pop((subj_id, scan_id), None)
            return subjects_dict

        intensities = intensities if intensities else [&#39;T1&#39;, &#39;FLAIR&#39;]
        labels = labels if labels else []

        for intensity in intensities:
            assert intensity in self.intensity2template

        for label in labels:
            assert label in self.label2template

        subj_train_paths, subj_test_paths, subj_val_paths = self.get_paths(
            self.root,
            stem=self.step,
            has_train_test_split=self.has_train_test_split,
            has_train_val_split=self.has_train_val_split,
            shuffle=self.shuffle,
            seed=self.seed,
        )

        subj_train_dict = _get_dict(subj_train_paths,
                                    intensities,
                                    labels,
                                    train=True)
        subj_val_dict = _get_dict(subj_val_paths,
                                  intensities,
                                  labels,
                                  train=True)
        subj_test_dict = _get_dict(subj_test_paths,
                                   intensities,
                                   labels,
                                   train=False)

        return subj_train_dict, subj_test_dict, subj_val_dict

    @staticmethod
    def get_paths(
        data_root: PathType,
        stem: str = &#39;step01_structural_processing&#39;,
        has_train_test_split: bool = False,
        has_train_val_split: bool = False,
        test_split: Union[int, float] = 0.2,
        shuffle: bool = True,
        seed: int = 41,
    ) -&gt; Tuple[SubjPathType, SubjPathType, SubjPathType]:
        &#34;&#34;&#34;
        Get subject and scan IDs and the respective paths from the study data
        directory.

        Returns
        -------
        _ : {(str, str): Path}, {(str, str): Path}, {(str, str): Path}
            Paths for respectively, train, test and images and labels.
        &#34;&#34;&#34;

        def _split_subj_train_paths(
                paths: OrderedDict) -&gt; Tuple[OrderedDict, OrderedDict]:
            &#34;&#34;&#34;Split dictionary into two proportially to `test_split`.&#34;&#34;&#34;
            len_paths = len(paths)
            if isinstance(test_split, int):
                train_len = len_paths - test_split
                splits = [train_len, test_split]
            elif isinstance(test_split, float):
                test_len = int(np.floor(test_split * len_paths))
                train_len = len_paths - test_len
                splits = [train_len, test_len]
            else:
                raise ValueError(f&#34;Unsupported type {type(test_split)}&#34;)
            indexes = list(range(len_paths))
            if shuffle:
                np.random.seed(seed)
                np.random.shuffle(indexes)
            train_idx, test_idx = indexes[:splits[0]], indexes[:splits[1]]

            paths_list = list(paths.items())

            subj_train_paths = OrderedDict([
                value for idx, value in enumerate(paths_list)
                if idx in train_idx
            ])
            subj_test_paths = OrderedDict([
                value for idx, value in enumerate(paths_list)
                if idx in test_idx
            ])
            return subj_train_paths, subj_test_paths

        data_root = Path(data_root)
        subj_pattern = r&#34;[a-zA-z]{3}_[a-zA-Z]{2}_\d{4}&#34;
        scan_pattern = r&#34;[a-zA-z]{4}\d{3}&#34;
        no_split_regex = re.compile(&#34;(&#34; + subj_pattern + &#34;)&#34; + &#34;/&#34; +
                                    subj_pattern + &#34;_&#34; + &#34;(&#34; + scan_pattern +
                                    &#34;)&#34;)
        has_split_regex = re.compile(&#34;(&#34; + subj_pattern + &#34;)&#34; + &#34;_&#34; + &#34;(&#34; +
                                     scan_pattern + &#34;)&#34;)

        def _get_subj_paths(data_root, regex):
            subj_paths = OrderedDict()
            for item in data_root.glob(&#34;*&#34;):
                if not item.is_dir() and not item.name.startswith(&#39;.&#39;):
                    match = regex.search(str(item))
                    if match is not None:
                        subj_id, scan_id = match.groups()
                        subj_paths[(subj_id, scan_id)] = data_root
            return subj_paths

        if not has_train_test_split:
            paths = OrderedDict()
            for item in data_root.glob(&#34;*/*&#34;):
                if item.is_dir() and not item.name.startswith(&#39;.&#39;):
                    match = no_split_regex.search(str(item))
                    if match is not None:
                        subj_id, scan_id = match.groups()
                        paths[(subj_id, scan_id)] = data_root / subj_id / (
                            subj_id + &#34;_&#34; + scan_id) / stem
            subj_train_paths, subj_test_paths = _split_subj_train_paths(paths)
        else:
            train_root = data_root / stem / &#34;train&#34;
            subj_train_paths = _get_subj_paths(train_root, has_split_regex)
            test_root = data_root / stem / &#34;test&#34;
            subj_test_paths = _get_subj_paths(test_root, has_split_regex)

        val_root = data_root / stem / &#34;val&#34;
        subj_val_paths = _get_subj_paths(
            val_root,
            has_split_regex) if has_train_val_split else OrderedDict()

        return subj_train_paths, subj_test_paths, subj_val_paths

    def get_preprocessing_transforms(
        self,
        shape: Optional[Tuple[int, int, int]] = None,
        resample: bool = False,
    ) -&gt; tio.Transform:
        &#34;&#34;&#34;
        Get preprocessing transorms to apply to all subjects.

        Returns
        -------
        preprocess : tio.Transform
            All preprocessing steps that should be applied to all subjects.
        &#34;&#34;&#34;
        preprocess_list: List[tio.transforms.Transform] = []

        # Use standard orientation for all images, RAS+
        preprocess_list.append(tio.ToCanonical())

        # If true, resample to T1
        if resample:
            preprocess_list.append(tio.Resample(&#39;T1&#39;))

        if shape is None:
            train_subjects = self.get_subjects(fold=&#34;train&#34;)
            test_subjects = self.get_subjects(fold=&#34;test&#34;)
            shape = self.get_max_shape(train_subjects + test_subjects)
        else:
            shape = self.dims

        preprocess_list.extend([
            tio.RescaleIntensity((-1, 1)),
            tio.CropOrPad(shape),  # (160, 192, 160)
            tio.EnsureShapeMultiple(8),  # better suited for U-Net type Nets
            tio.OneHot()  # for labels
        ])

        return tio.Compose(preprocess_list)

    @staticmethod
    def get_augmentation_transforms() -&gt; tio.Transform:
        &#34;&#34;&#34;&#34;
        Get augmentation transorms to apply to subjects during training.

        Returns
        -------
        augment : tio.Transform
            All augmentation steps that should be applied to subjects during
            training.
        &#34;&#34;&#34;
        augment = tio.Compose([
            tio.RandomAffine(),
            tio.RandomGamma(p=0.5),
            tio.RandomNoise(p=0.5),
            tio.RandomMotion(p=0.1),
            tio.RandomBiasField(p=0.25),
        ])
        return augment

    def default_transforms(
        self,
        stage: Optional[str] = None,
    ) -&gt; tio.Transform:
        &#34;&#34;&#34;
        Default transforms and augmentations for the dataset.

        Parameters
        ----------
        stage: Optional[str]
            Either ``&#39;fit``, ``&#39;validate&#39;``, ``&#39;test&#39;``, or ``&#39;predict&#39;``.
            If stage = None, set-up all stages. Default = None.

        Returns
        -------
        _: tio.Transform
            All preprocessing steps (and if ``&#39;fit&#39;``, augmentation steps too)
            that should be applied to the subjects.
        &#34;&#34;&#34;
        transforms: List[tio.transforms.Transform] = []
        if self.use_preprocessing:
            preprocess = self.get_preprocessing_transforms(
                shape=self.dims,
                resample=self.resample,
            )
            transforms.append(preprocess)
        if (stage == &#34;fit&#34; or stage is None) and self.use_augmentation:
            augment = self.get_augmentation_transforms()
            transforms.append(augment)

        return tio.Compose(transforms)

    def save(self,
             dataloader: DataLoader,
             root: PathType = Path(
                 &#34;/media/cerebro/Workspaces/Students/Eduardo_Diniz/Studies&#34;),
             data_dir: str = &#39;processed_data&#39;,
             step: str = &#39;step01_structural_processing&#39;,
             fold: str = &#34;train&#34;) -&gt; None:
        &#34;&#34;&#34;
        Arguments
        ---------
        root : Path or str, optional
            Root where to save data. Default = ``&#39;~/LocalCerebro&#39;``.
        &#34;&#34;&#34;
        save_root = ensure_exists(
            Path(root).expanduser() / self.study / data_dir / step / fold)

        for batch in dataloader:
            subjects = get_subjects_from_batch(cast(Dict[str, Any], batch))
            for subject in subjects:
                subj_id = subject[&#34;subj_id&#34;]
                scan_id = subject[&#34;scan_id&#34;]
                for image_name in subject.get_images_names():
                    filename = self.intensity2template[image_name].substitute(
                        subj_id=subj_id, scan_id=scan_id)
                    subject[image_name].save(save_root / filename)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="radio.data.visiondatamodule.VisionDataModule" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule">VisionDataModule</a></li>
<li><a title="radio.data.basedatamodule.BaseDataModule" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule">BaseDataModule</a></li>
<li>pytorch_lightning.core.datamodule.LightningDataModule</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="radio.data.datamodules.brain_aging_prediction_patch.BrainAgingPredictionPatchDataModule" href="brain_aging_prediction_patch.html#radio.data.datamodules.brain_aging_prediction_patch.BrainAgingPredictionPatchDataModule">BrainAgingPredictionPatchDataModule</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.intensity2template"><code class="name">var <span class="ident">intensity2template</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.label2template"><code class="name">var <span class="ident">label2template</span> : Dict[str, string.Template]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_augmentation_transforms"><code class="name flex">
<span>def <span class="ident">get_augmentation_transforms</span></span>(<span>) ‑> torchio.transforms.transform.Transform</span>
</code></dt>
<dd>
<div class="desc"><p>"
Get augmentation transorms to apply to subjects during training.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>augment</code></strong> :&ensp;<code>tio.Transform</code></dt>
<dd>All augmentation steps that should be applied to subjects during
training.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def get_augmentation_transforms() -&gt; tio.Transform:
    &#34;&#34;&#34;&#34;
    Get augmentation transorms to apply to subjects during training.

    Returns
    -------
    augment : tio.Transform
        All augmentation steps that should be applied to subjects during
        training.
    &#34;&#34;&#34;
    augment = tio.Compose([
        tio.RandomAffine(),
        tio.RandomGamma(p=0.5),
        tio.RandomNoise(p=0.5),
        tio.RandomMotion(p=0.1),
        tio.RandomBiasField(p=0.25),
    ])
    return augment</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_paths"><code class="name flex">
<span>def <span class="ident">get_paths</span></span>(<span>data_root: Union[str, pathlib.Path], stem: str = 'step01_structural_processing', has_train_test_split: bool = False, has_train_val_split: bool = False, test_split: Union[int, float] = 0.2, shuffle: bool = True, seed: int = 41) ‑> Tuple[collections.OrderedDict[Tuple[str, str], pathlib.Path], collections.OrderedDict[Tuple[str, str], pathlib.Path], collections.OrderedDict[Tuple[str, str], pathlib.Path]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get subject and scan IDs and the respective paths from the study data
directory.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>{(str, str): Path}, {(str, str): Path}, {(str, str): Path}</code></dt>
<dd>Paths for respectively, train, test and images and labels.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def get_paths(
    data_root: PathType,
    stem: str = &#39;step01_structural_processing&#39;,
    has_train_test_split: bool = False,
    has_train_val_split: bool = False,
    test_split: Union[int, float] = 0.2,
    shuffle: bool = True,
    seed: int = 41,
) -&gt; Tuple[SubjPathType, SubjPathType, SubjPathType]:
    &#34;&#34;&#34;
    Get subject and scan IDs and the respective paths from the study data
    directory.

    Returns
    -------
    _ : {(str, str): Path}, {(str, str): Path}, {(str, str): Path}
        Paths for respectively, train, test and images and labels.
    &#34;&#34;&#34;

    def _split_subj_train_paths(
            paths: OrderedDict) -&gt; Tuple[OrderedDict, OrderedDict]:
        &#34;&#34;&#34;Split dictionary into two proportially to `test_split`.&#34;&#34;&#34;
        len_paths = len(paths)
        if isinstance(test_split, int):
            train_len = len_paths - test_split
            splits = [train_len, test_split]
        elif isinstance(test_split, float):
            test_len = int(np.floor(test_split * len_paths))
            train_len = len_paths - test_len
            splits = [train_len, test_len]
        else:
            raise ValueError(f&#34;Unsupported type {type(test_split)}&#34;)
        indexes = list(range(len_paths))
        if shuffle:
            np.random.seed(seed)
            np.random.shuffle(indexes)
        train_idx, test_idx = indexes[:splits[0]], indexes[:splits[1]]

        paths_list = list(paths.items())

        subj_train_paths = OrderedDict([
            value for idx, value in enumerate(paths_list)
            if idx in train_idx
        ])
        subj_test_paths = OrderedDict([
            value for idx, value in enumerate(paths_list)
            if idx in test_idx
        ])
        return subj_train_paths, subj_test_paths

    data_root = Path(data_root)
    subj_pattern = r&#34;[a-zA-z]{3}_[a-zA-Z]{2}_\d{4}&#34;
    scan_pattern = r&#34;[a-zA-z]{4}\d{3}&#34;
    no_split_regex = re.compile(&#34;(&#34; + subj_pattern + &#34;)&#34; + &#34;/&#34; +
                                subj_pattern + &#34;_&#34; + &#34;(&#34; + scan_pattern +
                                &#34;)&#34;)
    has_split_regex = re.compile(&#34;(&#34; + subj_pattern + &#34;)&#34; + &#34;_&#34; + &#34;(&#34; +
                                 scan_pattern + &#34;)&#34;)

    def _get_subj_paths(data_root, regex):
        subj_paths = OrderedDict()
        for item in data_root.glob(&#34;*&#34;):
            if not item.is_dir() and not item.name.startswith(&#39;.&#39;):
                match = regex.search(str(item))
                if match is not None:
                    subj_id, scan_id = match.groups()
                    subj_paths[(subj_id, scan_id)] = data_root
        return subj_paths

    if not has_train_test_split:
        paths = OrderedDict()
        for item in data_root.glob(&#34;*/*&#34;):
            if item.is_dir() and not item.name.startswith(&#39;.&#39;):
                match = no_split_regex.search(str(item))
                if match is not None:
                    subj_id, scan_id = match.groups()
                    paths[(subj_id, scan_id)] = data_root / subj_id / (
                        subj_id + &#34;_&#34; + scan_id) / stem
        subj_train_paths, subj_test_paths = _split_subj_train_paths(paths)
    else:
        train_root = data_root / stem / &#34;train&#34;
        subj_train_paths = _get_subj_paths(train_root, has_split_regex)
        test_root = data_root / stem / &#34;test&#34;
        subj_test_paths = _get_subj_paths(test_root, has_split_regex)

    val_root = data_root / stem / &#34;val&#34;
    subj_val_paths = _get_subj_paths(
        val_root,
        has_split_regex) if has_train_val_split else OrderedDict()

    return subj_train_paths, subj_test_paths, subj_val_paths</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.default_transforms"><code class="name flex">
<span>def <span class="ident">default_transforms</span></span>(<span>self, stage: Optional[str] = None) ‑> torchio.transforms.transform.Transform</span>
</code></dt>
<dd>
<div class="desc"><p>Default transforms and augmentations for the dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>stage</code></strong> :&ensp;<code>Optional[str]</code></dt>
<dd>Either <code>'fit</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code>.
If stage = None, set-up all stages. Default = None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>tio.Transform</code></dt>
<dd>All preprocessing steps (and if <code>'fit'</code>, augmentation steps too)
that should be applied to the subjects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def default_transforms(
    self,
    stage: Optional[str] = None,
) -&gt; tio.Transform:
    &#34;&#34;&#34;
    Default transforms and augmentations for the dataset.

    Parameters
    ----------
    stage: Optional[str]
        Either ``&#39;fit``, ``&#39;validate&#39;``, ``&#39;test&#39;``, or ``&#39;predict&#39;``.
        If stage = None, set-up all stages. Default = None.

    Returns
    -------
    _: tio.Transform
        All preprocessing steps (and if ``&#39;fit&#39;``, augmentation steps too)
        that should be applied to the subjects.
    &#34;&#34;&#34;
    transforms: List[tio.transforms.Transform] = []
    if self.use_preprocessing:
        preprocess = self.get_preprocessing_transforms(
            shape=self.dims,
            resample=self.resample,
        )
        transforms.append(preprocess)
    if (stage == &#34;fit&#34; or stage is None) and self.use_augmentation:
        augment = self.get_augmentation_transforms()
        transforms.append(augment)

    return tio.Compose(transforms)</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_preprocessing_transforms"><code class="name flex">
<span>def <span class="ident">get_preprocessing_transforms</span></span>(<span>self, shape: Optional[Tuple[int, int, int]] = None, resample: bool = False) ‑> torchio.transforms.transform.Transform</span>
</code></dt>
<dd>
<div class="desc"><p>Get preprocessing transorms to apply to all subjects.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>preprocess</code></strong> :&ensp;<code>tio.Transform</code></dt>
<dd>All preprocessing steps that should be applied to all subjects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_preprocessing_transforms(
    self,
    shape: Optional[Tuple[int, int, int]] = None,
    resample: bool = False,
) -&gt; tio.Transform:
    &#34;&#34;&#34;
    Get preprocessing transorms to apply to all subjects.

    Returns
    -------
    preprocess : tio.Transform
        All preprocessing steps that should be applied to all subjects.
    &#34;&#34;&#34;
    preprocess_list: List[tio.transforms.Transform] = []

    # Use standard orientation for all images, RAS+
    preprocess_list.append(tio.ToCanonical())

    # If true, resample to T1
    if resample:
        preprocess_list.append(tio.Resample(&#39;T1&#39;))

    if shape is None:
        train_subjects = self.get_subjects(fold=&#34;train&#34;)
        test_subjects = self.get_subjects(fold=&#34;test&#34;)
        shape = self.get_max_shape(train_subjects + test_subjects)
    else:
        shape = self.dims

    preprocess_list.extend([
        tio.RescaleIntensity((-1, 1)),
        tio.CropOrPad(shape),  # (160, 192, 160)
        tio.EnsureShapeMultiple(8),  # better suited for U-Net type Nets
        tio.OneHot()  # for labels
    ])

    return tio.Compose(preprocess_list)</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_subjects"><code class="name flex">
<span>def <span class="ident">get_subjects</span></span>(<span>self, fold: str = 'train') ‑> List[torchio.data.subject.Subject]</span>
</code></dt>
<dd>
<div class="desc"><p>Get train, test, or val list of TorchIO Subjects.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fold</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Identify which type of dataset, <code>'train'</code>, <code>'test'</code>, or
<code>'val'</code>. Default = <code>'train'</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>List[tio.Subject]</code></dt>
<dd>Train, test or val list of TorchIO Subjects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_subjects(self, fold: str = &#34;train&#34;) -&gt; List[tio.Subject]:
    &#34;&#34;&#34;
    Get train, test, or val list of TorchIO Subjects.

    Parameters
    ----------
    fold : str, optional
        Identify which type of dataset, ``&#39;train&#39;``, ``&#39;test&#39;``, or
        ``&#39;val&#39;``. Default = ``&#39;train&#39;``.

    Returns
    -------
    _ : List[tio.Subject]
        Train, test or val list of TorchIO Subjects.
    &#34;&#34;&#34;
    train_subjs, test_subjs, val_subjs = self.get_subjects_dicts(
        intensities=self.intensities, labels=self.labels)
    if fold == &#34;train&#34;:
        subjs_dict = train_subjs
    elif fold == &#34;test&#34;:
        subjs_dict = test_subjs
    else:
        subjs_dict = val_subjs

    subjects = []
    for _, subject_dict in subjs_dict.items():
        subject = tio.Subject(subject_dict)
        subjects.append(subject)
    return subjects</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_subjects_dicts"><code class="name flex">
<span>def <span class="ident">get_subjects_dicts</span></span>(<span>self, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None) ‑> Tuple[collections.OrderedDict[Tuple[str, str], collections.OrderedDict[str, Any]], collections.OrderedDict[Tuple[str, str], collections.OrderedDict[str, Any]], collections.OrderedDict[Tuple[str, str], collections.OrderedDict[str, Any]]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get paths to nii files for train/test/val images and labels.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>{(str, str): Dict}, {(str, str): Dict}, {(str, str): Dict}</code></dt>
<dd>Paths to, respectively, train, test, and val images and labels.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_subjects_dicts(
    self,
    intensities: Optional[List[str]] = None,
    labels: Optional[List[str]] = None,
) -&gt; Tuple[SubjDictType, SubjDictType, SubjDictType]:
    &#34;&#34;&#34;
    Get paths to nii files for train/test/val images and labels.

    Returns
    -------
    _ : {(str, str): Dict}, {(str, str): Dict}, {(str, str): Dict}
        Paths to, respectively, train, test, and val images and labels.
    &#34;&#34;&#34;

    def _get_dict(
        paths_dict: OrderedDict[Tuple[str, str], Path],
        intensities: List[str],
        labels: List[str],
        train: bool = True,
    ) -&gt; SubjDictType:
        subjects_dict: SubjDictType = OrderedDict()
        for (subj_id, scan_id), path in paths_dict.items():
            subjects_dict[(subj_id, scan_id)] = OrderedDict({
                &#34;subj_id&#34;:
                subj_id,
                &#34;scan_id&#34;:
                scan_id
            })
            for intensity in intensities:
                intensity_path = path / self.intensity2template[
                    intensity].substitute(subj_id=subj_id, scan_id=scan_id)
                if intensity_path.is_file():
                    subjects_dict[(subj_id, scan_id)].update(
                        {intensity: tio.ScalarImage(intensity_path)})
                else:
                    subjects_dict.pop((subj_id, scan_id), None)

            if train:
                for label in labels:
                    label_path = path / self.label2template[
                        label].substitute(subj_id=subj_id, scan_id=scan_id)
                    if label_path.is_file():
                        subjects_dict[(subj_id, scan_id)].update(
                            {label: tio.LabelMap(label_path)})
                    else:
                        subjects_dict.pop((subj_id, scan_id), None)
        return subjects_dict

    intensities = intensities if intensities else [&#39;T1&#39;, &#39;FLAIR&#39;]
    labels = labels if labels else []

    for intensity in intensities:
        assert intensity in self.intensity2template

    for label in labels:
        assert label in self.label2template

    subj_train_paths, subj_test_paths, subj_val_paths = self.get_paths(
        self.root,
        stem=self.step,
        has_train_test_split=self.has_train_test_split,
        has_train_val_split=self.has_train_val_split,
        shuffle=self.shuffle,
        seed=self.seed,
    )

    subj_train_dict = _get_dict(subj_train_paths,
                                intensities,
                                labels,
                                train=True)
    subj_val_dict = _get_dict(subj_val_paths,
                              intensities,
                              labels,
                              train=True)
    subj_test_dict = _get_dict(subj_test_paths,
                               intensities,
                               labels,
                               train=False)

    return subj_train_dict, subj_test_dict, subj_val_dict</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.prepare_data"><code class="name flex">
<span>def <span class="ident">prepare_data</span></span>(<span>self, *args: Any, **kwargs: Any) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Verify data directory exists and if test/train/val splitted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_data(self, *args: Any, **kwargs: Any) -&gt; None:
    &#34;&#34;&#34;Verify data directory exists and if test/train/val splitted.&#34;&#34;&#34;
    if not is_dir_or_symlink(self.root):
        raise OSError(&#39;Study data directory not found!&#39;)
    self.check_if_data_split(self.step)</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, dataloader: torch.utils.data.dataloader.DataLoader, root: Union[str, pathlib.Path] = PosixPath('/media/cerebro/Workspaces/Students/Eduardo_Diniz/Studies'), data_dir: str = 'processed_data', step: str = 'step01_structural_processing', fold: str = 'train') ‑> None</span>
</code></dt>
<dd>
<div class="desc"><h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>root</code></strong> :&ensp;<code>Path</code> or <code>str</code>, optional</dt>
<dd>Root where to save data. Default = <code>'~/LocalCerebro'</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self,
         dataloader: DataLoader,
         root: PathType = Path(
             &#34;/media/cerebro/Workspaces/Students/Eduardo_Diniz/Studies&#34;),
         data_dir: str = &#39;processed_data&#39;,
         step: str = &#39;step01_structural_processing&#39;,
         fold: str = &#34;train&#34;) -&gt; None:
    &#34;&#34;&#34;
    Arguments
    ---------
    root : Path or str, optional
        Root where to save data. Default = ``&#39;~/LocalCerebro&#39;``.
    &#34;&#34;&#34;
    save_root = ensure_exists(
        Path(root).expanduser() / self.study / data_dir / step / fold)

    for batch in dataloader:
        subjects = get_subjects_from_batch(cast(Dict[str, Any], batch))
        for subject in subjects:
            subj_id = subject[&#34;subj_id&#34;]
            scan_id = subject[&#34;scan_id&#34;]
            for image_name in subject.get_images_names():
                filename = self.intensity2template[image_name].substitute(
                    subj_id=subj_id, scan_id=scan_id)
                subject[image_name].save(save_root / filename)</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.setup"><code class="name flex">
<span>def <span class="ident">setup</span></span>(<span>self, stage: Optional[str] = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Creates train, validation and test collection of samplers.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>stage</code></strong> :&ensp;<code>Optional[str]</code></dt>
<dd>Either <code>'fit</code>, <code>'validate'</code>, or <code>'test'</code>.
If stage = <code>None</code>, set-up all stages. Default = <code>None</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def setup(self, stage: Optional[str] = None) -&gt; None:
    &#34;&#34;&#34;
    Creates train, validation and test collection of samplers.

    Parameters
    ----------
    stage: Optional[str]
        Either ``&#39;fit``, ``&#39;validate&#39;``, or ``&#39;test&#39;``.
        If stage = ``None``, set-up all stages. Default = ``None``.
    &#34;&#34;&#34;
    if stage == &#34;fit&#34; or stage is None:
        train_transforms = self.default_transforms(
            stage=&#34;fit&#34;
        ) if self.train_transforms is None else self.train_transforms

        val_transforms = self.default_transforms(
            stage=&#34;fit&#34;
        ) if self.val_transforms is None else self.val_transforms

        if not self.has_train_val_split:
            train_subjects = self.get_subjects(fold=&#34;train&#34;)
            train_dataset = self.dataset_cls(
                train_subjects,
                transform=train_transforms,
            )
            val_dataset = self.dataset_cls(
                train_subjects,
                transform=val_transforms,
            )
            self.validation = self.val_cls(
                train_dataset=train_dataset,
                val_dataset=val_dataset,
                batch_size=self.batch_size,
                shuffle=self.shuffle,
                num_workers=self.num_workers,
                pin_memory=self.pin_memory,
                drop_last=self.drop_last,
                num_folds=self.num_folds,
                seed=self.seed,
            )
            self.validation.setup(self.val_split)
            self.has_validation = True
            self.train_dataset = train_dataset
            self.size_train = self.size_train_dataset(
                self.validation.train_samplers)
            self.val_dataset = val_dataset
            self.size_val = self.size_eval_dataset(
                self.validation.val_samplers)
        else:
            train_subjects = self.get_subjects(fold=&#34;train&#34;)
            self.train_dataset = self.dataset_cls(
                train_subjects, transform=train_transforms)
            self.size_train = self.size_train_dataset(self.train_dataset)

            val_subjects = self.get_subjects(fold=&#34;val&#34;)
            self.val_dataset = self.dataset_cls(val_subjects,
                                                transform=val_transforms)
            self.size_val = self.size_eval_dataset(self.val_dataset)

    if stage == &#34;test&#34; or stage is None:
        test_transforms = self.default_transforms(
            stage=&#34;test&#34;
        ) if self.test_transforms is None else self.test_transforms
        test_subjects = self.get_subjects(fold=&#34;test&#34;)
        self.test_dataset = self.dataset_cls(test_subjects,
                                             transform=test_transforms)
        self.size_test = self.size_eval_dataset(self.test_dataset)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="radio.data.visiondatamodule.VisionDataModule" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule">VisionDataModule</a></b></code>:
<ul class="hlist">
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.check_if_data_split" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.check_if_data_split">check_if_data_split</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.dataloader" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.dataloader">dataloader</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.dims" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule.dims">dims</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.get_max_shape" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.get_max_shape">get_max_shape</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.predict_dataloader" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.predict_dataloader">predict_dataloader</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.size_eval_dataset" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.size_eval_dataset">size_eval_dataset</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.size_train_dataset" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.size_train_dataset">size_train_dataset</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.teardown" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.teardown">teardown</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.test_dataloader" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.test_dataloader">test_dataloader</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.train_dataloader" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.train_dataloader">train_dataloader</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.val_dataloader" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.val_dataloader">val_dataloader</a></code></li>
</ul>
</li>
<li><code><b><a title="radio.data.basedatamodule.BaseDataModule" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule">BaseDataModule</a></b></code>:
<ul class="hlist">
<li><code><a title="radio.data.basedatamodule.BaseDataModule.dataset_cls" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule.dataset_cls">dataset_cls</a></code></li>
<li><code><a title="radio.data.basedatamodule.BaseDataModule.name" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule.name">name</a></code></li>
</ul>
</li>
<li><code><b><a title="radio.data.basedatamodule.BaseDataModule" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule">BaseDataModule</a></b></code>:
<ul class="hlist">
<li><code><a title="radio.data.basedatamodule.BaseDataModule.EXTRA_ARGS" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule.EXTRA_ARGS">EXTRA_ARGS</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="radio.data.datamodules" href="index.html">radio.data.datamodules</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule">BrainAgingPredictionDataModule</a></code></h4>
<ul class="">
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.default_transforms" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.default_transforms">default_transforms</a></code></li>
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_augmentation_transforms" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_augmentation_transforms">get_augmentation_transforms</a></code></li>
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_paths" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_paths">get_paths</a></code></li>
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_preprocessing_transforms" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_preprocessing_transforms">get_preprocessing_transforms</a></code></li>
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_subjects" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_subjects">get_subjects</a></code></li>
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_subjects_dicts" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.get_subjects_dicts">get_subjects_dicts</a></code></li>
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.intensity2template" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.intensity2template">intensity2template</a></code></li>
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.label2template" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.label2template">label2template</a></code></li>
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.prepare_data" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.prepare_data">prepare_data</a></code></li>
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.save" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.save">save</a></code></li>
<li><code><a title="radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.setup" href="#radio.data.datamodules.brain_aging_prediction.BrainAgingPredictionDataModule.setup">setup</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>