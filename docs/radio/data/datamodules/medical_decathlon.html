<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>radio.data.datamodules.medical_decathlon API documentation</title>
<meta name="description" content="Medical Decathlon Data Module" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>radio.data.datamodules.medical_decathlon</code></h1>
</header>
<section id="section-intro">
<p>Medical Decathlon Data Module</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python
# coding=utf-8
&#34;&#34;&#34;
Medical Decathlon Data Module
&#34;&#34;&#34;

from typing import Optional, Any, Callable, Union, Tuple, List
from pathlib import Path
import random
import matplotlib.pyplot as plt  # type: ignore
import numpy as np
import numpy.typing as npt
import torchio as tio  # type: ignore
from monai.apps import download_and_extract
from radio.settings.pathutils import (DATA_ROOT, is_dir_or_symlink,
                                      ensure_exists, PathType)
from ..visiondatamodule import VisionDataModule

__all__ = [&#34;MedicalDecathlonDataModule&#34;, &#34;plot_train_batch&#34;, &#34;plot_test_batch&#34;]


def plot_train_batch(batch: dict,
                     num_imgs: int = 5,
                     slice_num: int = 24) -&gt; None:
    &#34;&#34;&#34;plot images and labels from a batch of train images&#34;&#34;&#34;
    images, labels = (batch[&#34;image&#34;][&#34;data&#34;], batch[&#34;label&#34;][&#34;data&#34;])
    batch_size = images.shape[0]
    assert num_imgs &lt;= batch_size
    samples = random.sample(range(0, batch_size), num_imgs)

    print(f&#34;image shape: {images.shape[2:]}, label shape: {labels.shape[2:]}&#34;)
    _, axs = plt.subplots(nrows=num_imgs, ncols=2, squeeze=False)
    for row_idx, img_idx in enumerate(samples):
        # Plot image
        axis = axs[row_idx, 0]
        axis.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])
        img = images[img_idx].permute(0, 3, 1, 2).numpy().squeeze()
        axis.imshow(img[slice_num, :, :], cmap=&#34;gray&#34;)
        # Plot label
        axis = axs[row_idx, 1]
        axis.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])
        label = labels[img_idx].permute(0, 3, 1, 2).numpy().squeeze()
        axis.imshow(label[0, slice_num, :, :])

    plt.sca(axs[0, 0])
    plt.title(label=&#34;Images&#34;, size=15)
    plt.sca(axs[0, 1])
    plt.title(label=&#34;Labels&#34;, size=15)
    plt.show()


def plot_test_batch(batch: dict,
                    num_imgs: int = 5,
                    slice_num: int = 24) -&gt; None:
    &#34;&#34;&#34;plot images from a batch of test images&#34;&#34;&#34;
    images = batch[&#34;image&#34;][&#34;data&#34;]
    batch_size = images.shape[0]
    assert num_imgs &lt;= batch_size
    samples = random.sample(range(0, batch_size), num_imgs)

    print(f&#34;image shape: {images.shape[2:]}&#34;)
    _, axs = plt.subplots(nrows=num_imgs, ncols=1, squeeze=False)
    for row_idx, img_idx in enumerate(samples):
        # Plot image
        axis = axs[row_idx, 0]
        axis.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])
        img = images[img_idx].permute(0, 3, 1, 2).numpy().squeeze()
        axis.imshow(img[slice_num, :, :], cmap=&#34;gray&#34;)

    plt.sca(axs[0, 0])
    plt.title(label=&#34;Images&#34;, size=15)
    plt.show()


class MedicalDecathlonDataModule(VisionDataModule):
    &#34;&#34;&#34;
    Medical Decathlon Data Module.

    Typical Workflow
    ----------------
    medicaldecathlon = MedicalDecathlonDataModule()
    medicaldecathlon.prepare_data() # download
    medicaldecathlon.setup(stage) # process and split
    medicaldecathlon.teardown(stage) # clean-up

    Parameters
    ----------
    root : Path or str, optional
        Root directory of dataset. If None, a temporary directory will be used.
        Default = ``DATA_ROOT / &#39;medical_decathlon&#39;``.
    task : str, optional
        Which task to download and execute. One of
        ``&#39;Task01_BrainTumour&#39;``,
        ``&#39;Task02_Heart&#39;``,
        ``&#39;Task03_Liver&#39;``,
        ``&#39;Task04_Hippocampus&#39;``,
        ``&#39;Task05_Prostate&#39;``,
        ``&#39;Task06_Lung&#39;``,
        ``&#39;Task07_Pancreas&#39;``,
        ``&#39;Task08_HepaticVessel&#39;``,
        ``&#39;Task09_Spleen&#39;``, and
        ``&#39;Task10_Colon&#39;``.
        Default = ``&#39;Task04_Hippocampus&#39;``.
        See = http://medicaldecathlon.com/#tasks.
    train_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    val_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    test_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    use_augmentation : bool, optional
        If ``True``, augment samples during the ``fit`` stage.
        Default = ``True``.
    batch_size : int, optional
        How many samples per batch to load. Default = ``32``.
    shuffle : bool, optional
        Whether to shuffle the data at every epoch. Default = ``False``.
    num_workers : int, optional
        How many subprocesses to use for data loading. ``0`` means that the
        data will be loaded in the main process. Default: ``0``.
    pin_memory : bool, optional
        If ``True``, the data loader will copy Tensors into CUDA pinned memory
        before returning them.
    drop_last : bool, optional
        Set to ``True`` to drop the last incomplete batch, if the dataset size
        is not divisible by the batch size. If ``False`` and the size of
        dataset is not divisible by the batch size, then the last batch will be
        smaller. Default = ``False``.
    num_folds : int, optional
        Number of folds. Must be at least ``2``. ``2`` corresponds to a single
        train/validation split. Default = ``2``.
    val_split: int or float, optional
        If ``num_folds = 2``, then ``val_split`` specify how the
        train_dataset should be split into train/validation datasets. If
        ``num_folds &gt; 2``, then it is not used. Default = ``0.2``.
    seed : int, optional
        When `shuffle` is True, `seed` affects the ordering of the indices,
        which controls the randomness of each fold. It is also use to seed the
        RNG used by RandomSampler to generate random indexes and
        multiprocessing to generate `base_seed` for workers. Pass an int for
        reproducible output across multiple function calls. Default = ``41``.
    &#34;&#34;&#34;
    name: str = &#34;medicaldecathlon&#34;
    dataset_cls = tio.SubjectsDataset

    def __init__(
        self,
        *args: Any,
        root: PathType = DATA_ROOT / &#39;medical_decathlon&#39;,
        task: str = &#39;Task04_Hippocampus&#39;,
        train_transforms: Optional[Callable] = None,
        val_transforms: Optional[Callable] = None,
        test_transforms: Optional[Callable] = None,
        use_augmentation: bool = True,
        batch_size: int = 32,
        shuffle: bool = True,
        num_workers: int = 0,
        pin_memory: bool = True,
        drop_last: bool = False,
        num_folds: int = 2,
        val_split: Union[int, float] = 0.2,
        seed: int = 41,
        **kwargs: Any,
    ) -&gt; None:
        super().__init__(*args,
                         root=root,
                         train_transforms=train_transforms,
                         val_transforms=val_transforms,
                         test_transforms=test_transforms,
                         batch_size=batch_size,
                         shuffle=shuffle,
                         num_workers=num_workers,
                         pin_memory=pin_memory,
                         drop_last=drop_last,
                         num_folds=num_folds,
                         val_split=val_split,
                         seed=seed,
                         **kwargs)
        self.use_augmentation = use_augmentation
        self.task = task
        self.task_dir = self.root / task

    def get_max_shape(self,
                      subjects: List[tio.Subject]) -&gt; npt.NDArray[np.int_]:
        &#34;&#34;&#34;
        Get max shape.

        Parameters
        ----------
        subjects : List[tio.Subject]
            List of TorchIO Subject objects.

        Returns
        -------
        _ : np.ndarray((1, 3), np.int_)
            Max height, width and depth across all subjects.
        &#34;&#34;&#34;
        dataset = self.dataset_cls(subjects)
        shapes = np.array([subject.spatial_shape for subject in dataset])
        return shapes.max(axis=0)

    def prepare_data(self, *args: Any, **kwargs: Any) -&gt; None:
        &#34;&#34;&#34;Saves files to task data directory.&#34;&#34;&#34;
        if not is_dir_or_symlink(self.task_dir):
            url = (&#39;https://msd-for-monai.s3-us-west-2.amazonaws.com/&#39; +
                   f&#39;{self.task}.tar&#39;)
            output_dir = ensure_exists(self.root)
            download_and_extract(url=url, output_dir=output_dir)

    def setup(self, stage: Optional[str] = None) -&gt; None:
        &#34;&#34;&#34;
        Creates train, validation and test collection of samplers.

        Parameters
        ----------
        stage: Optional[str]
            Either ``&#39;fit``, ``&#39;validate&#39;``, ``&#39;test&#39;``, or ``&#39;predict&#39;``.
            If stage = None, set-up all stages. Default = None.
        &#34;&#34;&#34;
        dims = []
        if stage == &#34;fit&#34; or stage is None:
            train_transforms = (self.default_transforms()
                                if self.train_transforms is None else
                                self.train_transforms)

            val_transforms = (self.default_transforms()
                              if self.val_transforms is None else
                              self.val_transforms)

            train_subjects = self.get_subjects()
            dims.append([self.get_max_shape(train_subjects)])
            self.train_dataset = self.dataset_cls(train_subjects,
                                                  transform=train_transforms)
            self.val_dataset = self.dataset_cls(train_subjects,
                                                transform=val_transforms)

            self.validation = self.val_cls(train_dataset=self.train_dataset,
                                           val_dataset=self.val_dataset,
                                           batch_size=self.batch_size,
                                           shuffle=self.shuffle,
                                           num_workers=self.num_workers,
                                           pin_memory=self.pin_memory,
                                           drop_last=self.drop_last,
                                           num_folds=self.num_folds,
                                           seed=self.seed)

            self.validation.setup(self.val_split)
            self.size_train = self.validation.size_train
            self.size_val = self.validation.size_val

        if stage == &#34;test&#34; or stage is None:
            test_transforms = (self.default_transforms()
                               if self.test_transforms is None else
                               self.test_transforms)
            test_subjects = self.get_subjects(train=False)
            dims.append([self.get_max_shape(test_subjects)])
            test_dataset = self.dataset_cls(test_subjects,
                                            transform=test_transforms)
            self.test_datasets.append(test_dataset)
            self.test_datasets.append(test_dataset)
            self.size_test = min([len(data) for data in self.test_datasets])

        if stage == &#34;predict&#34; or stage is None:
            predict_transforms = (self.default_transforms()
                                  if self.test_transforms is None else
                                  self.test_transforms)
            predict_subjects = self.get_subjects(train=False)
            predict_dataset = self.dataset_cls(predict_subjects,
                                               transform=predict_transforms)
            self.predict_datasets.append(predict_dataset)
            self.size_predict = min(
                [len(data) for data in self.predict_datasets])

        self.dims = np.concatenate(dims, axis=0).max(axis=0)

    @staticmethod
    def get_niis(directory: Path) -&gt; List[Path]:
        &#34;&#34;&#34;Get paths to nii files in the given directory.&#34;&#34;&#34;
        return sorted(path for path in directory.glob(&#39;*.nii*&#39;)
                      if not path.name.startswith(&#39;.&#39;))

    def get_train_paths(self) -&gt; Tuple[List[Path], List[Path]]:
        &#34;&#34;&#34;
        Get paths to nii files for train images and labels.

        Returns
        -------
        _ : Tuple[List[Path], List[Path]]
            Paths to train images and labels.
        &#34;&#34;&#34;
        image_training_paths = self.get_niis(self.task_dir / &#39;imagesTr&#39;)
        label_training_paths = self.get_niis(self.task_dir / &#39;labelsTr&#39;)
        return image_training_paths, label_training_paths

    def get_test_paths(self) -&gt; List[Path]:
        &#34;&#34;&#34;
        Get paths to nii files for test images.

        Returns
        -------
        _ : List[Path]
            Paths to test images.
        &#34;&#34;&#34;
        image_test_paths = self.get_niis(self.task_dir / &#39;imagesTs&#39;)
        return image_test_paths

    def get_subjects(self, train: bool = True) -&gt; List[tio.Subject]:
        &#34;&#34;&#34;
        Get TorchIO Subject train and test subjects.

        Parameters
        ----------
        train : bool, optional
            If True, return a loader for the train dataset, else for the
            validation dataset. Default = ``True``.

        Returns
        -------
        _ : List[tio.Subject]
            TorchIO Subject train or test subjects.
        &#34;&#34;&#34;
        if train:
            train_img_paths, train_label_paths = self.get_train_paths()
            train_subjects = []
            for image_path, label_path in zip(train_img_paths,
                                              train_label_paths):
                # &#39;image&#39; and &#39;label&#39; are arbitrary names for the images
                subject = tio.Subject(image=tio.ScalarImage(image_path),
                                      label=tio.LabelMap(label_path))
                train_subjects.append(subject)
            return train_subjects

        test_img_paths = self.get_test_paths()
        test_subjects = []
        for image_path in test_img_paths:
            subject = tio.Subject(image=tio.ScalarImage(image_path))
            test_subjects.append(subject)

        return test_subjects

    def get_preprocessing_transforms(self) -&gt; Callable:
        &#34;&#34;&#34;
        Get preprocessing transorms to apply to all subjects.

        Returns
        -------
        preprocess : tio.Compose
            All preprocessing steps that should be applied to all subjects.
        &#34;&#34;&#34;
        train_subjects = self.get_subjects()
        test_subjects = self.get_subjects(train=False)
        preprocess = tio.Compose([
            tio.RescaleIntensity((-1, 1)),
            tio.CropOrPad(self.get_max_shape(train_subjects + test_subjects)),
            tio.EnsureShapeMultiple(8),  # for the U-Net
            tio.OneHot(),
        ])
        return preprocess

    @staticmethod
    def get_augmentation_transforms() -&gt; Callable:
        &#34;&#34;&#34;&#34;
        Get augmentation transorms to apply to subjects during training.

        Returns
        -------
        augment : tio.Compose
            All augmentation steps that should be applied to subjects during
            training.
        &#34;&#34;&#34;
        augment = tio.Compose([
            tio.RandomAffine(),
            tio.RandomGamma(p=0.5),
            tio.RandomNoise(p=0.5),
            tio.RandomMotion(p=0.1),
            tio.RandomBiasField(p=0.25),
        ])
        return augment

    def default_transforms(self, stage: Optional[str] = None) -&gt; Callable:
        &#34;&#34;&#34;
        Default transforms and augmentations for the dataset.

        Parameters
        ----------
        stage: Optional[str]
            Either ``&#39;fit``, ``&#39;validate&#39;``, ``&#39;test&#39;``, or ``&#39;predict&#39;``.
            If stage = None, set-up all stages. Default = None.

        Returns
        -------
        _: Callable
            All preprocessing steps (and if ``&#39;fit&#39;``, augmentation steps too)
            that should be applied to the subjects.
        &#34;&#34;&#34;
        transforms = []
        preprocess = self.get_preprocessing_transforms()
        transforms.append(preprocess)
        if stage == &#34;fit&#34; or stage is None and self.use_augmentation:
            augment = self.get_augmentation_transforms()
            transforms.append(augment)

        return tio.Compose(transforms)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="radio.data.datamodules.medical_decathlon.plot_test_batch"><code class="name flex">
<span>def <span class="ident">plot_test_batch</span></span>(<span>batch: dict, num_imgs: int = 5, slice_num: int = 24) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>plot images from a batch of test images</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_test_batch(batch: dict,
                    num_imgs: int = 5,
                    slice_num: int = 24) -&gt; None:
    &#34;&#34;&#34;plot images from a batch of test images&#34;&#34;&#34;
    images = batch[&#34;image&#34;][&#34;data&#34;]
    batch_size = images.shape[0]
    assert num_imgs &lt;= batch_size
    samples = random.sample(range(0, batch_size), num_imgs)

    print(f&#34;image shape: {images.shape[2:]}&#34;)
    _, axs = plt.subplots(nrows=num_imgs, ncols=1, squeeze=False)
    for row_idx, img_idx in enumerate(samples):
        # Plot image
        axis = axs[row_idx, 0]
        axis.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])
        img = images[img_idx].permute(0, 3, 1, 2).numpy().squeeze()
        axis.imshow(img[slice_num, :, :], cmap=&#34;gray&#34;)

    plt.sca(axs[0, 0])
    plt.title(label=&#34;Images&#34;, size=15)
    plt.show()</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.medical_decathlon.plot_train_batch"><code class="name flex">
<span>def <span class="ident">plot_train_batch</span></span>(<span>batch: dict, num_imgs: int = 5, slice_num: int = 24) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>plot images and labels from a batch of train images</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_train_batch(batch: dict,
                     num_imgs: int = 5,
                     slice_num: int = 24) -&gt; None:
    &#34;&#34;&#34;plot images and labels from a batch of train images&#34;&#34;&#34;
    images, labels = (batch[&#34;image&#34;][&#34;data&#34;], batch[&#34;label&#34;][&#34;data&#34;])
    batch_size = images.shape[0]
    assert num_imgs &lt;= batch_size
    samples = random.sample(range(0, batch_size), num_imgs)

    print(f&#34;image shape: {images.shape[2:]}, label shape: {labels.shape[2:]}&#34;)
    _, axs = plt.subplots(nrows=num_imgs, ncols=2, squeeze=False)
    for row_idx, img_idx in enumerate(samples):
        # Plot image
        axis = axs[row_idx, 0]
        axis.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])
        img = images[img_idx].permute(0, 3, 1, 2).numpy().squeeze()
        axis.imshow(img[slice_num, :, :], cmap=&#34;gray&#34;)
        # Plot label
        axis = axs[row_idx, 1]
        axis.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])
        label = labels[img_idx].permute(0, 3, 1, 2).numpy().squeeze()
        axis.imshow(label[0, slice_num, :, :])

    plt.sca(axs[0, 0])
    plt.title(label=&#34;Images&#34;, size=15)
    plt.sca(axs[0, 1])
    plt.title(label=&#34;Labels&#34;, size=15)
    plt.show()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule"><code class="flex name class">
<span>class <span class="ident">MedicalDecathlonDataModule</span></span>
<span>(</span><span>*args: Any, root: Union[str, pathlib.Path] = PosixPath('/home/wangl15@acct.upmchs.net/radio/dataset/medical_decathlon'), task: str = 'Task04_Hippocampus', train_transforms: Optional[Callable] = None, val_transforms: Optional[Callable] = None, test_transforms: Optional[Callable] = None, use_augmentation: bool = True, batch_size: int = 32, shuffle: bool = True, num_workers: int = 0, pin_memory: bool = True, drop_last: bool = False, num_folds: int = 2, val_split: Union[int, float] = 0.2, seed: int = 41, **kwargs: Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Medical Decathlon Data Module.</p>
<h2 id="typical-workflow">Typical Workflow</h2>
<p>medicaldecathlon = MedicalDecathlonDataModule()
medicaldecathlon.prepare_data() # download
medicaldecathlon.setup(stage) # process and split
medicaldecathlon.teardown(stage) # clean-up</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>root</code></strong> :&ensp;<code>Path</code> or <code>str</code>, optional</dt>
<dd>Root directory of dataset. If None, a temporary directory will be used.
Default = <code>DATA_ROOT / 'medical_decathlon'</code>.</dd>
<dt><strong><code>task</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Which task to download and execute. One of
<code>'Task01_BrainTumour'</code>,
<code>'Task02_Heart'</code>,
<code>'Task03_Liver'</code>,
<code>'Task04_Hippocampus'</code>,
<code>'Task05_Prostate'</code>,
<code>'Task06_Lung'</code>,
<code>'Task07_Pancreas'</code>,
<code>'Task08_HepaticVessel'</code>,
<code>'Task09_Spleen'</code>, and
<code>'Task10_Colon'</code>.
Default = <code>'Task04_Hippocampus'</code>.
See = <a href="http://medicaldecathlon.com/#tasks.">http://medicaldecathlon.com/#tasks.</a></dd>
<dt><strong><code>train_transforms</code></strong> :&ensp;<code>Callable</code>, optional</dt>
<dd>A function/transform that takes in a sample and returns a
transformed version, e.g, <code>torchvision.transforms.RandomCrop</code>.</dd>
<dt><strong><code>val_transforms</code></strong> :&ensp;<code>Callable</code>, optional</dt>
<dd>A function/transform that takes in a sample and returns a
transformed version, e.g, <code>torchvision.transforms.RandomCrop</code>.</dd>
<dt><strong><code>test_transforms</code></strong> :&ensp;<code>Callable</code>, optional</dt>
<dd>A function/transform that takes in a sample and returns a
transformed version, e.g, <code>torchvision.transforms.RandomCrop</code>.</dd>
<dt><strong><code>use_augmentation</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, augment samples during the <code>fit</code> stage.
Default = <code>True</code>.</dd>
<dt><strong><code>batch_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>How many samples per batch to load. Default = <code>32</code>.</dd>
<dt><strong><code>shuffle</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to shuffle the data at every epoch. Default = <code>False</code>.</dd>
<dt><strong><code>num_workers</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>How many subprocesses to use for data loading. <code>0</code> means that the
data will be loaded in the main process. Default: <code>0</code>.</dd>
<dt><strong><code>pin_memory</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, the data loader will copy Tensors into CUDA pinned memory
before returning them.</dd>
<dt><strong><code>drop_last</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Set to <code>True</code> to drop the last incomplete batch, if the dataset size
is not divisible by the batch size. If <code>False</code> and the size of
dataset is not divisible by the batch size, then the last batch will be
smaller. Default = <code>False</code>.</dd>
<dt><strong><code>num_folds</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of folds. Must be at least <code>2</code>. <code>2</code> corresponds to a single
train/validation split. Default = <code>2</code>.</dd>
<dt><strong><code>val_split</code></strong> :&ensp;<code>int</code> or <code>float</code>, optional</dt>
<dd>If <code>num_folds = 2</code>, then <code>val_split</code> specify how the
train_dataset should be split into train/validation datasets. If
<code>num_folds &gt; 2</code>, then it is not used. Default = <code>0.2</code>.</dd>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>When <code>shuffle</code> is True, <code>seed</code> affects the ordering of the indices,
which controls the randomness of each fold. It is also use to seed the
RNG used by RandomSampler to generate random indexes and
multiprocessing to generate <code>base_seed</code> for workers. Pass an int for
reproducible output across multiple function calls. Default = <code>41</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MedicalDecathlonDataModule(VisionDataModule):
    &#34;&#34;&#34;
    Medical Decathlon Data Module.

    Typical Workflow
    ----------------
    medicaldecathlon = MedicalDecathlonDataModule()
    medicaldecathlon.prepare_data() # download
    medicaldecathlon.setup(stage) # process and split
    medicaldecathlon.teardown(stage) # clean-up

    Parameters
    ----------
    root : Path or str, optional
        Root directory of dataset. If None, a temporary directory will be used.
        Default = ``DATA_ROOT / &#39;medical_decathlon&#39;``.
    task : str, optional
        Which task to download and execute. One of
        ``&#39;Task01_BrainTumour&#39;``,
        ``&#39;Task02_Heart&#39;``,
        ``&#39;Task03_Liver&#39;``,
        ``&#39;Task04_Hippocampus&#39;``,
        ``&#39;Task05_Prostate&#39;``,
        ``&#39;Task06_Lung&#39;``,
        ``&#39;Task07_Pancreas&#39;``,
        ``&#39;Task08_HepaticVessel&#39;``,
        ``&#39;Task09_Spleen&#39;``, and
        ``&#39;Task10_Colon&#39;``.
        Default = ``&#39;Task04_Hippocampus&#39;``.
        See = http://medicaldecathlon.com/#tasks.
    train_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    val_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    test_transforms : Callable, optional
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    use_augmentation : bool, optional
        If ``True``, augment samples during the ``fit`` stage.
        Default = ``True``.
    batch_size : int, optional
        How many samples per batch to load. Default = ``32``.
    shuffle : bool, optional
        Whether to shuffle the data at every epoch. Default = ``False``.
    num_workers : int, optional
        How many subprocesses to use for data loading. ``0`` means that the
        data will be loaded in the main process. Default: ``0``.
    pin_memory : bool, optional
        If ``True``, the data loader will copy Tensors into CUDA pinned memory
        before returning them.
    drop_last : bool, optional
        Set to ``True`` to drop the last incomplete batch, if the dataset size
        is not divisible by the batch size. If ``False`` and the size of
        dataset is not divisible by the batch size, then the last batch will be
        smaller. Default = ``False``.
    num_folds : int, optional
        Number of folds. Must be at least ``2``. ``2`` corresponds to a single
        train/validation split. Default = ``2``.
    val_split: int or float, optional
        If ``num_folds = 2``, then ``val_split`` specify how the
        train_dataset should be split into train/validation datasets. If
        ``num_folds &gt; 2``, then it is not used. Default = ``0.2``.
    seed : int, optional
        When `shuffle` is True, `seed` affects the ordering of the indices,
        which controls the randomness of each fold. It is also use to seed the
        RNG used by RandomSampler to generate random indexes and
        multiprocessing to generate `base_seed` for workers. Pass an int for
        reproducible output across multiple function calls. Default = ``41``.
    &#34;&#34;&#34;
    name: str = &#34;medicaldecathlon&#34;
    dataset_cls = tio.SubjectsDataset

    def __init__(
        self,
        *args: Any,
        root: PathType = DATA_ROOT / &#39;medical_decathlon&#39;,
        task: str = &#39;Task04_Hippocampus&#39;,
        train_transforms: Optional[Callable] = None,
        val_transforms: Optional[Callable] = None,
        test_transforms: Optional[Callable] = None,
        use_augmentation: bool = True,
        batch_size: int = 32,
        shuffle: bool = True,
        num_workers: int = 0,
        pin_memory: bool = True,
        drop_last: bool = False,
        num_folds: int = 2,
        val_split: Union[int, float] = 0.2,
        seed: int = 41,
        **kwargs: Any,
    ) -&gt; None:
        super().__init__(*args,
                         root=root,
                         train_transforms=train_transforms,
                         val_transforms=val_transforms,
                         test_transforms=test_transforms,
                         batch_size=batch_size,
                         shuffle=shuffle,
                         num_workers=num_workers,
                         pin_memory=pin_memory,
                         drop_last=drop_last,
                         num_folds=num_folds,
                         val_split=val_split,
                         seed=seed,
                         **kwargs)
        self.use_augmentation = use_augmentation
        self.task = task
        self.task_dir = self.root / task

    def get_max_shape(self,
                      subjects: List[tio.Subject]) -&gt; npt.NDArray[np.int_]:
        &#34;&#34;&#34;
        Get max shape.

        Parameters
        ----------
        subjects : List[tio.Subject]
            List of TorchIO Subject objects.

        Returns
        -------
        _ : np.ndarray((1, 3), np.int_)
            Max height, width and depth across all subjects.
        &#34;&#34;&#34;
        dataset = self.dataset_cls(subjects)
        shapes = np.array([subject.spatial_shape for subject in dataset])
        return shapes.max(axis=0)

    def prepare_data(self, *args: Any, **kwargs: Any) -&gt; None:
        &#34;&#34;&#34;Saves files to task data directory.&#34;&#34;&#34;
        if not is_dir_or_symlink(self.task_dir):
            url = (&#39;https://msd-for-monai.s3-us-west-2.amazonaws.com/&#39; +
                   f&#39;{self.task}.tar&#39;)
            output_dir = ensure_exists(self.root)
            download_and_extract(url=url, output_dir=output_dir)

    def setup(self, stage: Optional[str] = None) -&gt; None:
        &#34;&#34;&#34;
        Creates train, validation and test collection of samplers.

        Parameters
        ----------
        stage: Optional[str]
            Either ``&#39;fit``, ``&#39;validate&#39;``, ``&#39;test&#39;``, or ``&#39;predict&#39;``.
            If stage = None, set-up all stages. Default = None.
        &#34;&#34;&#34;
        dims = []
        if stage == &#34;fit&#34; or stage is None:
            train_transforms = (self.default_transforms()
                                if self.train_transforms is None else
                                self.train_transforms)

            val_transforms = (self.default_transforms()
                              if self.val_transforms is None else
                              self.val_transforms)

            train_subjects = self.get_subjects()
            dims.append([self.get_max_shape(train_subjects)])
            self.train_dataset = self.dataset_cls(train_subjects,
                                                  transform=train_transforms)
            self.val_dataset = self.dataset_cls(train_subjects,
                                                transform=val_transforms)

            self.validation = self.val_cls(train_dataset=self.train_dataset,
                                           val_dataset=self.val_dataset,
                                           batch_size=self.batch_size,
                                           shuffle=self.shuffle,
                                           num_workers=self.num_workers,
                                           pin_memory=self.pin_memory,
                                           drop_last=self.drop_last,
                                           num_folds=self.num_folds,
                                           seed=self.seed)

            self.validation.setup(self.val_split)
            self.size_train = self.validation.size_train
            self.size_val = self.validation.size_val

        if stage == &#34;test&#34; or stage is None:
            test_transforms = (self.default_transforms()
                               if self.test_transforms is None else
                               self.test_transforms)
            test_subjects = self.get_subjects(train=False)
            dims.append([self.get_max_shape(test_subjects)])
            test_dataset = self.dataset_cls(test_subjects,
                                            transform=test_transforms)
            self.test_datasets.append(test_dataset)
            self.test_datasets.append(test_dataset)
            self.size_test = min([len(data) for data in self.test_datasets])

        if stage == &#34;predict&#34; or stage is None:
            predict_transforms = (self.default_transforms()
                                  if self.test_transforms is None else
                                  self.test_transforms)
            predict_subjects = self.get_subjects(train=False)
            predict_dataset = self.dataset_cls(predict_subjects,
                                               transform=predict_transforms)
            self.predict_datasets.append(predict_dataset)
            self.size_predict = min(
                [len(data) for data in self.predict_datasets])

        self.dims = np.concatenate(dims, axis=0).max(axis=0)

    @staticmethod
    def get_niis(directory: Path) -&gt; List[Path]:
        &#34;&#34;&#34;Get paths to nii files in the given directory.&#34;&#34;&#34;
        return sorted(path for path in directory.glob(&#39;*.nii*&#39;)
                      if not path.name.startswith(&#39;.&#39;))

    def get_train_paths(self) -&gt; Tuple[List[Path], List[Path]]:
        &#34;&#34;&#34;
        Get paths to nii files for train images and labels.

        Returns
        -------
        _ : Tuple[List[Path], List[Path]]
            Paths to train images and labels.
        &#34;&#34;&#34;
        image_training_paths = self.get_niis(self.task_dir / &#39;imagesTr&#39;)
        label_training_paths = self.get_niis(self.task_dir / &#39;labelsTr&#39;)
        return image_training_paths, label_training_paths

    def get_test_paths(self) -&gt; List[Path]:
        &#34;&#34;&#34;
        Get paths to nii files for test images.

        Returns
        -------
        _ : List[Path]
            Paths to test images.
        &#34;&#34;&#34;
        image_test_paths = self.get_niis(self.task_dir / &#39;imagesTs&#39;)
        return image_test_paths

    def get_subjects(self, train: bool = True) -&gt; List[tio.Subject]:
        &#34;&#34;&#34;
        Get TorchIO Subject train and test subjects.

        Parameters
        ----------
        train : bool, optional
            If True, return a loader for the train dataset, else for the
            validation dataset. Default = ``True``.

        Returns
        -------
        _ : List[tio.Subject]
            TorchIO Subject train or test subjects.
        &#34;&#34;&#34;
        if train:
            train_img_paths, train_label_paths = self.get_train_paths()
            train_subjects = []
            for image_path, label_path in zip(train_img_paths,
                                              train_label_paths):
                # &#39;image&#39; and &#39;label&#39; are arbitrary names for the images
                subject = tio.Subject(image=tio.ScalarImage(image_path),
                                      label=tio.LabelMap(label_path))
                train_subjects.append(subject)
            return train_subjects

        test_img_paths = self.get_test_paths()
        test_subjects = []
        for image_path in test_img_paths:
            subject = tio.Subject(image=tio.ScalarImage(image_path))
            test_subjects.append(subject)

        return test_subjects

    def get_preprocessing_transforms(self) -&gt; Callable:
        &#34;&#34;&#34;
        Get preprocessing transorms to apply to all subjects.

        Returns
        -------
        preprocess : tio.Compose
            All preprocessing steps that should be applied to all subjects.
        &#34;&#34;&#34;
        train_subjects = self.get_subjects()
        test_subjects = self.get_subjects(train=False)
        preprocess = tio.Compose([
            tio.RescaleIntensity((-1, 1)),
            tio.CropOrPad(self.get_max_shape(train_subjects + test_subjects)),
            tio.EnsureShapeMultiple(8),  # for the U-Net
            tio.OneHot(),
        ])
        return preprocess

    @staticmethod
    def get_augmentation_transforms() -&gt; Callable:
        &#34;&#34;&#34;&#34;
        Get augmentation transorms to apply to subjects during training.

        Returns
        -------
        augment : tio.Compose
            All augmentation steps that should be applied to subjects during
            training.
        &#34;&#34;&#34;
        augment = tio.Compose([
            tio.RandomAffine(),
            tio.RandomGamma(p=0.5),
            tio.RandomNoise(p=0.5),
            tio.RandomMotion(p=0.1),
            tio.RandomBiasField(p=0.25),
        ])
        return augment

    def default_transforms(self, stage: Optional[str] = None) -&gt; Callable:
        &#34;&#34;&#34;
        Default transforms and augmentations for the dataset.

        Parameters
        ----------
        stage: Optional[str]
            Either ``&#39;fit``, ``&#39;validate&#39;``, ``&#39;test&#39;``, or ``&#39;predict&#39;``.
            If stage = None, set-up all stages. Default = None.

        Returns
        -------
        _: Callable
            All preprocessing steps (and if ``&#39;fit&#39;``, augmentation steps too)
            that should be applied to the subjects.
        &#34;&#34;&#34;
        transforms = []
        preprocess = self.get_preprocessing_transforms()
        transforms.append(preprocess)
        if stage == &#34;fit&#34; or stage is None and self.use_augmentation:
            augment = self.get_augmentation_transforms()
            transforms.append(augment)

        return tio.Compose(transforms)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="radio.data.visiondatamodule.VisionDataModule" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule">VisionDataModule</a></li>
<li><a title="radio.data.basedatamodule.BaseDataModule" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule">BaseDataModule</a></li>
<li>pytorch_lightning.core.datamodule.LightningDataModule</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_augmentation_transforms"><code class="name flex">
<span>def <span class="ident">get_augmentation_transforms</span></span>(<span>) ‑> Callable</span>
</code></dt>
<dd>
<div class="desc"><p>"
Get augmentation transorms to apply to subjects during training.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>augment</code></strong> :&ensp;<code>tio.Compose</code></dt>
<dd>All augmentation steps that should be applied to subjects during
training.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def get_augmentation_transforms() -&gt; Callable:
    &#34;&#34;&#34;&#34;
    Get augmentation transorms to apply to subjects during training.

    Returns
    -------
    augment : tio.Compose
        All augmentation steps that should be applied to subjects during
        training.
    &#34;&#34;&#34;
    augment = tio.Compose([
        tio.RandomAffine(),
        tio.RandomGamma(p=0.5),
        tio.RandomNoise(p=0.5),
        tio.RandomMotion(p=0.1),
        tio.RandomBiasField(p=0.25),
    ])
    return augment</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_niis"><code class="name flex">
<span>def <span class="ident">get_niis</span></span>(<span>directory: pathlib.Path) ‑> List[pathlib.Path]</span>
</code></dt>
<dd>
<div class="desc"><p>Get paths to nii files in the given directory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def get_niis(directory: Path) -&gt; List[Path]:
    &#34;&#34;&#34;Get paths to nii files in the given directory.&#34;&#34;&#34;
    return sorted(path for path in directory.glob(&#39;*.nii*&#39;)
                  if not path.name.startswith(&#39;.&#39;))</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.default_transforms"><code class="name flex">
<span>def <span class="ident">default_transforms</span></span>(<span>self, stage: Optional[str] = None) ‑> Callable</span>
</code></dt>
<dd>
<div class="desc"><p>Default transforms and augmentations for the dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>stage</code></strong> :&ensp;<code>Optional[str]</code></dt>
<dd>Either <code>'fit</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code>.
If stage = None, set-up all stages. Default = None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>Callable</code></dt>
<dd>All preprocessing steps (and if <code>'fit'</code>, augmentation steps too)
that should be applied to the subjects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def default_transforms(self, stage: Optional[str] = None) -&gt; Callable:
    &#34;&#34;&#34;
    Default transforms and augmentations for the dataset.

    Parameters
    ----------
    stage: Optional[str]
        Either ``&#39;fit``, ``&#39;validate&#39;``, ``&#39;test&#39;``, or ``&#39;predict&#39;``.
        If stage = None, set-up all stages. Default = None.

    Returns
    -------
    _: Callable
        All preprocessing steps (and if ``&#39;fit&#39;``, augmentation steps too)
        that should be applied to the subjects.
    &#34;&#34;&#34;
    transforms = []
    preprocess = self.get_preprocessing_transforms()
    transforms.append(preprocess)
    if stage == &#34;fit&#34; or stage is None and self.use_augmentation:
        augment = self.get_augmentation_transforms()
        transforms.append(augment)

    return tio.Compose(transforms)</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_max_shape"><code class="name flex">
<span>def <span class="ident">get_max_shape</span></span>(<span>self, subjects: List[torchio.data.subject.Subject]) ‑> numpy.ndarray[typing.Any, numpy.dtype[numpy.int64]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get max shape.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>subjects</code></strong> :&ensp;<code>List[tio.Subject]</code></dt>
<dd>List of TorchIO Subject objects.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>np.ndarray((1, 3), np.int_)</code></dt>
<dd>Max height, width and depth across all subjects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_max_shape(self,
                  subjects: List[tio.Subject]) -&gt; npt.NDArray[np.int_]:
    &#34;&#34;&#34;
    Get max shape.

    Parameters
    ----------
    subjects : List[tio.Subject]
        List of TorchIO Subject objects.

    Returns
    -------
    _ : np.ndarray((1, 3), np.int_)
        Max height, width and depth across all subjects.
    &#34;&#34;&#34;
    dataset = self.dataset_cls(subjects)
    shapes = np.array([subject.spatial_shape for subject in dataset])
    return shapes.max(axis=0)</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_preprocessing_transforms"><code class="name flex">
<span>def <span class="ident">get_preprocessing_transforms</span></span>(<span>self) ‑> Callable</span>
</code></dt>
<dd>
<div class="desc"><p>Get preprocessing transorms to apply to all subjects.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>preprocess</code></strong> :&ensp;<code>tio.Compose</code></dt>
<dd>All preprocessing steps that should be applied to all subjects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_preprocessing_transforms(self) -&gt; Callable:
    &#34;&#34;&#34;
    Get preprocessing transorms to apply to all subjects.

    Returns
    -------
    preprocess : tio.Compose
        All preprocessing steps that should be applied to all subjects.
    &#34;&#34;&#34;
    train_subjects = self.get_subjects()
    test_subjects = self.get_subjects(train=False)
    preprocess = tio.Compose([
        tio.RescaleIntensity((-1, 1)),
        tio.CropOrPad(self.get_max_shape(train_subjects + test_subjects)),
        tio.EnsureShapeMultiple(8),  # for the U-Net
        tio.OneHot(),
    ])
    return preprocess</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_subjects"><code class="name flex">
<span>def <span class="ident">get_subjects</span></span>(<span>self, train: bool = True) ‑> List[torchio.data.subject.Subject]</span>
</code></dt>
<dd>
<div class="desc"><p>Get TorchIO Subject train and test subjects.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>train</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, return a loader for the train dataset, else for the
validation dataset. Default = <code>True</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>List[tio.Subject]</code></dt>
<dd>TorchIO Subject train or test subjects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_subjects(self, train: bool = True) -&gt; List[tio.Subject]:
    &#34;&#34;&#34;
    Get TorchIO Subject train and test subjects.

    Parameters
    ----------
    train : bool, optional
        If True, return a loader for the train dataset, else for the
        validation dataset. Default = ``True``.

    Returns
    -------
    _ : List[tio.Subject]
        TorchIO Subject train or test subjects.
    &#34;&#34;&#34;
    if train:
        train_img_paths, train_label_paths = self.get_train_paths()
        train_subjects = []
        for image_path, label_path in zip(train_img_paths,
                                          train_label_paths):
            # &#39;image&#39; and &#39;label&#39; are arbitrary names for the images
            subject = tio.Subject(image=tio.ScalarImage(image_path),
                                  label=tio.LabelMap(label_path))
            train_subjects.append(subject)
        return train_subjects

    test_img_paths = self.get_test_paths()
    test_subjects = []
    for image_path in test_img_paths:
        subject = tio.Subject(image=tio.ScalarImage(image_path))
        test_subjects.append(subject)

    return test_subjects</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_test_paths"><code class="name flex">
<span>def <span class="ident">get_test_paths</span></span>(<span>self) ‑> List[pathlib.Path]</span>
</code></dt>
<dd>
<div class="desc"><p>Get paths to nii files for test images.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>List[Path]</code></dt>
<dd>Paths to test images.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_test_paths(self) -&gt; List[Path]:
    &#34;&#34;&#34;
    Get paths to nii files for test images.

    Returns
    -------
    _ : List[Path]
        Paths to test images.
    &#34;&#34;&#34;
    image_test_paths = self.get_niis(self.task_dir / &#39;imagesTs&#39;)
    return image_test_paths</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_train_paths"><code class="name flex">
<span>def <span class="ident">get_train_paths</span></span>(<span>self) ‑> Tuple[List[pathlib.Path], List[pathlib.Path]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get paths to nii files for train images and labels.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>Tuple[List[Path], List[Path]]</code></dt>
<dd>Paths to train images and labels.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_train_paths(self) -&gt; Tuple[List[Path], List[Path]]:
    &#34;&#34;&#34;
    Get paths to nii files for train images and labels.

    Returns
    -------
    _ : Tuple[List[Path], List[Path]]
        Paths to train images and labels.
    &#34;&#34;&#34;
    image_training_paths = self.get_niis(self.task_dir / &#39;imagesTr&#39;)
    label_training_paths = self.get_niis(self.task_dir / &#39;labelsTr&#39;)
    return image_training_paths, label_training_paths</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.prepare_data"><code class="name flex">
<span>def <span class="ident">prepare_data</span></span>(<span>self, *args: Any, **kwargs: Any) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Saves files to task data directory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_data(self, *args: Any, **kwargs: Any) -&gt; None:
    &#34;&#34;&#34;Saves files to task data directory.&#34;&#34;&#34;
    if not is_dir_or_symlink(self.task_dir):
        url = (&#39;https://msd-for-monai.s3-us-west-2.amazonaws.com/&#39; +
               f&#39;{self.task}.tar&#39;)
        output_dir = ensure_exists(self.root)
        download_and_extract(url=url, output_dir=output_dir)</code></pre>
</details>
</dd>
<dt id="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.setup"><code class="name flex">
<span>def <span class="ident">setup</span></span>(<span>self, stage: Optional[str] = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Creates train, validation and test collection of samplers.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>stage</code></strong> :&ensp;<code>Optional[str]</code></dt>
<dd>Either <code>'fit</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code>.
If stage = None, set-up all stages. Default = None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def setup(self, stage: Optional[str] = None) -&gt; None:
    &#34;&#34;&#34;
    Creates train, validation and test collection of samplers.

    Parameters
    ----------
    stage: Optional[str]
        Either ``&#39;fit``, ``&#39;validate&#39;``, ``&#39;test&#39;``, or ``&#39;predict&#39;``.
        If stage = None, set-up all stages. Default = None.
    &#34;&#34;&#34;
    dims = []
    if stage == &#34;fit&#34; or stage is None:
        train_transforms = (self.default_transforms()
                            if self.train_transforms is None else
                            self.train_transforms)

        val_transforms = (self.default_transforms()
                          if self.val_transforms is None else
                          self.val_transforms)

        train_subjects = self.get_subjects()
        dims.append([self.get_max_shape(train_subjects)])
        self.train_dataset = self.dataset_cls(train_subjects,
                                              transform=train_transforms)
        self.val_dataset = self.dataset_cls(train_subjects,
                                            transform=val_transforms)

        self.validation = self.val_cls(train_dataset=self.train_dataset,
                                       val_dataset=self.val_dataset,
                                       batch_size=self.batch_size,
                                       shuffle=self.shuffle,
                                       num_workers=self.num_workers,
                                       pin_memory=self.pin_memory,
                                       drop_last=self.drop_last,
                                       num_folds=self.num_folds,
                                       seed=self.seed)

        self.validation.setup(self.val_split)
        self.size_train = self.validation.size_train
        self.size_val = self.validation.size_val

    if stage == &#34;test&#34; or stage is None:
        test_transforms = (self.default_transforms()
                           if self.test_transforms is None else
                           self.test_transforms)
        test_subjects = self.get_subjects(train=False)
        dims.append([self.get_max_shape(test_subjects)])
        test_dataset = self.dataset_cls(test_subjects,
                                        transform=test_transforms)
        self.test_datasets.append(test_dataset)
        self.test_datasets.append(test_dataset)
        self.size_test = min([len(data) for data in self.test_datasets])

    if stage == &#34;predict&#34; or stage is None:
        predict_transforms = (self.default_transforms()
                              if self.test_transforms is None else
                              self.test_transforms)
        predict_subjects = self.get_subjects(train=False)
        predict_dataset = self.dataset_cls(predict_subjects,
                                           transform=predict_transforms)
        self.predict_datasets.append(predict_dataset)
        self.size_predict = min(
            [len(data) for data in self.predict_datasets])

    self.dims = np.concatenate(dims, axis=0).max(axis=0)</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="radio.data.visiondatamodule.VisionDataModule" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule">VisionDataModule</a></b></code>:
<ul class="hlist">
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.check_if_data_split" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.check_if_data_split">check_if_data_split</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.dataloader" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.dataloader">dataloader</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.dims" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule.dims">dims</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.predict_dataloader" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.predict_dataloader">predict_dataloader</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.size_eval_dataset" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.size_eval_dataset">size_eval_dataset</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.size_train_dataset" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.size_train_dataset">size_train_dataset</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.teardown" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.teardown">teardown</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.test_dataloader" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.test_dataloader">test_dataloader</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.train_dataloader" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.train_dataloader">train_dataloader</a></code></li>
<li><code><a title="radio.data.visiondatamodule.VisionDataModule.val_dataloader" href="../visiondatamodule.html#radio.data.visiondatamodule.VisionDataModule.val_dataloader">val_dataloader</a></code></li>
</ul>
</li>
<li><code><b><a title="radio.data.basedatamodule.BaseDataModule" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule">BaseDataModule</a></b></code>:
<ul class="hlist">
<li><code><a title="radio.data.basedatamodule.BaseDataModule.dataset_cls" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule.dataset_cls">dataset_cls</a></code></li>
<li><code><a title="radio.data.basedatamodule.BaseDataModule.name" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule.name">name</a></code></li>
</ul>
</li>
<li><code><b><a title="radio.data.basedatamodule.BaseDataModule" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule">BaseDataModule</a></b></code>:
<ul class="hlist">
<li><code><a title="radio.data.basedatamodule.BaseDataModule.EXTRA_ARGS" href="../basedatamodule.html#radio.data.basedatamodule.BaseDataModule.EXTRA_ARGS">EXTRA_ARGS</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="radio.data.datamodules" href="index.html">radio.data.datamodules</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="radio.data.datamodules.medical_decathlon.plot_test_batch" href="#radio.data.datamodules.medical_decathlon.plot_test_batch">plot_test_batch</a></code></li>
<li><code><a title="radio.data.datamodules.medical_decathlon.plot_train_batch" href="#radio.data.datamodules.medical_decathlon.plot_train_batch">plot_train_batch</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule">MedicalDecathlonDataModule</a></code></h4>
<ul class="">
<li><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.default_transforms" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.default_transforms">default_transforms</a></code></li>
<li><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_augmentation_transforms" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_augmentation_transforms">get_augmentation_transforms</a></code></li>
<li><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_max_shape" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_max_shape">get_max_shape</a></code></li>
<li><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_niis" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_niis">get_niis</a></code></li>
<li><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_preprocessing_transforms" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_preprocessing_transforms">get_preprocessing_transforms</a></code></li>
<li><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_subjects" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_subjects">get_subjects</a></code></li>
<li><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_test_paths" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_test_paths">get_test_paths</a></code></li>
<li><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_train_paths" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.get_train_paths">get_train_paths</a></code></li>
<li><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.prepare_data" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.prepare_data">prepare_data</a></code></li>
<li><code><a title="radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.setup" href="#radio.data.datamodules.medical_decathlon.MedicalDecathlonDataModule.setup">setup</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>