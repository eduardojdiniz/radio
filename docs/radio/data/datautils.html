<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>radio.data.datautils API documentation</title>
<meta name="description" content="Data related utilities." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>radio.data.datautils</code></h1>
</header>
<section id="section-intro">
<p>Data related utilities.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python
# coding=utf-8
&#34;&#34;&#34;
Data related utilities.
&#34;&#34;&#34;

from typing import Any, List, Optional, Tuple, Iterable, TypeVar, Dict, Mapping
import hashlib
import os.path
import traceback
import random
from os.path import join as pjoin
from pathlib import Path
import matplotlib.pyplot as plt  # type: ignore
import numpy as np
import torch
import torchio as tio
import torchvision.transforms as T  # type: ignore
from PIL import Image
from torchio.data import ScalarImage, LabelMap, Subject
from .datatypes import Tensors, SeqSeqTensor
from . import constants

plt.rcParams[&#34;savefig.bbox&#34;] = &#34;tight&#34;

Var = TypeVar(&#34;Var&#34;)

__all__ = [
    &#34;get_first_batch&#34;,
    &#34;default_image_loader&#34;,
    &#34;denormalize&#34;,
    &#34;plot&#34;,
    &#34;plot_batch&#34;,
    &#34;load_standard_test_imgs&#34;,
    &#34;check_integrity&#34;,
]


def get_first_batch(loader: Iterable,
                    default: Optional[Var] = None) -&gt; Optional[Var]:
    &#34;&#34;&#34;
    Returns the first item in the given iterable or `default` if empty,
    meaningful mostly with &#39;for&#39; expressions.

    Parameters
    ----------
    loader : Iterable
        Dataloader to get the batch from.
    default: Any, optional
        Returned if ``loader`` is empty. Default = ``None``.

    Returns
    -------
    batch : Any
       First batch from the dataloader. Default = ``None``.

    &#34;&#34;&#34;
    for batch in loader:
        return batch
    return default


def plot_batch(
    batch: Dict,
    num_samples: int = 5,
    intensities: Optional[List[str]] = None,
    labels: Optional[List[str]] = None,
    exclude_keys: Optional[List[str]] = None,
) -&gt; None:
    &#34;&#34;&#34;plot images and labels from a batch of images&#34;&#34;&#34;
    # Create subjects dataset from batch
    batch_size = len(batch)
    samples_idx = random.sample(
        range(0, batch_size),
        min(num_samples, batch_size),
    )
    dataset = tio.SubjectsDataset.from_batch(batch)

    # Keep only samples_idx subjects in the dataset
    dataset._subjects = [
        subject for idx, subject in enumerate(dataset._subjects)
        if idx in samples_idx
    ]

    # Parse intensities, labels and exclude_keys
    exclude_keys = exclude_keys if exclude_keys else []
    # # Assumes all subjects hold the same tio.IMAGE&#39;s
    intensities_in_subj = list(
        dataset[0].get_images_dict(intensity_only=True).keys())
    labels_in_subj = list(dataset[0].get_images_dict(
        intensity_only=False, exclude=intensities_in_subj).keys())
    intensities_in_subj = [
        intensity for intensity in intensities_in_subj
        if intensity not in exclude_keys
    ]
    labels_in_subj = [
        label for label in labels_in_subj if label not in exclude_keys
    ]
    intensities = intensities if intensities else intensities_in_subj
    labels = labels if labels else labels_in_subj

    # Filter images from dataset
    for _, subject in enumerate(dataset):
        for image_name in subject.get_images_names():
            if image_name not in intensities or image_name not in labels:
                subject.remove_image(image_name)

    # Plot subjects
    for row_idx, subject in enumerate(dataset):
        print(f&#34;Subject: {row_idx}&#34;)
        subject.plot()
        print(&#34;\n&#34;)


def get_batch_images_and_size(batch: Dict) -&gt; Tuple[List[str], int]:
    &#34;&#34;&#34;Get number of images and images names in a batch.
    Args:
        batch: Dictionary generated by a :class:`torch.utils.data.DataLoader`
        extracting data from a :class:`torchio.SubjectsDataset`.
    Raises:
        RuntimeError: If the batch does not seem to contain any dictionaries
        that seem to represent a :class:`torchio.Image`.
    &#34;&#34;&#34;
    names = []
    for image_name, image_dict in batch.items():
        if isinstance(
                image_dict, Mapping
        ) and constants.DATA in image_dict:  # assume it is a TorchIO Image
            size = len(image_dict[constants.DATA])
            names.append(image_name)
    if not names:
        raise RuntimeError(&#39;The batch does not seem to contain any images&#39;)
    return names, size


def get_subjects_from_batch(batch: Dict) -&gt; List:
    &#34;&#34;&#34;Get list of subjects from collated batch.
    Args:
        batch: Dictionary generated by a :class:`torch.utils.data.DataLoader`
        extracting data from a :class:`torchio.SubjectsDataset`.
    &#34;&#34;&#34;
    subjects = []
    image_names, batch_size = get_batch_images_and_size(batch)
    for i in range(batch_size):
        subject_dict = {}
        for image_name in image_names:
            image_dict = batch[image_name]
            data = image_dict[constants.DATA][i]
            affine = image_dict[constants.AFFINE][i]
            path = Path(image_dict[constants.PATH][i])
            is_label = image_dict[constants.TYPE][i] == constants.LABEL
            klass = LabelMap if is_label else ScalarImage
            image = klass(tensor=data, affine=affine, filename=path.name)
            subject_dict[image_name] = image
            subject_dict[&#39;subj_id&#39;] = batch[&#39;subj_id&#39;][i]
            subject_dict[&#39;scan_id&#39;] = batch[&#39;scan_id&#39;][i]
        subject = Subject(subject_dict)
        if constants.HISTORY in batch:
            applied_transforms = batch[constants.HISTORY][i]
            for transform in applied_transforms:
                transform.add_transform_to_subject_history(subject)
        subjects.append(subject)
    return subjects


def default_image_loader(path: Path) -&gt; Image.Image:
    &#34;&#34;&#34;
    Load image file as RGB PIL Image

    Parameters
    ----------
    path : Path
        Image file path

    Returns
    -------
    return : Image.Image
       RGB PIL Image
    &#34;&#34;&#34;

    # Open path as file to avoid ResourceWarning
    # (https://github.com/python-pillow/Pillow/issues/835)
    with path.open(mode=&#34;rb&#34;) as fid:
        img = Image.open(fid)
        return img.convert(&#34;RGB&#34;)


def denormalize(tensor: torch.Tensor,
                mean: Tuple[float, ...] = None,
                std: Tuple[float, ...] = None):
    &#34;&#34;&#34;
    Undoes mean/standard deviation normalization, zero to one scaling, and
    channel rearrangement for a batch of images.

    Parameters
    ----------
    tensor : torch.Tensor
        A (CHANNELS x HEIGHT x WIDTH) tensor
    mean: Tuple[float, ...]
        A tuple of mean values to be subtracted from each image channel.
    std: Tuple[float, ...]
        A tuple of standard deviation values to be devided from each image
        channel.

    Returns
    ----------
    array : numpy.ndarray[float]
        A (HEIGHT x WIDTH x CHANNELS) numpy array of floats
    &#34;&#34;&#34;
    if not mean:
        if tensor.shape[0] == 1:
            mean = (-0.5 / 0.5, )
        else:
            mean = (-0.5 / 0.5, -0.5 / 0.5, -0.5 / 0.5)
    if not std:
        if tensor.shape[0] == 1:
            std = (1 / 0.5, )
        else:
            std = (1 / 0.5, 1 / 0.5, 1 / 0.5)
    inverse_normalize = T.Normalize(mean=mean, std=std)
    denormalized_tensor = (inverse_normalize(tensor) * 255.0).type(torch.uint8)
    array = denormalized_tensor.permute(1, 2, 0).numpy().squeeze()
    return array


def plot(imgs: Tensors,
         baseline_imgs: Tensors = None,
         row_titles: List[str] = None,
         fig_title: str = None,
         **imshow_kwargs) -&gt; None:
    &#34;&#34;&#34;
    Plot images in a 2D grid.

    Arguments
    ---------
    imgs : Samples
        Collection of images to be plotted. Each element of ``imgs`` holds a
        row of the image grid to be plotted.
    baseline_imgs : Samples, Optional
        Collection of baseline images. If not ``None``, the first column of the
        grid will be filled with the baseline images. ``baseline_imgs`` is
        either a single image, or a collection of images of the same length of
        an element of ``imgs``. Default = ``None``.
    row_titles : List[str], Optional
        List of row titles. If not ``None``, ``len(row_title)`` must be equal
        to ``len(imgs)``. Default = ``None``.
    fig_title : str, Optional
        Figure title.  Default = ``None``.
    &#34;&#34;&#34;
    # Make a 2d grid even if there&#39;s just 1 row
    if isinstance(imgs, SeqSeqTensor):
        local_imgs = imgs
    else:
        local_imgs = SeqSeqTensor(imgs)

    num_rows = len(local_imgs)
    num_cols = len(local_imgs[0])

    if not baseline_imgs:
        with_baseline = False
    else:
        if not isinstance(baseline_imgs, list):
            baseline_imgs = [baseline_imgs for i in range(0, num_rows)]
        else:
            if len(baseline_imgs) == 1:
                baseline_imgs = [baseline_imgs[0] for i in range(0, num_rows)]
            elif len(baseline_imgs) != num_rows:
                msg = (
                    &#34;Number of elements in `baseline_imgs` &#34;,
                    &#34;must match the number of elements in `imgs[0]`&#34;,
                )
                raise ValueError(msg)
            if isinstance(baseline_imgs[0], list):
                msg = (
                    &#34;Elements of `baseline_imgs` must be PIL Images &#34;,
                    &#34;or Torch Tensors&#34;,
                )
                raise TypeError(msg)
        with_baseline = True
        num_cols += 1  # First column is now the baseline images
    if row_title:
        if len(row_title) != num_rows:
            msg = (
                &#34;Number of elements in `row_title` &#34;,
                &#34;must match the number of elements in `imgs`&#34;,
            )
            raise ValueError(msg)

    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)
    for row_idx, row in enumerate(imgs):
        row = [baseline_imgs[row_idx]] + row if with_baseline else row
        for col_idx, img in enumerate(row):
            ax = axs[row_idx, col_idx]
            if isinstance(img, torch.Tensor):
                img = denormalize(img)
            else:
                img = np.asarray(img)
            if len(img.shape) == 2:
                ax.imshow(img, cmap=&#34;gray&#34;, vmin=0, vmax=255)
            else:
                ax.imshow(img, **imshow_kwargs)
            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])

    if with_baseline:
        plt.sca(axs[0, 0])
        plt.title(label=&#34;Baseline images&#34;, size=15)

    if row_title is not None:
        for row_idx in range(num_rows):
            plt.sca(axs[row_idx, 0])
            plt.ylabel(row_title[row_idx], rotation=0, labelpad=50, size=15)
            plt.tight_layout()

    if title:
        fig.suptitle(t=title, size=16)

    fig.tight_layout()
    return fig


def load_standard_test_imgs(directory: Path = Path().cwd() / &#34;imgs&#34;):
    directory = directory.expanduser()
    test_imgs = []
    names = []
    for root, _, fnames in sorted(os.walk(directory, followlinks=True)):
        for fname in sorted(fnames):
            if is_valid_image(Path(fname)):
                path = pjoin(root, fname)
                test_imgs.extend([Image.open(path)])
                names.append(Path(path).stem)
    return test_imgs, names


def calculate_md5_dir(dirpath: Path,
                      chunk_size: int = 1024 * 1024,
                      verbose: bool = False) -&gt; str:
    md5 = hashlib.md5()
    try:
        for root, _, files in sorted(os.walk(dirpath)):
            for name in files:
                if verbose:
                    print(&#34;Hashing&#34;, name)
                fpath = Path(root) / name
                with fpath.open(mode=&#34;rb&#34;) as fid:
                    for chunk in iter(lambda: fid.read(chunk_size), b&#34;&#34;):
                        md5.update(chunk)

    except BaseException:
        # Print the stack traceback
        traceback.print_exc()
        return -2

    return md5.hexdigest()


def calculate_md5_file(fpath: Path, chunk_size: int = 1024 * 1024) -&gt; str:
    md5 = hashlib.md5()
    try:
        with fpath.open(mode=&#34;rb&#34;) as fid:
            for chunk in iter(lambda: fid.read(chunk_size), b&#34;&#34;):
                md5.update(chunk)
    except BaseException:
        # Print the stack traceback
        traceback.print_exc()
        return -2
    return md5.hexdigest()


def check_md5(path: Path, md5: str, **kwargs: Any) -&gt; bool:
    if path.is_dir():
        return md5 == calculate_md5_dir(path, **kwargs)
    return md5 == calculate_md5_file(path, **kwargs)


def check_integrity(path: Path, md5: Optional[str] = None) -&gt; bool:
    if not os.path.exists(path):
        return False
    if md5 is None:
        return True
    return check_md5(path, md5)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="radio.data.datautils.check_integrity"><code class="name flex">
<span>def <span class="ident">check_integrity</span></span>(<span>path: pathlib.Path, md5: Optional[str] = None) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_integrity(path: Path, md5: Optional[str] = None) -&gt; bool:
    if not os.path.exists(path):
        return False
    if md5 is None:
        return True
    return check_md5(path, md5)</code></pre>
</details>
</dd>
<dt id="radio.data.datautils.default_image_loader"><code class="name flex">
<span>def <span class="ident">default_image_loader</span></span>(<span>path: pathlib.Path) ‑> PIL.Image.Image</span>
</code></dt>
<dd>
<div class="desc"><p>Load image file as RGB PIL Image</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>Path</code></dt>
<dd>Image file path</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>return</code></strong> :&ensp;<code>Image.Image</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>RGB PIL Image</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def default_image_loader(path: Path) -&gt; Image.Image:
    &#34;&#34;&#34;
    Load image file as RGB PIL Image

    Parameters
    ----------
    path : Path
        Image file path

    Returns
    -------
    return : Image.Image
       RGB PIL Image
    &#34;&#34;&#34;

    # Open path as file to avoid ResourceWarning
    # (https://github.com/python-pillow/Pillow/issues/835)
    with path.open(mode=&#34;rb&#34;) as fid:
        img = Image.open(fid)
        return img.convert(&#34;RGB&#34;)</code></pre>
</details>
</dd>
<dt id="radio.data.datautils.denormalize"><code class="name flex">
<span>def <span class="ident">denormalize</span></span>(<span>tensor: torch.Tensor, mean: Tuple[float, ...] = None, std: Tuple[float, ...] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Undoes mean/standard deviation normalization, zero to one scaling, and
channel rearrangement for a batch of images.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tensor</code></strong> :&ensp;<code>torch.Tensor</code></dt>
<dd>A (CHANNELS x HEIGHT x WIDTH) tensor</dd>
<dt><strong><code>mean</code></strong> :&ensp;<code>Tuple[float, &hellip;]</code></dt>
<dd>A tuple of mean values to be subtracted from each image channel.</dd>
<dt><strong><code>std</code></strong> :&ensp;<code>Tuple[float, &hellip;]</code></dt>
<dd>A tuple of standard deviation values to be devided from each image
channel.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>array</code></strong> :&ensp;<code>numpy.ndarray[float]</code></dt>
<dd>A (HEIGHT x WIDTH x CHANNELS) numpy array of floats</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def denormalize(tensor: torch.Tensor,
                mean: Tuple[float, ...] = None,
                std: Tuple[float, ...] = None):
    &#34;&#34;&#34;
    Undoes mean/standard deviation normalization, zero to one scaling, and
    channel rearrangement for a batch of images.

    Parameters
    ----------
    tensor : torch.Tensor
        A (CHANNELS x HEIGHT x WIDTH) tensor
    mean: Tuple[float, ...]
        A tuple of mean values to be subtracted from each image channel.
    std: Tuple[float, ...]
        A tuple of standard deviation values to be devided from each image
        channel.

    Returns
    ----------
    array : numpy.ndarray[float]
        A (HEIGHT x WIDTH x CHANNELS) numpy array of floats
    &#34;&#34;&#34;
    if not mean:
        if tensor.shape[0] == 1:
            mean = (-0.5 / 0.5, )
        else:
            mean = (-0.5 / 0.5, -0.5 / 0.5, -0.5 / 0.5)
    if not std:
        if tensor.shape[0] == 1:
            std = (1 / 0.5, )
        else:
            std = (1 / 0.5, 1 / 0.5, 1 / 0.5)
    inverse_normalize = T.Normalize(mean=mean, std=std)
    denormalized_tensor = (inverse_normalize(tensor) * 255.0).type(torch.uint8)
    array = denormalized_tensor.permute(1, 2, 0).numpy().squeeze()
    return array</code></pre>
</details>
</dd>
<dt id="radio.data.datautils.get_first_batch"><code class="name flex">
<span>def <span class="ident">get_first_batch</span></span>(<span>loader: Iterable, default: Optional[~Var] = None) ‑> Optional[~Var]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the first item in the given iterable or <code>default</code> if empty,
meaningful mostly with 'for' expressions.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>loader</code></strong> :&ensp;<code>Iterable</code></dt>
<dd>Dataloader to get the batch from.</dd>
<dt><strong><code>default</code></strong> :&ensp;<code>Any</code>, optional</dt>
<dd>Returned if <code>loader</code> is empty. Default = <code>None</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>batch</code></strong> :&ensp;<code>Any</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>First batch from the dataloader. Default = <code>None</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_first_batch(loader: Iterable,
                    default: Optional[Var] = None) -&gt; Optional[Var]:
    &#34;&#34;&#34;
    Returns the first item in the given iterable or `default` if empty,
    meaningful mostly with &#39;for&#39; expressions.

    Parameters
    ----------
    loader : Iterable
        Dataloader to get the batch from.
    default: Any, optional
        Returned if ``loader`` is empty. Default = ``None``.

    Returns
    -------
    batch : Any
       First batch from the dataloader. Default = ``None``.

    &#34;&#34;&#34;
    for batch in loader:
        return batch
    return default</code></pre>
</details>
</dd>
<dt id="radio.data.datautils.load_standard_test_imgs"><code class="name flex">
<span>def <span class="ident">load_standard_test_imgs</span></span>(<span>directory: pathlib.Path = PosixPath('/home/wangl15@acct.upmchs.net/radio/imgs'))</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_standard_test_imgs(directory: Path = Path().cwd() / &#34;imgs&#34;):
    directory = directory.expanduser()
    test_imgs = []
    names = []
    for root, _, fnames in sorted(os.walk(directory, followlinks=True)):
        for fname in sorted(fnames):
            if is_valid_image(Path(fname)):
                path = pjoin(root, fname)
                test_imgs.extend([Image.open(path)])
                names.append(Path(path).stem)
    return test_imgs, names</code></pre>
</details>
</dd>
<dt id="radio.data.datautils.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>imgs: Union[torch.Tensor, <a title="radio.data.datatypes.Tensor" href="datatypes.html#radio.data.datatypes.Tensor">Tensor</a>, Sequence[Union[torch.Tensor, <a title="radio.data.datatypes.Tensor" href="datatypes.html#radio.data.datatypes.Tensor">Tensor</a>]], <a title="radio.data.datatypes.SeqTensor" href="datatypes.html#radio.data.datatypes.SeqTensor">SeqTensor</a>, Sequence[Union[torch.Tensor, <a title="radio.data.datatypes.Tensor" href="datatypes.html#radio.data.datatypes.Tensor">Tensor</a>, Sequence[Union[torch.Tensor, <a title="radio.data.datatypes.Tensor" href="datatypes.html#radio.data.datatypes.Tensor">Tensor</a>]], <a title="radio.data.datatypes.SeqTensor" href="datatypes.html#radio.data.datatypes.SeqTensor">SeqTensor</a>]], <a title="radio.data.datatypes.SeqSeqTensor" href="datatypes.html#radio.data.datatypes.SeqSeqTensor">SeqSeqTensor</a>], baseline_imgs: Union[torch.Tensor, <a title="radio.data.datatypes.Tensor" href="datatypes.html#radio.data.datatypes.Tensor">Tensor</a>, Sequence[Union[torch.Tensor, <a title="radio.data.datatypes.Tensor" href="datatypes.html#radio.data.datatypes.Tensor">Tensor</a>]], <a title="radio.data.datatypes.SeqTensor" href="datatypes.html#radio.data.datatypes.SeqTensor">SeqTensor</a>, Sequence[Union[torch.Tensor, <a title="radio.data.datatypes.Tensor" href="datatypes.html#radio.data.datatypes.Tensor">Tensor</a>, Sequence[Union[torch.Tensor, <a title="radio.data.datatypes.Tensor" href="datatypes.html#radio.data.datatypes.Tensor">Tensor</a>]], <a title="radio.data.datatypes.SeqTensor" href="datatypes.html#radio.data.datatypes.SeqTensor">SeqTensor</a>]], <a title="radio.data.datatypes.SeqSeqTensor" href="datatypes.html#radio.data.datatypes.SeqSeqTensor">SeqSeqTensor</a>] = None, row_titles: List[str] = None, fig_title: str = None, **imshow_kwargs) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Plot images in a 2D grid.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>imgs</code></strong> :&ensp;<code>Samples</code></dt>
<dd>Collection of images to be plotted. Each element of <code>imgs</code> holds a
row of the image grid to be plotted.</dd>
<dt><strong><code>baseline_imgs</code></strong> :&ensp;<code>Samples, Optional</code></dt>
<dd>Collection of baseline images. If not <code>None</code>, the first column of the
grid will be filled with the baseline images. <code>baseline_imgs</code> is
either a single image, or a collection of images of the same length of
an element of <code>imgs</code>. Default = <code>None</code>.</dd>
<dt><strong><code>row_titles</code></strong> :&ensp;<code>List[str], Optional</code></dt>
<dd>List of row titles. If not <code>None</code>, <code>len(row_title)</code> must be equal
to <code>len(imgs)</code>. Default = <code>None</code>.</dd>
<dt><strong><code>fig_title</code></strong> :&ensp;<code>str, Optional</code></dt>
<dd>Figure title.
Default = <code>None</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(imgs: Tensors,
         baseline_imgs: Tensors = None,
         row_titles: List[str] = None,
         fig_title: str = None,
         **imshow_kwargs) -&gt; None:
    &#34;&#34;&#34;
    Plot images in a 2D grid.

    Arguments
    ---------
    imgs : Samples
        Collection of images to be plotted. Each element of ``imgs`` holds a
        row of the image grid to be plotted.
    baseline_imgs : Samples, Optional
        Collection of baseline images. If not ``None``, the first column of the
        grid will be filled with the baseline images. ``baseline_imgs`` is
        either a single image, or a collection of images of the same length of
        an element of ``imgs``. Default = ``None``.
    row_titles : List[str], Optional
        List of row titles. If not ``None``, ``len(row_title)`` must be equal
        to ``len(imgs)``. Default = ``None``.
    fig_title : str, Optional
        Figure title.  Default = ``None``.
    &#34;&#34;&#34;
    # Make a 2d grid even if there&#39;s just 1 row
    if isinstance(imgs, SeqSeqTensor):
        local_imgs = imgs
    else:
        local_imgs = SeqSeqTensor(imgs)

    num_rows = len(local_imgs)
    num_cols = len(local_imgs[0])

    if not baseline_imgs:
        with_baseline = False
    else:
        if not isinstance(baseline_imgs, list):
            baseline_imgs = [baseline_imgs for i in range(0, num_rows)]
        else:
            if len(baseline_imgs) == 1:
                baseline_imgs = [baseline_imgs[0] for i in range(0, num_rows)]
            elif len(baseline_imgs) != num_rows:
                msg = (
                    &#34;Number of elements in `baseline_imgs` &#34;,
                    &#34;must match the number of elements in `imgs[0]`&#34;,
                )
                raise ValueError(msg)
            if isinstance(baseline_imgs[0], list):
                msg = (
                    &#34;Elements of `baseline_imgs` must be PIL Images &#34;,
                    &#34;or Torch Tensors&#34;,
                )
                raise TypeError(msg)
        with_baseline = True
        num_cols += 1  # First column is now the baseline images
    if row_title:
        if len(row_title) != num_rows:
            msg = (
                &#34;Number of elements in `row_title` &#34;,
                &#34;must match the number of elements in `imgs`&#34;,
            )
            raise ValueError(msg)

    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)
    for row_idx, row in enumerate(imgs):
        row = [baseline_imgs[row_idx]] + row if with_baseline else row
        for col_idx, img in enumerate(row):
            ax = axs[row_idx, col_idx]
            if isinstance(img, torch.Tensor):
                img = denormalize(img)
            else:
                img = np.asarray(img)
            if len(img.shape) == 2:
                ax.imshow(img, cmap=&#34;gray&#34;, vmin=0, vmax=255)
            else:
                ax.imshow(img, **imshow_kwargs)
            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])

    if with_baseline:
        plt.sca(axs[0, 0])
        plt.title(label=&#34;Baseline images&#34;, size=15)

    if row_title is not None:
        for row_idx in range(num_rows):
            plt.sca(axs[row_idx, 0])
            plt.ylabel(row_title[row_idx], rotation=0, labelpad=50, size=15)
            plt.tight_layout()

    if title:
        fig.suptitle(t=title, size=16)

    fig.tight_layout()
    return fig</code></pre>
</details>
</dd>
<dt id="radio.data.datautils.plot_batch"><code class="name flex">
<span>def <span class="ident">plot_batch</span></span>(<span>batch: Dict, num_samples: int = 5, intensities: Optional[List[str]] = None, labels: Optional[List[str]] = None, exclude_keys: Optional[List[str]] = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>plot images and labels from a batch of images</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_batch(
    batch: Dict,
    num_samples: int = 5,
    intensities: Optional[List[str]] = None,
    labels: Optional[List[str]] = None,
    exclude_keys: Optional[List[str]] = None,
) -&gt; None:
    &#34;&#34;&#34;plot images and labels from a batch of images&#34;&#34;&#34;
    # Create subjects dataset from batch
    batch_size = len(batch)
    samples_idx = random.sample(
        range(0, batch_size),
        min(num_samples, batch_size),
    )
    dataset = tio.SubjectsDataset.from_batch(batch)

    # Keep only samples_idx subjects in the dataset
    dataset._subjects = [
        subject for idx, subject in enumerate(dataset._subjects)
        if idx in samples_idx
    ]

    # Parse intensities, labels and exclude_keys
    exclude_keys = exclude_keys if exclude_keys else []
    # # Assumes all subjects hold the same tio.IMAGE&#39;s
    intensities_in_subj = list(
        dataset[0].get_images_dict(intensity_only=True).keys())
    labels_in_subj = list(dataset[0].get_images_dict(
        intensity_only=False, exclude=intensities_in_subj).keys())
    intensities_in_subj = [
        intensity for intensity in intensities_in_subj
        if intensity not in exclude_keys
    ]
    labels_in_subj = [
        label for label in labels_in_subj if label not in exclude_keys
    ]
    intensities = intensities if intensities else intensities_in_subj
    labels = labels if labels else labels_in_subj

    # Filter images from dataset
    for _, subject in enumerate(dataset):
        for image_name in subject.get_images_names():
            if image_name not in intensities or image_name not in labels:
                subject.remove_image(image_name)

    # Plot subjects
    for row_idx, subject in enumerate(dataset):
        print(f&#34;Subject: {row_idx}&#34;)
        subject.plot()
        print(&#34;\n&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="radio.data" href="index.html">radio.data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="radio.data.datautils.check_integrity" href="#radio.data.datautils.check_integrity">check_integrity</a></code></li>
<li><code><a title="radio.data.datautils.default_image_loader" href="#radio.data.datautils.default_image_loader">default_image_loader</a></code></li>
<li><code><a title="radio.data.datautils.denormalize" href="#radio.data.datautils.denormalize">denormalize</a></code></li>
<li><code><a title="radio.data.datautils.get_first_batch" href="#radio.data.datautils.get_first_batch">get_first_batch</a></code></li>
<li><code><a title="radio.data.datautils.load_standard_test_imgs" href="#radio.data.datautils.load_standard_test_imgs">load_standard_test_imgs</a></code></li>
<li><code><a title="radio.data.datautils.plot" href="#radio.data.datautils.plot">plot</a></code></li>
<li><code><a title="radio.data.datautils.plot_batch" href="#radio.data.datautils.plot_batch">plot_batch</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>