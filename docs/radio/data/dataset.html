<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>radio.data.dataset API documentation</title>
<meta name="description" content="Datasets are based on the PyTorch ``torch.utils.data.Dataset`` data
primitive. They store the samples and their corresponding labels. Pytorch
domain …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>radio.data.dataset</code></h1>
</header>
<section id="section-intro">
<p>Datasets are based on the PyTorch <code>torch.utils.data.Dataset</code> data
primitive. They store the samples and their corresponding labels. Pytorch
domain libraries (e.g., vision, text, audio) provide pre-loaded datasets (e.g.,
MNIST) that subclass <code>torch.utils.data.Dataset</code> and implement functions
specific to the particular data. They can be used to prototype and benchmark
your model. You can find them at
<a href="https://pytorch.org/vision/stable/datasets.html">Image Datasets</a>,
<a href="https://pytorch.org/text/stable/datasets.html">Text Datasets</a>, and
<a href="https://pytorch.org/audio/stable/datasets.html">Audio Datasets</a>.</p>
<p>This module implements an abstract base class <code><a title="radio.data.dataset.BaseVisionDataset" href="#radio.data.dataset.BaseVisionDataset">BaseVisionDataset</a></code> for vision
datasets. It also replicates the official PyTorch image folder
(<a href="https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py">https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py</a>)
so it can inherent from <code><a title="radio.data.dataset.BaseVisionDataset" href="#radio.data.dataset.BaseVisionDataset">BaseVisionDataset</a></code> and have extended functionality.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python
# coding=utf-8
&#34;&#34;&#34;
Datasets are based on the PyTorch ``torch.utils.data.Dataset`` data
primitive. They store the samples and their corresponding labels. Pytorch
domain libraries (e.g., vision, text, audio) provide pre-loaded datasets (e.g.,
MNIST) that subclass ``torch.utils.data.Dataset`` and implement functions
specific to the particular data. They can be used to prototype and benchmark
your model. You can find them at
[Image Datasets](https://pytorch.org/vision/stable/datasets.html),
[Text Datasets](https://pytorch.org/text/stable/datasets.html), and
[Audio Datasets](https://pytorch.org/audio/stable/datasets.html).

This module implements an abstract base class `BaseVisionDataset` for vision
datasets. It also replicates the official PyTorch image folder
(https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py)
so it can inherent from `BaseVisionDataset` and have extended functionality.
&#34;&#34;&#34;

import os
import sys
from abc import ABCMeta, abstractmethod
from itertools import zip_longest
from pathlib import Path
from typing import (Any, Callable, Dict, List, Optional, Tuple, Union, cast)
from torch.utils.data import Dataset
from torchvision.datasets.vision import VisionDataset  # type: ignore
from radio.settings.pathutils import (DATA_ROOT, IMG_EXTENSIONS,
                                      is_dir_or_symlink, PathType,
                                      is_valid_extension)
from .datautils import default_image_loader
from .datatypes import GenericEvalType, GenericTrainType

Sample = List[Tuple[Path, int]]
OneSample = Union[Dict[str, Tuple[Any, ...]], Tuple[Any, ...]]

__all__ = [
    &#34;DatasetType&#34;, &#34;EvalDatasetType&#34;, &#34;TrainDatasetType&#34;, &#34;BaseVisionDataset&#34;,
    &#34;FolderDataset&#34;, &#34;ImageFolder&#34;
]


def find_classes(directory: Path) -&gt; Tuple[List[str], Dict[str, int]]:
    &#34;&#34;&#34;
    Finds the class folders in a dataset.

    See :class:`FolderDataset` for details.
    &#34;&#34;&#34;
    classes = sorted(
        [entry.name for entry in os.scandir(directory) if entry.is_dir()])

    if not classes:
        msg = f&#34;Couldn&#39;t find any class folder in {directory}.&#34;
        raise FileNotFoundError(msg)

    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
    return classes, class_to_idx


def make_dataset(  # noqa: C901 - C901: Function is too complex.
    directory: Path,
    class_to_idx: Optional[Dict[str, int]] = None,
    extensions: Optional[Tuple[str, ...]] = None,
    is_valid_file: Optional[Callable[[Path], bool]] = None,
    max_class_size: int = sys.maxsize,
    max_dataset_size: int = sys.maxsize,
) -&gt; Sample:
    &#34;&#34;&#34;
    Generates a list of samples of a form (path_to_sample, class).

    See :class:`FolderDataset` for details.

    Note: The class_to_idx parameter is here optional and will use the logic of
    the ``find_classes`` function by default.
    &#34;&#34;&#34;
    # Arguments parsing
    assert is_dir_or_symlink(
        directory), f&#34;{directory} is not a valid directory&#34;

    if class_to_idx is None:
        _, class_to_idx = find_classes(directory)
    elif not class_to_idx:
        raise ValueError(&#34;&#39;class_to_idx&#39; must have at least one entry.&#34;)

    both_none = extensions is None and is_valid_file is None
    both_something = extensions is not None and is_valid_file is not None
    if both_none or both_something:
        both_none_or_something_msg = (
            &#34;Both &#39;extensions&#39; and &#39;is_valid_file&#39; cannot be None &#34;,
            &#34;or not None at the same time&#34;,
        )
        raise ValueError(both_none_or_something_msg)

    if extensions is not None:

        def _is_valid_file(fname: PathType) -&gt; bool:
            return is_valid_extension(fname, cast(Tuple[str, ...], extensions))

    is_valid_file = cast(Callable[[PathType], bool], _is_valid_file)

    # Main logic
    instances_dict = {}
    available_classes = set()
    for target_class in sorted(class_to_idx.keys()):
        class_idx = class_to_idx[target_class]
        class_instances = []
        n_instances = 0
        target_dir = directory / target_class
        if not is_dir_or_symlink(target_dir):
            continue
        for root, _, fnames in sorted(os.walk(target_dir, followlinks=True)):
            for fname in sorted(fnames):
                if is_valid_file(fname):
                    path = Path(root) / fname
                    item = path, class_idx
                    class_instances.append(item)
                    n_instances += 1
                    available_classes.add(target_class)

        # This ensures the maximum number of samples per class is respected.
        instances_dict[
            target_class] = class_instances[:min(max_class_size, n_instances)]

    empty_classes = set(class_to_idx.keys()) - available_classes
    if empty_classes:
        empty_classes_msg = (
            &#34;Found no valid file for the classes &#34;,
            f&#34;{&#39;, &#39;.join(sorted(empty_classes))}. &#34;,
            f&#34;Supported extensions are: {&#39;, &#39;.join(IMG_EXTENSIONS)}&#34;,
        )
        raise FileNotFoundError(empty_classes_msg)

    instances: Sample = []
    # This ensures the maximum number of samples allowed is respected.
    for samples in zip_longest(*sorted(instances_dict.values())):
        if len(instances) &gt; len(available_classes) * (max_dataset_size - 1):
            break
        # Remove None values using filter.
        instances.extend(list(filter(None, samples)))

    return instances


class BaseVisionDataset(VisionDataset, metaclass=ABCMeta):
    &#34;&#34;&#34;
    Base Class For making datasets which are compatible with torchvision.
    It is necessary to override the ``__getitem__`` and ``__len__`` method.

    To create a subclass, you need to implement the following functions:

    &lt;__init__&gt;:
        (Optionally) Initialize the class, first call super.__init__(root,
        train, transform, target_transform, **kwargs).
    &lt;__len__&gt;:
        Return the number of samples in the dataset.
    &lt;__getitem__&gt;:
        Get a data point.

    Parameters
    ----------
    root : Path or str
        Data root directory. Where to save/load the data.
    transform : Optional[Callable]
        A function/transform that takes in an PIL image and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    target_transform : Optional[Callable]
        A function/transform that takes in the target and transforms it.
    &#34;&#34;&#34;

    def __init__(
        self,
        root: PathType = DATA_ROOT,
        transform: Optional[Callable] = None,
        target_transform: Optional[Callable] = None,
        max_class_size: int = sys.maxsize,
        max_dataset_size: int = sys.maxsize,
    ) -&gt; None:
        super().__init__(root=Path(root),
                         transform=transform,
                         target_transform=target_transform)
        self.max_class_size = max_class_size
        self.max_dataset_size = max_dataset_size

    @abstractmethod
    def __getitem__(self, idx: int) -&gt; Any:
        &#34;&#34;&#34;
        Arguments
        ---------
        idx : int
            Index.

        Returns
        -------
        _ : Any
            Sample and meta data, optionally transformed by the respective
            transforms.
        &#34;&#34;&#34;

    @abstractmethod
    def __len__(self) -&gt; int:
        &#34;&#34;&#34;
        Returns
        -------
        _ : int
            Number of samples in dataset.
        &#34;&#34;&#34;


class FolderDataset(BaseVisionDataset):
    &#34;&#34;&#34;
    A generic folder dataset.

    This default directory structure can be customized by overriding the
    :meth:`find_classes` and :meth:`make_dataset` methods.

    Attributes
    ----------
    classes : list
        List of the class names sorted alphabetically.
    num_classes : int
        Number of classes in the dataset.
    class_to_idx : dict
        Dict with items (class_name, class_index).
    samples : list
        List of (sample, class_index) tuples.
    targets : list
        The class_index value for each image in the dataset.

    Parameters
    ----------
    root : Path or str
        Data root directory. Where to save/load the data.
    loader : Callable
        A function to load a sample given its path.
    transform : Optional[Callable]
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop`` for
        images.
    target_transform : Callable[Optional]
        Optional function/transform that takes in a target and returns a
        transformed version.
    extensions : Tuple[str]
        A list of allowed extensions.
    is_valid_file :  Optional[Callable[[Path], bool]]
        A function that takes path of a file and check if the file is a
        valid file (used to check of corrupt files).
    return_paths : bool
        If True, calling the dataset returns `(sample, target), target,
        sample path` instead of returning `(sample, target), target`.

    Notes
    -----
    Both `extensions` and `is_valid_file` cannot be None or not None at the
    same time.
    &#34;&#34;&#34;

    def __init__(
        self,
        root: PathType,
        loader: Callable[[Path], Any],
        transform: Optional[Callable] = None,
        target_transform: Optional[Callable] = None,
        extensions: Optional[Tuple[str, ...]] = None,
        is_valid_file: Optional[Callable[[Path], bool]] = None,
        return_paths: bool = False,
        max_class_size: int = sys.maxsize,
        max_dataset_size: int = sys.maxsize,
    ) -&gt; None:
        super().__init__(
            root=root,
            transform=transform,
            target_transform=target_transform,
            max_class_size=max_class_size,
            max_dataset_size=max_dataset_size,
        )

        classes, class_to_idx = self.find_classes(self.root)
        samples = self.make_dataset(
            self.root,
            class_to_idx,
            extensions,
            is_valid_file,
            self.max_class_size,
            self.max_dataset_size,
        )

        if len(samples) == 0:
            msg = (
                f&#34;Found 0 samples in: {root}. \n Supported &#34;,
                f&#39;extensions are: {&#34;,&#34;.join(IMG_EXTENSIONS)}&#39;,
            )
            raise RuntimeError(msg)

        self.loader = loader
        self.extensions = extensions
        self.classes = classes
        self.num_classes = len(classes)
        self.class_to_idx = class_to_idx
        self.samples = samples
        self.targets = [s[1] for s in samples]
        self.return_paths = return_paths

    @staticmethod
    def make_dataset(
        directory: Path,
        class_to_idx: Dict[str, int],
        extensions: Optional[Tuple[str, ...]] = None,
        is_valid_file: Optional[Callable[[Path], bool]] = None,
        max_class_size: int = sys.maxsize,
        max_dataset_size: int = sys.maxsize,
    ) -&gt; Sample:
        &#34;&#34;&#34;
        Generates a list of images of a form (path_to_sample, class).
        This can be overridden to e.g. read files from a compressed zip file
        instead of from the disk.

        Parameters
        ----------
        directory : Path
            root dataset directory, corresponding to ``self.root``.
        class_to_idx : Dict[str, int]
            Dictionary mapping class name to class index.
        extensions : Tuple[str]
            A list of allowed extensions.
        is_valid_file :  Optional[Callable[[Path], bool]]
            A function that takes path of a file and check if the file is a
            valid file (used to check of corrupt files).
        max_dataset_size : int
            Maximum number of samples allowed in the dataset.
        max_class_size : int
            Maximum number of samples allowed per class.

        Raises
        ------
        ValueError: In case ``class_to_idx`` is empty.
        FileNotFoundError: In case no valid file was found for any class.

        Returns
        -------
        _: Sample
            Samples of a form (path_to_sample, class).

        Notes
        -----
        Both `extensions` and `is_valid_file` cannot be None or not None at the
        same time.
        &#34;&#34;&#34;
        if class_to_idx is None:
            # prevent potential bug since make_dataset() would use the
            # class_to_idx logic of the find_classes() function, instead of
            # using that of the find_classes() method, which is potentially
            # overridden and thus could have a different logic.
            raise ValueError(&#34;The class_to_idx parameter cannot be None.&#34;)
        return make_dataset(
            directory,
            class_to_idx,
            extensions=extensions,
            is_valid_file=is_valid_file,
            max_class_size=max_class_size,
            max_dataset_size=max_dataset_size,
        )

    @staticmethod
    def find_classes(directory: Path) -&gt; Tuple[List[str], Dict[str, int]]:
        &#34;&#34;&#34;Find the class folders in a image dataset structured as follows:

        directory/
        ├── class_x
        │   ├── xxx.ext
        │   ├── xxy.ext
        │   └── ...
        │   └── xxz.ext
        └── class_y
            ├── 123.ext
            ├── nsdf3.ext
            └── ...
            └── asd932_.ext


        This method can be overridden to only consider a subset of classes,
        or to adapt to a different dataset directory structure.

        Arguments
        ---------
        directory : Path
            Root directory path, corresponding to ``self.root``.

        Raises
        ------
        FileNotFoundError: If ``directory`` has no class folders.

        Returns
        -------
        _: Tuple[List[str], Dict[str, int]]
            List of all classes and dictionary mapping each class to an index.
        &#34;&#34;&#34;
        return find_classes(directory)

    def __getitem__(self, idx: int) -&gt; OneSample:
        &#34;&#34;&#34;
        Parameters
        ----------
        idx : int
            A (random) integer for data intexing.

        Returns
        -------
        _: Tuple[Any, ...]
            (sample, target) where target is class_index of the target class.
            (sample, target, path) if ``self.return_paths`` is True.
        &#34;&#34;&#34;
        path, target = self.samples[idx]
        sample = self.loader(path)
        if self.transform is not None:
            sample = self.transform(sample)
        if self.target_transform is not None:
            target = self.target_transform(target)
        if self.return_paths:
            return sample, target, path
        return sample, target

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;Return the total number of images&#34;&#34;&#34;
        return len(self.samples)


class ImageFolder(FolderDataset):
    &#34;&#34;&#34;
    A generic image folder dataset where the images are arranged in this way by
    default:

    root/
    ├── dog
    │   ├── xxx.png
    │   ├── xxy.png
    │   └── ...
    │   └── xxz.png
    └── cat
        ├── 123.png
        ├── nsdf3.png
        └── ...
        └── asd932_.png

    This class inherits from :class:`FolderDataset` so the same methods can be
    overridden to customize the dataset.

    Attributes
    ----------
    classes : list
        List of the class names sorted alphabetically.
    num_classes : int
        Number of classes in the dataset.
    class_to_idx : dict
        Dict with items (class_name, class_index).
    samples : list
        List of (images, class_index) tuples
    targets : list
        The class_index value for each image in the dataset

    Parameters
    ----------
    root : Path or str
        Data root directory. Where to save/load the data.
    loader : Optional[Callable]
        A function to load a image given its path.
    transform : Optional[Callable]
        A function/transform that takes in an PIL image and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    target_transform : Callable[Optional]
        Optional function/transform that takes in a target and returns a
        transformed version.
    is_valid_file : Optional[Callable[[Path], bool]]
        A function that takes path of an image file and check if the file
        is a valid image file (used to check of corrupt files).
    return_paths : bool
        If True, calling the dataset returns `(img, label), label, image
        path` instead of returning `(img, label), label`.
    &#34;&#34;&#34;

    def __init__(
        self,
        root: PathType,
        loader: Callable[[Path], Any] = default_image_loader,
        transform: Optional[Callable] = None,
        target_transform: Optional[Callable] = None,
        is_valid_file: Optional[Callable[[Path], bool]] = None,
        return_paths: bool = False,
        max_class_size: int = sys.maxsize,
        max_dataset_size: int = sys.maxsize,
    ) -&gt; None:
        super().__init__(
            root=root,
            loader=loader,
            transform=transform,
            target_transform=target_transform,
            extensions=IMG_EXTENSIONS if is_valid_file is None else None,
            is_valid_file=is_valid_file,
            return_paths=return_paths,
            max_class_size=max_class_size,
            max_dataset_size=max_dataset_size,
        )


DatasetType = Union[Dataset, BaseVisionDataset]
TrainDatasetType = GenericTrainType[DatasetType]
EvalDatasetType = GenericEvalType[DatasetType]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="radio.data.dataset.BaseVisionDataset"><code class="flex name class">
<span>class <span class="ident">BaseVisionDataset</span></span>
<span>(</span><span>root: Union[str, pathlib.Path] = PosixPath('/home/wangl15@acct.upmchs.net/radio/dataset'), transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807)</span>
</code></dt>
<dd>
<div class="desc"><p>Base Class For making datasets which are compatible with torchvision.
It is necessary to override the <code>__getitem__</code> and <code>__len__</code> method.</p>
<p>To create a subclass, you need to implement the following functions:</p>
<p>&lt;<strong>init</strong>&gt;:
(Optionally) Initialize the class, first call super.<strong>init</strong>(root,
train, transform, target_transform, **kwargs).
&lt;<strong>len</strong>&gt;:
Return the number of samples in the dataset.
&lt;<strong>getitem</strong>&gt;:
Get a data point.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>root</code></strong> :&ensp;<code>Path</code> or <code>str</code></dt>
<dd>Data root directory. Where to save/load the data.</dd>
<dt><strong><code>transform</code></strong> :&ensp;<code>Optional[Callable]</code></dt>
<dd>A function/transform that takes in an PIL image and returns a
transformed version, e.g, <code>torchvision.transforms.RandomCrop</code>.</dd>
<dt><strong><code>target_transform</code></strong> :&ensp;<code>Optional[Callable]</code></dt>
<dd>A function/transform that takes in the target and transforms it.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BaseVisionDataset(VisionDataset, metaclass=ABCMeta):
    &#34;&#34;&#34;
    Base Class For making datasets which are compatible with torchvision.
    It is necessary to override the ``__getitem__`` and ``__len__`` method.

    To create a subclass, you need to implement the following functions:

    &lt;__init__&gt;:
        (Optionally) Initialize the class, first call super.__init__(root,
        train, transform, target_transform, **kwargs).
    &lt;__len__&gt;:
        Return the number of samples in the dataset.
    &lt;__getitem__&gt;:
        Get a data point.

    Parameters
    ----------
    root : Path or str
        Data root directory. Where to save/load the data.
    transform : Optional[Callable]
        A function/transform that takes in an PIL image and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    target_transform : Optional[Callable]
        A function/transform that takes in the target and transforms it.
    &#34;&#34;&#34;

    def __init__(
        self,
        root: PathType = DATA_ROOT,
        transform: Optional[Callable] = None,
        target_transform: Optional[Callable] = None,
        max_class_size: int = sys.maxsize,
        max_dataset_size: int = sys.maxsize,
    ) -&gt; None:
        super().__init__(root=Path(root),
                         transform=transform,
                         target_transform=target_transform)
        self.max_class_size = max_class_size
        self.max_dataset_size = max_dataset_size

    @abstractmethod
    def __getitem__(self, idx: int) -&gt; Any:
        &#34;&#34;&#34;
        Arguments
        ---------
        idx : int
            Index.

        Returns
        -------
        _ : Any
            Sample and meta data, optionally transformed by the respective
            transforms.
        &#34;&#34;&#34;

    @abstractmethod
    def __len__(self) -&gt; int:
        &#34;&#34;&#34;
        Returns
        -------
        _ : int
            Number of samples in dataset.
        &#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torchvision.datasets.vision.VisionDataset</li>
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="radio.data.dataset.FolderDataset" href="#radio.data.dataset.FolderDataset">FolderDataset</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="radio.data.dataset.BaseVisionDataset.functions"><code class="name">var <span class="ident">functions</span> : Dict[str, Callable]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="radio.data.dataset.FolderDataset"><code class="flex name class">
<span>class <span class="ident">FolderDataset</span></span>
<span>(</span><span>root: Union[str, pathlib.Path], loader: Callable[[pathlib.Path], Any], transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[pathlib.Path], bool]] = None, return_paths: bool = False, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807)</span>
</code></dt>
<dd>
<div class="desc"><p>A generic folder dataset.</p>
<p>This default directory structure can be customized by overriding the
:meth:<code>find_classes</code> and :meth:<code>make_dataset</code> methods.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>classes</code></strong> :&ensp;<code>list</code></dt>
<dd>List of the class names sorted alphabetically.</dd>
<dt><strong><code>num_classes</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of classes in the dataset.</dd>
<dt><strong><code>class_to_idx</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dict with items (class_name, class_index).</dd>
<dt><strong><code>samples</code></strong> :&ensp;<code>list</code></dt>
<dd>List of (sample, class_index) tuples.</dd>
<dt><strong><code>targets</code></strong> :&ensp;<code>list</code></dt>
<dd>The class_index value for each image in the dataset.</dd>
</dl>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>root</code></strong> :&ensp;<code>Path</code> or <code>str</code></dt>
<dd>Data root directory. Where to save/load the data.</dd>
<dt><strong><code>loader</code></strong> :&ensp;<code>Callable</code></dt>
<dd>A function to load a sample given its path.</dd>
<dt><strong><code>transform</code></strong> :&ensp;<code>Optional[Callable]</code></dt>
<dd>A function/transform that takes in a sample and returns a
transformed version, e.g, <code>torchvision.transforms.RandomCrop</code> for
images.</dd>
<dt><strong><code>target_transform</code></strong> :&ensp;<code>Callable[Optional]</code></dt>
<dd>Optional function/transform that takes in a target and returns a
transformed version.</dd>
<dt><strong><code>extensions</code></strong> :&ensp;<code>Tuple[str]</code></dt>
<dd>A list of allowed extensions.</dd>
<dt><strong><code>is_valid_file</code></strong> :&ensp;<code> Optional[Callable[[Path], bool]]</code></dt>
<dd>A function that takes path of a file and check if the file is a
valid file (used to check of corrupt files).</dd>
<dt><strong><code>return_paths</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, calling the dataset returns <code>(sample, target), target,
sample path&lt;code&gt; instead of returning &lt;/code&gt;(sample, target), target</code>.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Both <code>extensions</code> and <code>is_valid_file</code> cannot be None or not None at the
same time.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FolderDataset(BaseVisionDataset):
    &#34;&#34;&#34;
    A generic folder dataset.

    This default directory structure can be customized by overriding the
    :meth:`find_classes` and :meth:`make_dataset` methods.

    Attributes
    ----------
    classes : list
        List of the class names sorted alphabetically.
    num_classes : int
        Number of classes in the dataset.
    class_to_idx : dict
        Dict with items (class_name, class_index).
    samples : list
        List of (sample, class_index) tuples.
    targets : list
        The class_index value for each image in the dataset.

    Parameters
    ----------
    root : Path or str
        Data root directory. Where to save/load the data.
    loader : Callable
        A function to load a sample given its path.
    transform : Optional[Callable]
        A function/transform that takes in a sample and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop`` for
        images.
    target_transform : Callable[Optional]
        Optional function/transform that takes in a target and returns a
        transformed version.
    extensions : Tuple[str]
        A list of allowed extensions.
    is_valid_file :  Optional[Callable[[Path], bool]]
        A function that takes path of a file and check if the file is a
        valid file (used to check of corrupt files).
    return_paths : bool
        If True, calling the dataset returns `(sample, target), target,
        sample path` instead of returning `(sample, target), target`.

    Notes
    -----
    Both `extensions` and `is_valid_file` cannot be None or not None at the
    same time.
    &#34;&#34;&#34;

    def __init__(
        self,
        root: PathType,
        loader: Callable[[Path], Any],
        transform: Optional[Callable] = None,
        target_transform: Optional[Callable] = None,
        extensions: Optional[Tuple[str, ...]] = None,
        is_valid_file: Optional[Callable[[Path], bool]] = None,
        return_paths: bool = False,
        max_class_size: int = sys.maxsize,
        max_dataset_size: int = sys.maxsize,
    ) -&gt; None:
        super().__init__(
            root=root,
            transform=transform,
            target_transform=target_transform,
            max_class_size=max_class_size,
            max_dataset_size=max_dataset_size,
        )

        classes, class_to_idx = self.find_classes(self.root)
        samples = self.make_dataset(
            self.root,
            class_to_idx,
            extensions,
            is_valid_file,
            self.max_class_size,
            self.max_dataset_size,
        )

        if len(samples) == 0:
            msg = (
                f&#34;Found 0 samples in: {root}. \n Supported &#34;,
                f&#39;extensions are: {&#34;,&#34;.join(IMG_EXTENSIONS)}&#39;,
            )
            raise RuntimeError(msg)

        self.loader = loader
        self.extensions = extensions
        self.classes = classes
        self.num_classes = len(classes)
        self.class_to_idx = class_to_idx
        self.samples = samples
        self.targets = [s[1] for s in samples]
        self.return_paths = return_paths

    @staticmethod
    def make_dataset(
        directory: Path,
        class_to_idx: Dict[str, int],
        extensions: Optional[Tuple[str, ...]] = None,
        is_valid_file: Optional[Callable[[Path], bool]] = None,
        max_class_size: int = sys.maxsize,
        max_dataset_size: int = sys.maxsize,
    ) -&gt; Sample:
        &#34;&#34;&#34;
        Generates a list of images of a form (path_to_sample, class).
        This can be overridden to e.g. read files from a compressed zip file
        instead of from the disk.

        Parameters
        ----------
        directory : Path
            root dataset directory, corresponding to ``self.root``.
        class_to_idx : Dict[str, int]
            Dictionary mapping class name to class index.
        extensions : Tuple[str]
            A list of allowed extensions.
        is_valid_file :  Optional[Callable[[Path], bool]]
            A function that takes path of a file and check if the file is a
            valid file (used to check of corrupt files).
        max_dataset_size : int
            Maximum number of samples allowed in the dataset.
        max_class_size : int
            Maximum number of samples allowed per class.

        Raises
        ------
        ValueError: In case ``class_to_idx`` is empty.
        FileNotFoundError: In case no valid file was found for any class.

        Returns
        -------
        _: Sample
            Samples of a form (path_to_sample, class).

        Notes
        -----
        Both `extensions` and `is_valid_file` cannot be None or not None at the
        same time.
        &#34;&#34;&#34;
        if class_to_idx is None:
            # prevent potential bug since make_dataset() would use the
            # class_to_idx logic of the find_classes() function, instead of
            # using that of the find_classes() method, which is potentially
            # overridden and thus could have a different logic.
            raise ValueError(&#34;The class_to_idx parameter cannot be None.&#34;)
        return make_dataset(
            directory,
            class_to_idx,
            extensions=extensions,
            is_valid_file=is_valid_file,
            max_class_size=max_class_size,
            max_dataset_size=max_dataset_size,
        )

    @staticmethod
    def find_classes(directory: Path) -&gt; Tuple[List[str], Dict[str, int]]:
        &#34;&#34;&#34;Find the class folders in a image dataset structured as follows:

        directory/
        ├── class_x
        │   ├── xxx.ext
        │   ├── xxy.ext
        │   └── ...
        │   └── xxz.ext
        └── class_y
            ├── 123.ext
            ├── nsdf3.ext
            └── ...
            └── asd932_.ext


        This method can be overridden to only consider a subset of classes,
        or to adapt to a different dataset directory structure.

        Arguments
        ---------
        directory : Path
            Root directory path, corresponding to ``self.root``.

        Raises
        ------
        FileNotFoundError: If ``directory`` has no class folders.

        Returns
        -------
        _: Tuple[List[str], Dict[str, int]]
            List of all classes and dictionary mapping each class to an index.
        &#34;&#34;&#34;
        return find_classes(directory)

    def __getitem__(self, idx: int) -&gt; OneSample:
        &#34;&#34;&#34;
        Parameters
        ----------
        idx : int
            A (random) integer for data intexing.

        Returns
        -------
        _: Tuple[Any, ...]
            (sample, target) where target is class_index of the target class.
            (sample, target, path) if ``self.return_paths`` is True.
        &#34;&#34;&#34;
        path, target = self.samples[idx]
        sample = self.loader(path)
        if self.transform is not None:
            sample = self.transform(sample)
        if self.target_transform is not None:
            target = self.target_transform(target)
        if self.return_paths:
            return sample, target, path
        return sample, target

    def __len__(self) -&gt; int:
        &#34;&#34;&#34;Return the total number of images&#34;&#34;&#34;
        return len(self.samples)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="radio.data.dataset.BaseVisionDataset" href="#radio.data.dataset.BaseVisionDataset">BaseVisionDataset</a></li>
<li>torchvision.datasets.vision.VisionDataset</li>
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="radio.data.dataset.ImageFolder" href="#radio.data.dataset.ImageFolder">ImageFolder</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="radio.data.dataset.FolderDataset.functions"><code class="name">var <span class="ident">functions</span> : Dict[str, Callable]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="radio.data.dataset.FolderDataset.find_classes"><code class="name flex">
<span>def <span class="ident">find_classes</span></span>(<span>directory: pathlib.Path) ‑> Tuple[List[str], Dict[str, int]]</span>
</code></dt>
<dd>
<div class="desc"><p>Find the class folders in a image dataset structured as follows:</p>
<p>directory/
├── class_x
│
├── xxx.ext
│
├── xxy.ext
│
└── &hellip;
│
└── xxz.ext
└── class_y
├── 123.ext
├── nsdf3.ext
└── &hellip;
└── asd932_.ext</p>
<p>This method can be overridden to only consider a subset of classes,
or to adapt to a different dataset directory structure.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>directory</code></strong> :&ensp;<code>Path</code></dt>
<dd>Root directory path, corresponding to <code>self.root</code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<p>FileNotFoundError: If <code>directory</code> has no class folders.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>Tuple[List[str], Dict[str, int]]</code></dt>
<dd>List of all classes and dictionary mapping each class to an index.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def find_classes(directory: Path) -&gt; Tuple[List[str], Dict[str, int]]:
    &#34;&#34;&#34;Find the class folders in a image dataset structured as follows:

    directory/
    ├── class_x
    │   ├── xxx.ext
    │   ├── xxy.ext
    │   └── ...
    │   └── xxz.ext
    └── class_y
        ├── 123.ext
        ├── nsdf3.ext
        └── ...
        └── asd932_.ext


    This method can be overridden to only consider a subset of classes,
    or to adapt to a different dataset directory structure.

    Arguments
    ---------
    directory : Path
        Root directory path, corresponding to ``self.root``.

    Raises
    ------
    FileNotFoundError: If ``directory`` has no class folders.

    Returns
    -------
    _: Tuple[List[str], Dict[str, int]]
        List of all classes and dictionary mapping each class to an index.
    &#34;&#34;&#34;
    return find_classes(directory)</code></pre>
</details>
</dd>
<dt id="radio.data.dataset.FolderDataset.make_dataset"><code class="name flex">
<span>def <span class="ident">make_dataset</span></span>(<span>directory: pathlib.Path, class_to_idx: Dict[str, int], extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[pathlib.Path], bool]] = None, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807) ‑> List[Tuple[pathlib.Path, int]]</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a list of images of a form (path_to_sample, class).
This can be overridden to e.g. read files from a compressed zip file
instead of from the disk.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>directory</code></strong> :&ensp;<code>Path</code></dt>
<dd>root dataset directory, corresponding to <code>self.root</code>.</dd>
<dt><strong><code>class_to_idx</code></strong> :&ensp;<code>Dict[str, int]</code></dt>
<dd>Dictionary mapping class name to class index.</dd>
<dt><strong><code>extensions</code></strong> :&ensp;<code>Tuple[str]</code></dt>
<dd>A list of allowed extensions.</dd>
<dt><strong><code>is_valid_file</code></strong> :&ensp;<code> Optional[Callable[[Path], bool]]</code></dt>
<dd>A function that takes path of a file and check if the file is a
valid file (used to check of corrupt files).</dd>
<dt><strong><code>max_dataset_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Maximum number of samples allowed in the dataset.</dd>
<dt><strong><code>max_class_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Maximum number of samples allowed per class.</dd>
</dl>
<h2 id="raises">Raises</h2>
<p>ValueError: In case <code>class_to_idx</code> is empty.
FileNotFoundError: In case no valid file was found for any class.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>_</code></strong> :&ensp;<code>Sample</code></dt>
<dd>Samples of a form (path_to_sample, class).</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Both <code>extensions</code> and <code>is_valid_file</code> cannot be None or not None at the
same time.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def make_dataset(
    directory: Path,
    class_to_idx: Dict[str, int],
    extensions: Optional[Tuple[str, ...]] = None,
    is_valid_file: Optional[Callable[[Path], bool]] = None,
    max_class_size: int = sys.maxsize,
    max_dataset_size: int = sys.maxsize,
) -&gt; Sample:
    &#34;&#34;&#34;
    Generates a list of images of a form (path_to_sample, class).
    This can be overridden to e.g. read files from a compressed zip file
    instead of from the disk.

    Parameters
    ----------
    directory : Path
        root dataset directory, corresponding to ``self.root``.
    class_to_idx : Dict[str, int]
        Dictionary mapping class name to class index.
    extensions : Tuple[str]
        A list of allowed extensions.
    is_valid_file :  Optional[Callable[[Path], bool]]
        A function that takes path of a file and check if the file is a
        valid file (used to check of corrupt files).
    max_dataset_size : int
        Maximum number of samples allowed in the dataset.
    max_class_size : int
        Maximum number of samples allowed per class.

    Raises
    ------
    ValueError: In case ``class_to_idx`` is empty.
    FileNotFoundError: In case no valid file was found for any class.

    Returns
    -------
    _: Sample
        Samples of a form (path_to_sample, class).

    Notes
    -----
    Both `extensions` and `is_valid_file` cannot be None or not None at the
    same time.
    &#34;&#34;&#34;
    if class_to_idx is None:
        # prevent potential bug since make_dataset() would use the
        # class_to_idx logic of the find_classes() function, instead of
        # using that of the find_classes() method, which is potentially
        # overridden and thus could have a different logic.
        raise ValueError(&#34;The class_to_idx parameter cannot be None.&#34;)
    return make_dataset(
        directory,
        class_to_idx,
        extensions=extensions,
        is_valid_file=is_valid_file,
        max_class_size=max_class_size,
        max_dataset_size=max_dataset_size,
    )</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="radio.data.dataset.ImageFolder"><code class="flex name class">
<span>class <span class="ident">ImageFolder</span></span>
<span>(</span><span>root: Union[str, pathlib.Path], loader: Callable[[pathlib.Path], Any] = &lt;function default_image_loader&gt;, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, is_valid_file: Optional[Callable[[pathlib.Path], bool]] = None, return_paths: bool = False, max_class_size: int = 9223372036854775807, max_dataset_size: int = 9223372036854775807)</span>
</code></dt>
<dd>
<div class="desc"><p>A generic image folder dataset where the images are arranged in this way by
default:</p>
<p>root/
├── dog
│
├── xxx.png
│
├── xxy.png
│
└── &hellip;
│
└── xxz.png
└── cat
├── 123.png
├── nsdf3.png
└── &hellip;
└── asd932_.png</p>
<p>This class inherits from :class:<code><a title="radio.data.dataset.FolderDataset" href="#radio.data.dataset.FolderDataset">FolderDataset</a></code> so the same methods can be
overridden to customize the dataset.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>classes</code></strong> :&ensp;<code>list</code></dt>
<dd>List of the class names sorted alphabetically.</dd>
<dt><strong><code>num_classes</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of classes in the dataset.</dd>
<dt><strong><code>class_to_idx</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dict with items (class_name, class_index).</dd>
<dt><strong><code>samples</code></strong> :&ensp;<code>list</code></dt>
<dd>List of (images, class_index) tuples</dd>
<dt><strong><code>targets</code></strong> :&ensp;<code>list</code></dt>
<dd>The class_index value for each image in the dataset</dd>
</dl>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>root</code></strong> :&ensp;<code>Path</code> or <code>str</code></dt>
<dd>Data root directory. Where to save/load the data.</dd>
<dt><strong><code>loader</code></strong> :&ensp;<code>Optional[Callable]</code></dt>
<dd>A function to load a image given its path.</dd>
<dt><strong><code>transform</code></strong> :&ensp;<code>Optional[Callable]</code></dt>
<dd>A function/transform that takes in an PIL image and returns a
transformed version, e.g, <code>torchvision.transforms.RandomCrop</code>.</dd>
<dt><strong><code>target_transform</code></strong> :&ensp;<code>Callable[Optional]</code></dt>
<dd>Optional function/transform that takes in a target and returns a
transformed version.</dd>
<dt><strong><code>is_valid_file</code></strong> :&ensp;<code>Optional[Callable[[Path], bool]]</code></dt>
<dd>A function that takes path of an image file and check if the file
is a valid image file (used to check of corrupt files).</dd>
<dt><strong><code>return_paths</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, calling the dataset returns <code>(img, label), label, image
path&lt;code&gt; instead of returning &lt;/code&gt;(img, label), label</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ImageFolder(FolderDataset):
    &#34;&#34;&#34;
    A generic image folder dataset where the images are arranged in this way by
    default:

    root/
    ├── dog
    │   ├── xxx.png
    │   ├── xxy.png
    │   └── ...
    │   └── xxz.png
    └── cat
        ├── 123.png
        ├── nsdf3.png
        └── ...
        └── asd932_.png

    This class inherits from :class:`FolderDataset` so the same methods can be
    overridden to customize the dataset.

    Attributes
    ----------
    classes : list
        List of the class names sorted alphabetically.
    num_classes : int
        Number of classes in the dataset.
    class_to_idx : dict
        Dict with items (class_name, class_index).
    samples : list
        List of (images, class_index) tuples
    targets : list
        The class_index value for each image in the dataset

    Parameters
    ----------
    root : Path or str
        Data root directory. Where to save/load the data.
    loader : Optional[Callable]
        A function to load a image given its path.
    transform : Optional[Callable]
        A function/transform that takes in an PIL image and returns a
        transformed version, e.g, ``torchvision.transforms.RandomCrop``.
    target_transform : Callable[Optional]
        Optional function/transform that takes in a target and returns a
        transformed version.
    is_valid_file : Optional[Callable[[Path], bool]]
        A function that takes path of an image file and check if the file
        is a valid image file (used to check of corrupt files).
    return_paths : bool
        If True, calling the dataset returns `(img, label), label, image
        path` instead of returning `(img, label), label`.
    &#34;&#34;&#34;

    def __init__(
        self,
        root: PathType,
        loader: Callable[[Path], Any] = default_image_loader,
        transform: Optional[Callable] = None,
        target_transform: Optional[Callable] = None,
        is_valid_file: Optional[Callable[[Path], bool]] = None,
        return_paths: bool = False,
        max_class_size: int = sys.maxsize,
        max_dataset_size: int = sys.maxsize,
    ) -&gt; None:
        super().__init__(
            root=root,
            loader=loader,
            transform=transform,
            target_transform=target_transform,
            extensions=IMG_EXTENSIONS if is_valid_file is None else None,
            is_valid_file=is_valid_file,
            return_paths=return_paths,
            max_class_size=max_class_size,
            max_dataset_size=max_dataset_size,
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="radio.data.dataset.FolderDataset" href="#radio.data.dataset.FolderDataset">FolderDataset</a></li>
<li><a title="radio.data.dataset.BaseVisionDataset" href="#radio.data.dataset.BaseVisionDataset">BaseVisionDataset</a></li>
<li>torchvision.datasets.vision.VisionDataset</li>
<li>torch.utils.data.dataset.Dataset</li>
<li>typing.Generic</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="radio.data.dataset.ImageFolder.functions"><code class="name">var <span class="ident">functions</span> : Dict[str, Callable]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="radio.data.dataset.FolderDataset" href="#radio.data.dataset.FolderDataset">FolderDataset</a></b></code>:
<ul class="hlist">
<li><code><a title="radio.data.dataset.FolderDataset.find_classes" href="#radio.data.dataset.FolderDataset.find_classes">find_classes</a></code></li>
<li><code><a title="radio.data.dataset.FolderDataset.make_dataset" href="#radio.data.dataset.FolderDataset.make_dataset">make_dataset</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="radio.data" href="index.html">radio.data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="radio.data.dataset.BaseVisionDataset" href="#radio.data.dataset.BaseVisionDataset">BaseVisionDataset</a></code></h4>
<ul class="">
<li><code><a title="radio.data.dataset.BaseVisionDataset.functions" href="#radio.data.dataset.BaseVisionDataset.functions">functions</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="radio.data.dataset.FolderDataset" href="#radio.data.dataset.FolderDataset">FolderDataset</a></code></h4>
<ul class="">
<li><code><a title="radio.data.dataset.FolderDataset.find_classes" href="#radio.data.dataset.FolderDataset.find_classes">find_classes</a></code></li>
<li><code><a title="radio.data.dataset.FolderDataset.functions" href="#radio.data.dataset.FolderDataset.functions">functions</a></code></li>
<li><code><a title="radio.data.dataset.FolderDataset.make_dataset" href="#radio.data.dataset.FolderDataset.make_dataset">make_dataset</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="radio.data.dataset.ImageFolder" href="#radio.data.dataset.ImageFolder">ImageFolder</a></code></h4>
<ul class="">
<li><code><a title="radio.data.dataset.ImageFolder.functions" href="#radio.data.dataset.ImageFolder.functions">functions</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>